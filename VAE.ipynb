{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/baseline_hybrid/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kCoGhlyfHLU",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFE8Oevpd134",
        "colab_type": "code",
        "outputId": "bdaa723e-4731-4f57-9e15-ad4783d2cdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EpY3vbmfKCD",
        "colab_type": "code",
        "outputId": "7143622b-8750-4f70-abef-239f3e2ebbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# !ls\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torchvision import models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibcwTlI1ohGd",
        "colab_type": "text"
      },
      "source": [
        "## cuda code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdEfZegwojD5",
        "colab_type": "code",
        "outputId": "535cbf41-c77d-4ba7-ff63-3db8d26f4ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05LjGyTCfL0M",
        "colab_type": "text"
      },
      "source": [
        "# MODEL "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S2WAZkgfRPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alex_net = models.A\n",
        "# alex = models.alexnet(pretrained = True)\n",
        "\n",
        "# # make conditioned - give the decoder the last output of encoder as input.\n",
        "# class Enc_Dec(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Enc_Dec, self).__init__()\n",
        "        \n",
        "#         self."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzjS6ZMux5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alex.features[0] = nn.Conv2d(1,64, kernel_size = (11,11), stride = (4,4), padding = (2,2))\n",
        "# for i, params in enumerate(alex.parameters()):\n",
        "#     if (i==1):\n",
        "#         print(params.data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR1BDEGSI1Qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8aPqCc_I1ln",
        "colab_type": "text"
      },
      "source": [
        "# Encoder\n",
        "NON VARIATIONAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTIl-oaCQwaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self, in_channels, image_dims):\n",
        "        super(encoder, self).__init__()\n",
        "        self.image_dims = image_dims # list of channels, height, width\n",
        "        self.in_chan = in_channels\n",
        "        \n",
        "        \"\"\"activations \"\"\"\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "        # need to decide how deep the input is\n",
        "        \"\"\"convolution encoding \"\"\"\n",
        "        self.c1 = nn.Conv2d(self.in_chan, 32, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.c2 = nn.Conv2d(32, 64, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.c3 = nn.Conv2d(64, 128, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.c4 = nn.Conv2d(128, 256, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \"\"\" fully connected layer \"\"\"\n",
        "        \n",
        "        self.fc1 = nn.Linear(1024,128)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128,1024)\n",
        "        \n",
        "        self.fc3 = nn.Linear(1024,4096) # get rid of this one\n",
        "        \n",
        "        \"\"\" decoder convolution\"\"\"\n",
        "        # why does not having equal kernel sizes as above not effect it in this way?\n",
        "        \n",
        "#         self.t1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=1)\n",
        "        \n",
        "#         self.t2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        \n",
        "#         self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        \n",
        "#         self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=6, stride=2)\n",
        "        \n",
        "        self.t1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2)\n",
        "        \n",
        "        self.t2 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2)\n",
        "        \n",
        "        self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2)\n",
        "        \n",
        "        self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=5, stride = 2)\n",
        "        \n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.relu(self.c1(x))\n",
        "        x = self.relu(self.c2(x))\n",
        "        x = self.relu(self.c3(x))\n",
        "        x = self.relu(self.c4(x))\n",
        "        return x\n",
        "    \n",
        "    def fc_layers(self, x):\n",
        "        #first we flatten\n",
        "        # -1 in pytorch view is the same as -1 in numpy reshape\n",
        "        x = x.view(x.size(0), -1) # using view terminology\n",
        "        \n",
        "        # fully connected layers\n",
        "        # this is an autoencoder with no variation, so no distribution sampling\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x) # get rid of this layer.\n",
        "        # x.size(0) allows for variable batch sizes.\n",
        "#         print(\"x shape debug\")\n",
        "#         print(x.shape)\n",
        "        size = 1024 # size of flattened array going in?\n",
        "        x = x.view(x.size(0), size, 1, 1)\n",
        "#         x = x.view(-1, self.image_dims[0], self.image_dims[1], self.image_dims[2])\n",
        "        \n",
        "        # now we reshape the image back into the square. \n",
        "        return x\n",
        "    \n",
        "    def decode(self, x):\n",
        "#         print(x.shape)\n",
        "        dummy = torch.randn([1,1,64,64])\n",
        "        x = self.relu(self.t1(x))\n",
        "        x = self.relu(self.t2(x))\n",
        "        x = self.relu(self.t3(x))\n",
        "        x = self.relu(self.t4(x, output_size = dummy.size())) #  output_size = dummy.size())\n",
        "        return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "#         x = self.fc_layers(x)\n",
        "        x = self.decode(x)\n",
        "        x = self.sig(x)\n",
        "        return x\n",
        "    \n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-ZDnz22uOhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fefea84d-1c39-4421-c941-29927964576a"
      },
      "source": [
        "64*15*15\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu0fK4PgghRm",
        "colab_type": "text"
      },
      "source": [
        "## dummy encoder \n",
        "for verification process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hll3c_zagksK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dummy_enc(nn.Module):\n",
        "    def __init__(self, in_channels, image_dims):\n",
        "        super(dummy_enc, self).__init__()\n",
        "        self.image_dims = image_dims # list of channels, height, width\n",
        "        self.in_chan = in_channels\n",
        "        \n",
        "        \"\"\"activations \"\"\"\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "        # need to decide how deep the input is\n",
        "        \"\"\"convolution encoding \"\"\"\n",
        "        self.c1 = nn.Conv2d(self.in_chan, 32, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.c2 = nn.Conv2d(32, 64, kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.t1 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
        "\n",
        "        self.t2 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=4, stride=2)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \"\"\" fully connected layer \"\"\"\n",
        "        \n",
        "      \n",
        "        self.fc1 = nn.Linear(14400,5000) # get rid of this one\n",
        "        self.fc2 = nn.Linear(5000,14400)  \n",
        "        \"\"\" decoder convolution\"\"\"\n",
        "        # why does not having equal kernel sizes as above not effect it in this way?\n",
        "        \n",
        "#         self.t1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=1)\n",
        "        \n",
        "#         self.t2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        \n",
        "#         self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        \n",
        "#         self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=6, stride=2)\n",
        "        \n",
        "        \n",
        "       \n",
        "\n",
        "    \n",
        "#     def encode(self, x):\n",
        "#         x = self.relu(self.c1(x))\n",
        "#         x = self.relu(self.c2(x))\n",
        "#         x = self.relu(self.c3(x))\n",
        "#         x = self.relu(self.c4(x))\n",
        "#         return x\n",
        "    \n",
        "#     def fc_layers(self, x):\n",
        "#         #first we flatten\n",
        "#         # -1 in pytorch view is the same as -1 in numpy reshape\n",
        "#         x = x.view(x.size(0), -1) # using view terminology\n",
        "        \n",
        "#         # fully connected layers\n",
        "#         # this is an autoencoder with no variation, so no distribution sampling\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.fc3(x) # get rid of this layer.\n",
        "#         # x.size(0) allows for variable batch sizes.\n",
        "# #         print(\"x shape debug\")\n",
        "# #         print(x.shape)\n",
        "#         size = 1024 # size of flattened array going in?\n",
        "#         x = x.view(x.size(0), size, 1, 1)\n",
        "# #         x = x.view(-1, self.image_dims[0], self.image_dims[1], self.image_dims[2])\n",
        "        \n",
        "#         # now we reshape the image back into the square. \n",
        "#         return x\n",
        "    \n",
        "#     def decode(self, x):\n",
        "# #         print(x.shape)\n",
        "#         dummy = torch.randn([1,1,64,64])\n",
        "#         x = self.relu(self.t1(x))\n",
        "#         x = self.relu(self.t2(x))\n",
        "#         x = self.relu(self.t3(x))\n",
        "#         x = self.relu(self.t4(x, output_size = dummy.size())) #  output_size = dummy.size())\n",
        "#         return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.c1(x))\n",
        "        x = self.relu(self.c2(x))\n",
        "#         print(x.shape)\n",
        "        x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x.view(x.size(0), 64, 15, 15)\n",
        "        x = self.relu(self.t1(x))\n",
        "        x = self.relu(self.t2(x, output_size = [1,1,64,64]))\n",
        "        \n",
        "#         x = self.fc_layers(x)\n",
        "#         x = self.decode(x)\n",
        "        x = self.sig(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcPkIfhejHob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "4d60e795-d839-4abc-dd34-37216293845f"
      },
      "source": [
        "dat[0:1].shape\n",
        "plt.imshow(dat[0:1][0][0])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd28fec6fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBjc9ljPVX7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "7087e842-0c8f-4406-a6cc-35389716bd17"
      },
      "source": [
        "dat = initialise_dataset_HDF5_randn()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test = dummy_enc(1, [1,64,64]).double()\n",
        "test.eval()\n",
        "\n",
        "x = torch.zeros([1,1,64,64]).double()\n",
        "\n",
        "plt.imshow(x[0][0])\n",
        "plt.figure()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = x.double()\n",
        "#     print(test.type)\n",
        "    out = test(x)\n",
        "#     out.detatch()\n",
        "    print(out.dtype)\n",
        "    plt.imshow(out[0][0])\n",
        "    print(out.shape)\n",
        "    # why are all these values 0.5?\n",
        "    \n",
        "    print(out[0][0][4][14])\n",
        "    plt.figure()\n",
        "    plt.imshow(test(dat[0:1])[0][0])\n",
        "\n",
        " \n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-89a0455d7257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     print(test.type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     out.detatch()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-c012e0e215a5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#         print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [960 x 15], m2: [14400 x 5000] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:961"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TsjhNbQjaNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrVBqifRiQZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vSDtUciQbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gquXe4uDiQda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYz5eAPlr8gT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test = encoder(1, [1,64,64]).double()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pGufv6Ls_Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "\n",
        "# res = torch.autograd.gradcheck(test, (x,), eps=1e-4, raise_exception=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA6_5F3CsEQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test.eval()\n",
        "# res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy_kaggJzClW",
        "colab_type": "text"
      },
      "source": [
        "## troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lt9Wd7esG2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.zeros([1,1,64,64]).double()\n",
        "\n",
        "plt.imshow(x[0][0])\n",
        "plt.figure()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = x.double()\n",
        "#     print(test.type)\n",
        "    out = test(x)\n",
        "#     out.detatch()\n",
        "    print(out.dtype)\n",
        "    plt.imshow(out[0][0])\n",
        "    print(out.shape)\n",
        "    # why are all these values 0.5?\n",
        "    \n",
        "    print(out[0][0][4][14])\n",
        "    out1 = test.encode(x)\n",
        "    print(out1.shape)\n",
        "    plt.figure()\n",
        "    plt.imshow(out1[0][0])\n",
        "    # decode now\n",
        "    plt.figure()\n",
        "    out2 = test.decode(out1)\n",
        "    print(out2.shape)\n",
        "    plt.imshow(out2[0][0])\n",
        "    plt.figure()\n",
        "    plt.imshow(test(dat[0:1])[0][0])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJSpwPteZP-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHnyCUjKV6EZ",
        "colab_type": "text"
      },
      "source": [
        "# Modified moving MNIST dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vY-fr24V445",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_randn(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        # random index for subsampling. \n",
        "        rand_index = np.random.randint(10) # random index 0 - 9\n",
        "        \n",
        "#         predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i,rand_index]) # change to fancy indexing. \n",
        "        \n",
        "        return truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQB2-Ukmcljc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_randn(dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    dummy = np.array(list(range(dataset_length))) # clean this up - not really needed\n",
        "    \n",
        "    \n",
        "    \n",
        "    train_dataset = HDF5Dataset_randn(\"train_set.hdf5\", index_map = dummy)\n",
        "\n",
        "    \n",
        "    return train_dataset\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5jN8avuBQ0J",
        "colab_type": "text"
      },
      "source": [
        "## troubleshooting 2 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-rO4_qFdN3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAG9rTJCBS34",
        "colab_type": "code",
        "outputId": "d70cb3c3-1538-4d1d-924e-5136d9196a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "a = dat[0]\n",
        "b = dat[0]\n",
        "plt.imshow(a[0])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(b[0])\n",
        "a.shape\n",
        "\n",
        "t = nn.MSELoss()\n",
        "# b= torch.randn(a.shape).double()\n",
        "print(t(a,b))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.0607, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJciJb5YgJ75Zgpz4Zgn6f03c6V6LpfU7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncuKbJej/AMyy8dozkHoAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTU3Xc8d0up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # plt.imshow(dat[0:3][0][0])\n",
        "# with torch.no_grad():\n",
        "#     out = test(dat[0:1])\n",
        "# #     out.detatch()\n",
        "#     plt.imshow(out[0][0])\n",
        "#     print(out.shape)\n",
        "#     # why are all these values 0.5?\n",
        "    \n",
        "#     print(out[0][0][4][14])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6VyjOoLeEhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGfNsmRatncG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f9c8993-e00b-41e1-8f53-7220cf4610e5"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/masters_project/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWKtv8jyto5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37d37d76-f7c0-417e-9f24-8ebd922f1d16"
      },
      "source": [
        "%cd models"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8jUtGjIeUC0",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WUyxZuheVz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, data_loader, loss_func):\n",
        "    model.train()\n",
        "    loss_tot = 0\n",
        "    for x in data_loader:\n",
        "        x = x.to(device)\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        \n",
        "        loss = loss_func(pred[:][0], x[:][0])\n",
        "#         print(pred.dtype)\n",
        "#         print(x.dtype)\n",
        "#         print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_tot += loss\n",
        "#         print(loss_tot)\n",
        "\n",
        "    return loss_tot / 9000\n",
        "\n",
        "def train_full(batch_size, epochs = 30):\n",
        "#     model = (encoder(1, [1,64,64]).double()).to(device)\n",
        "    model = (dummy_enc(1, [1,64,64]).double()).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters()) # default learning rate\n",
        "    \n",
        "    dataset = initialise_dataset_HDF5_randn()\n",
        "    \n",
        "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "    \n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss() #not working for some reason. \n",
        "    \n",
        "    print(\"TRAINING START\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        loss_val = train(model, optimizer, dataloader, loss_func)\n",
        "        torch.save(optimizer.state_dict(), F\"dummy_Adam_encoder\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"dummy_encoder_\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        print(\"ENCODER LOSS:\" , loss_val.item())\n",
        "        \n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9h0o49NqAA9",
        "colab_type": "code",
        "outputId": "bec230bc-4b9f-484d-d2e2-96e4eeb44f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoNs2fZ4oRld",
        "colab_type": "code",
        "outputId": "ee0eddb9-67ee-40e8-e5bb-fb3bd30ba5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "enc = train_full(batch_size = 64)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "TRAINING START\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-66c372207bcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-105-91e63270d66c>\u001b[0m in \u001b[0;36mtrain_full\u001b[0;34m(batch_size, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mF\"dummy_Adam_encoder\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mF\"dummy_encoder_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-91e63270d66c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data_loader, loss_func)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-c012e0e215a5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#         print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [61440 x 15], m2: [14400 x 5000] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:268"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDY8zcpN--c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# plt.imshow(x[0][0])\n",
        "x = dat[0:1]\n",
        "plt.figure()\n",
        "x = x.cuda()\n",
        "with torch.no_grad():\n",
        "    x = x.double()\n",
        "#     print(test.type)\n",
        "    \n",
        "    \n",
        "    out = enc(x)\n",
        "#     out.detatch()\n",
        "    out  = out.cpu()\n",
        "    \n",
        "    x = x.cpu()\n",
        "    print(\"x:\")\n",
        "    plt.imshow(x[0][0])\n",
        "    print(\"outcome:\")\n",
        "    plt.figure()\n",
        "    \n",
        "    \n",
        "    plt.imshow(out[0][0])\n",
        "    \n",
        "#     print(out.dtype)\n",
        "#     plt.imshow(out[0][0])\n",
        "#     print(out.shape)\n",
        "#     # why are all these values 0.5?\n",
        "    \n",
        "#     print(out[0][0][4][14])\n",
        "#     out1 = enc.encode(x)\n",
        "#     print(out1.shape)\n",
        "#     plt.figure()\n",
        "#     plt.imshow(out1[0][0])\n",
        "#     # decode now\n",
        "#     plt.figure()\n",
        "#     out2 = enc.decode(out1)\n",
        "#     print(out2.shape)\n",
        "#     plt.imshow(out2[0][0])\n",
        "#     plt.figure()\n",
        "#     plt.imshow(enc(dat[0:1])[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEdxeAIOR-eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in enc.parameters():\n",
        "    print(i.size(), i.is_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}