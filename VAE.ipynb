{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/baseline_hybrid/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kCoGhlyfHLU",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFE8Oevpd134",
        "colab_type": "code",
        "outputId": "b0bd19fb-30fc-490b-e48c-7fef2c37469d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EpY3vbmfKCD",
        "colab_type": "code",
        "outputId": "b67bda83-4da2-43eb-88fb-35294924f865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# !ls\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from torchvision import models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibcwTlI1ohGd",
        "colab_type": "text"
      },
      "source": [
        "## cuda code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdEfZegwojD5",
        "colab_type": "code",
        "outputId": "90c59e2d-ba49-413c-ac64-b648d1416e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05LjGyTCfL0M",
        "colab_type": "text"
      },
      "source": [
        "# MODEL "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S2WAZkgfRPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alex_net = models.A\n",
        "# alex = models.alexnet(pretrained = True)\n",
        "\n",
        "# # make conditioned - give the decoder the last output of encoder as input.\n",
        "# class Enc_Dec(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Enc_Dec, self).__init__()\n",
        "        \n",
        "#         self."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWzjS6ZMux5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alex.features[0] = nn.Conv2d(1,64, kernel_size = (11,11), stride = (4,4), padding = (2,2))\n",
        "# for i, params in enumerate(alex.parameters()):\n",
        "#     if (i==1):\n",
        "#         print(params.data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR1BDEGSI1Qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8aPqCc_I1ln",
        "colab_type": "text"
      },
      "source": [
        "# Encoder\n",
        "NON VARIATIONAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTIl-oaCQwaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder(nn.Module):\n",
        "    def __init__(self, in_channels, image_dims):\n",
        "        super(encoder, self).__init__()\n",
        "        self.image_dims = image_dims # list of channels, height, width\n",
        "        self.in_chan = in_channels\n",
        "        \n",
        "        \"\"\"activations \"\"\"\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "        # need to decide how deep the input is\n",
        "        \"\"\"convolution encoding \"\"\"\n",
        "        self.c1 = nn.Conv2d(self.in_chan, 32, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.c2 = nn.Conv2d(32, 64, kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.c3 = nn.Conv2d(64, 128, kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.c4 = nn.Conv2d(128, 256, kernel_size = 4, stride = 3)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \"\"\" fully connected layer \"\"\"\n",
        "        \n",
        "        self.fc1 = nn.Linear(1024,128)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128,1024)\n",
        "        \n",
        "        self.fc3 = nn.Linear(1024,4096) # get rid of this one\n",
        "        \n",
        "        \"\"\" decoder convolution\"\"\"\n",
        "        # why does not having equal kernel sizes as above not effect it in this way?\n",
        "        \n",
        "#         self.t1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=1)\n",
        "        \n",
        "#         self.t2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        \n",
        "#         self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        \n",
        "#         self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=6, stride=2)\n",
        "        \n",
        "        self.t1 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=3)\n",
        "        \n",
        "        self.t2 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2)\n",
        "        \n",
        "        self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
        "        \n",
        "        self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=4, stride = 2)\n",
        "        \n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.relu(self.c1(x))\n",
        "        x = self.relu(self.c2(x))\n",
        "        x = self.relu(self.c3(x))\n",
        "        x = self.relu(self.c4(x))\n",
        "        return x\n",
        "    \n",
        "    def fc_layers(self, x):\n",
        "        #first we flatten\n",
        "        # -1 in pytorch view is the same as -1 in numpy reshape\n",
        "        x = x.view(x.size(0), -1) # using view terminology\n",
        "        \n",
        "        # fully connected layers\n",
        "        # this is an autoencoder with no variation, so no distribution sampling\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x) # get rid of this layer.\n",
        "        # x.size(0) allows for variable batch sizes.\n",
        "#         print(\"x shape debug\")\n",
        "#         print(x.shape)\n",
        "        size = 256 # size of flattened array going in?\n",
        "        x = x.view(x.size(0), size, 2, 2)\n",
        "#         x = x.view(-1, self.image_dims[0], self.image_dims[1], self.image_dims[2])\n",
        "        \n",
        "        # now we reshape the image back into the square. \n",
        "        return x\n",
        "    \n",
        "    def decode(self, x):\n",
        "#         print(x.shape)\n",
        "        dummy = torch.randn([1,1,64,64])\n",
        "        x = self.relu(self.t1(x))\n",
        "        x = self.relu(self.t2(x))\n",
        "        x = self.relu(self.t3(x))\n",
        "        x = self.relu(self.t4(x, output_size = dummy.size())) #  output_size = dummy.size())\n",
        "        return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "#         x = self.fc_layers(x)\n",
        "        x = self.decode(x)\n",
        "        x = self.sig(x)\n",
        "        return x\n",
        "    \n",
        "        \n",
        "        \n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-ZDnz22uOhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0327aac-ca5e-49e2-8344-4062c5e1cc98"
      },
      "source": [
        "7*128\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "896"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu0fK4PgghRm",
        "colab_type": "text"
      },
      "source": [
        "## dummy encoder \n",
        "for verification process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hll3c_zagksK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dummy_enc(nn.Module):\n",
        "    def __init__(self, in_channels, image_dims):\n",
        "        super(dummy_enc, self).__init__()\n",
        "        self.image_dims = image_dims # list of channels, height, width\n",
        "        self.in_chan = in_channels\n",
        "        \n",
        "        \"\"\"activations \"\"\"\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "        # need to decide how deep the input is\n",
        "        \"\"\"convolution encoding \"\"\"\n",
        "        self.c1 = nn.Conv2d(self.in_chan, 32, kernel_size = 4, stride = 1)\n",
        "        \n",
        "        self.c2 = nn.Conv2d(32, 64, kernel_size = 3, stride = 2)\n",
        "        \n",
        "        self.c3 = nn.Conv2d(64, 128, kernel_size = 4, stride = 2)\n",
        "        \n",
        "#         self.c4 = nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "#         self.t1 = nn.ConvTranspose2d(256,128, kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.t2 = nn.ConvTranspose2d(128,64, kernel_size = 4, stride = 2)\n",
        "        \n",
        "        self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2)\n",
        "\n",
        "        self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=4, stride=1)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "        \"\"\" fully connected layer \"\"\"\n",
        "        \n",
        "      \n",
        "#         self.fc1 = nn.Linear(14400,5000) # get rid of this one\n",
        "#         self.fc2 = nn.Linear(5000,14400)  \n",
        "        \"\"\" decoder convolution\"\"\"\n",
        "        # why does not having equal kernel sizes as above not effect it in this way?\n",
        "        \n",
        "#         self.t1 = nn.ConvTranspose2d(1024, 128, kernel_size=5, stride=1)\n",
        "        \n",
        "#         self.t2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2)\n",
        "        \n",
        "#         self.t3 = nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2)\n",
        "        \n",
        "#         self.t4 = nn.ConvTranspose2d(32, self.in_chan, kernel_size=6, stride=2)\n",
        "        \n",
        "        \n",
        "       \n",
        "\n",
        "    \n",
        "#     def encode(self, x):\n",
        "#         x = self.relu(self.c1(x))\n",
        "#         x = self.relu(self.c2(x))\n",
        "#         x = self.relu(self.c3(x))\n",
        "#         x = self.relu(self.c4(x))\n",
        "#         return x\n",
        "    \n",
        "#     def fc_layers(self, x):\n",
        "#         #first we flatten\n",
        "#         # -1 in pytorch view is the same as -1 in numpy reshape\n",
        "#         x = x.view(x.size(0), -1) # using view terminology\n",
        "        \n",
        "#         # fully connected layers\n",
        "#         # this is an autoencoder with no variation, so no distribution sampling\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = self.fc3(x) # get rid of this layer.\n",
        "#         # x.size(0) allows for variable batch sizes.\n",
        "# #         print(\"x shape debug\")\n",
        "# #         print(x.shape)\n",
        "#         size = 1024 # size of flattened array going in?\n",
        "#         x = x.view(x.size(0), size, 1, 1)\n",
        "# #         x = x.view(-1, self.image_dims[0], self.image_dims[1], self.image_dims[2])\n",
        "        \n",
        "#         # now we reshape the image back into the square. \n",
        "#         return x\n",
        "    \n",
        "#     def decode(self, x):\n",
        "# #         print(x.shape)\n",
        "#         dummy = torch.randn([1,1,64,64])\n",
        "#         x = self.relu(self.t1(x))\n",
        "#         x = self.relu(self.t2(x))\n",
        "#         x = self.relu(self.t3(x))\n",
        "#         x = self.relu(self.t4(x, output_size = dummy.size())) #  output_size = dummy.size())\n",
        "#         return x\n",
        "\n",
        "    def encode(self,x):\n",
        "        x = self.relu(self.c1(x))\n",
        "        x = self.relu(self.c2(x))\n",
        "        x = self.relu(self.c3(x))       \n",
        "        return x\n",
        "    \n",
        "    def decode(self, x):\n",
        "        x = self.relu(self.t2(x))\n",
        "        x = self.relu(self.t3(x))\n",
        "        x = self.relu(self.t4(x, output_size = [1,1,64,64]))\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        \n",
        "        # at this point is \n",
        "#         x = self.relu(self.c4(x))\n",
        "\n",
        "#         print(x.shape)\n",
        "#         x.view(x.size(0), -1)\n",
        "#         x = self.relu(self.fc1(x))\n",
        "#         x = self.relu(self.fc2(x))\n",
        "#         x.view(x.size(0), 64, 15, 15)\n",
        "#         x = self.relu(self.t1(x))\n",
        "\n",
        "        \n",
        "#         x = self.fc_layers(x)\n",
        "#         x = self.decode(x)\n",
        "        x = self.sig(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcPkIfhejHob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "64deb42b-b4d7-482a-e9a7-79751b90106c"
      },
      "source": [
        "dat[0:1].shape\n",
        "plt.imshow(dat[0:1][0][0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bea2b2d71b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH_ACIbH63jC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "a2010252-8f58-4769-e747-7949f4c6c19a"
      },
      "source": [
        "dat = initialise_dataset_HDF5_randn()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6557e294da8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialise_dataset_HDF5_randn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'initialise_dataset_HDF5_randn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eil7eHO7EUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test = dummy_enc(1, [1,64,64]).double()\n",
        "test.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBjc9ljPVX7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = torch.randn([1,1,64,64]).double()\n",
        "\n",
        "plt.imshow(x[0][0])\n",
        "plt.figure()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = x.double()\n",
        "#     print(test.type)\n",
        "    out = test(x)\n",
        "#     out.detatch()\n",
        "    print(out.dtype)\n",
        "    plt.imshow(out[0][0])\n",
        "    print(out.shape)\n",
        "    # why are all these values 0.5?\n",
        "    \n",
        "    print(out[0][0][4][14])\n",
        "    plt.figure()\n",
        "    plt.imshow(test(dat[0:1])[0][0])\n",
        "    plt.title(\"test\")\n",
        "    \n",
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TsjhNbQjaNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrVBqifRiQZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vSDtUciQbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gquXe4uDiQda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYz5eAPlr8gT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test = encoder(1, [1,64,64]).double()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pGufv6Ls_Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "\n",
        "# res = torch.autograd.gradcheck(test, (x,), eps=1e-4, raise_exception=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA6_5F3CsEQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test.eval()\n",
        "# res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy_kaggJzClW",
        "colab_type": "text"
      },
      "source": [
        "## troubleshooting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lt9Wd7esG2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.zeros([1,1,64,64]).double()\n",
        "\n",
        "plt.imshow(x[0][0])\n",
        "plt.figure()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = x.double()\n",
        "#     print(test.type)\n",
        "    out = test(x)\n",
        "#     out.detatch()\n",
        "    print(out.dtype)\n",
        "    plt.imshow(out[0][0])\n",
        "    print(out.shape)\n",
        "    # why are all these values 0.5?\n",
        "    \n",
        "    print(out[0][0][4][14])\n",
        "    out1 = test.encode(x)\n",
        "    print(out1.shape)\n",
        "    plt.figure()\n",
        "    plt.imshow(out1[0][0])\n",
        "    # decode now\n",
        "    plt.figure()\n",
        "    out2 = test.decode(out1)\n",
        "    print(out2.shape)\n",
        "    plt.imshow(out2[0][0])\n",
        "    plt.figure()\n",
        "    plt.imshow(test(dat[0:1])[0][0])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJSpwPteZP-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHnyCUjKV6EZ",
        "colab_type": "text"
      },
      "source": [
        "# Modified moving MNIST dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vY-fr24V445",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_randn(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        # random index for subsampling. \n",
        "        rand_index = np.random.randint(10) # random index 0 - 9\n",
        "        \n",
        "#         predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i,rand_index]) # change to fancy indexing. \n",
        "        \n",
        "        return truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQB2-Ukmcljc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_randn(dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    dummy = np.array(list(range(dataset_length))) # clean this up - not really needed\n",
        "    \n",
        "    \n",
        "    \n",
        "    train_dataset = HDF5Dataset_randn(\"train_set.hdf5\", index_map = dummy)\n",
        "\n",
        "    \n",
        "    return train_dataset\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5jN8avuBQ0J",
        "colab_type": "text"
      },
      "source": [
        "## troubleshooting 2 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-rO4_qFdN3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAG9rTJCBS34",
        "colab_type": "code",
        "outputId": "c0d61fc1-1c19-4395-806f-850ceef0ed9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "a = dat[0]\n",
        "b = dat[0]\n",
        "plt.imshow(a[0])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(b[0])\n",
        "a.shape\n",
        "\n",
        "t = nn.MSELoss()\n",
        "# b= torch.randn(a.shape).double()\n",
        "print(t(a,b))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-aa99fca3bd61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTU3Xc8d0up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # plt.imshow(dat[0:3][0][0])\n",
        "# with torch.no_grad():\n",
        "#     out = test(dat[0:1])\n",
        "# #     out.detatch()\n",
        "#     plt.imshow(out[0][0])\n",
        "#     print(out.shape)\n",
        "#     # why are all these values 0.5?\n",
        "    \n",
        "#     print(out[0][0][4][14])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6VyjOoLeEhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGfNsmRatncG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56ba4d0d-1f20-45ed-b43a-5c3e0610c8bd"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/masters_project/data/models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thd0B4OMA4Uu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "438e0088-0f37-4582-b13f-15ee1eba3918"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldx0otlkA79-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57000277-ca8c-4eec-b799-1609124f98ac"
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".   .bash_history  .cache   .gsutil   .jupyter\t.local\t   .npm  .profile\n",
            "..  .bashrc\t   .config  .ipython  .keras\t.node-gyp  .nv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWKtv8jyto5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db13d359-544f-4723-e9ad-e71db9d06c32"
      },
      "source": [
        "\n",
        "%cd /content/drive/My Drive/masters_project/data/models"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8jUtGjIeUC0",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WUyxZuheVz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, data_loader, loss_func):\n",
        "    model.train()\n",
        "    loss_tot = 0\n",
        "    for x in data_loader:\n",
        "        x = x.to(device)\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        \n",
        "        loss = loss_func(pred[:][0], x[:][0])\n",
        "#         print(pred.dtype)\n",
        "#         print(x.dtype)\n",
        "#         print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_tot += loss\n",
        "#         print(loss_tot)\n",
        "\n",
        "    return loss_tot / 9000\n",
        "\n",
        "def train_full(batch_size, epochs = 20):\n",
        "#     model = (encoder(1, [1,64,64]).double()).to(device)\n",
        "    model = (dummy_enc(1, [1,64,64]).double()).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters()) # default learning rate\n",
        "    \n",
        "    dataset = initialise_dataset_HDF5_randn()\n",
        "    \n",
        "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "    \n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss() #not working for some reason. \n",
        "    \n",
        "    print(\"TRAINING START\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        loss_val = train(model, optimizer, dataloader, loss_func)\n",
        "        torch.save(optimizer.state_dict(), F\"dummy_Adam_encoder\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"dummy_encoder_\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        print(\"ENCODER LOSS:\" , loss_val.item())\n",
        "        \n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9h0o49NqAA9",
        "colab_type": "code",
        "outputId": "830ad1cb-c785-4500-f893-93981a40630d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoNs2fZ4oRld",
        "colab_type": "code",
        "outputId": "dc92dd77-ffb2-48ab-ef6f-80f4ca7868ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "enc = train_full(batch_size = 128)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "TRAINING START\n",
            "ENCODER LOSS: 0.008934224473602589\n",
            "ENCODER LOSS: 0.008660914811404104\n",
            "ENCODER LOSS: 0.008603907470213407\n",
            "ENCODER LOSS: 0.008617137827783119\n",
            "ENCODER LOSS: 0.008414251821328888\n",
            "ENCODER LOSS: 0.008561229640085124\n",
            "ENCODER LOSS: 0.008621505850239394\n",
            "ENCODER LOSS: 0.008507791755026564\n",
            "ENCODER LOSS: 0.008449938738930683\n",
            "ENCODER LOSS: 0.008369806546302058\n",
            "ENCODER LOSS: 0.00850158179715758\n",
            "ENCODER LOSS: 0.008577435936114692\n",
            "ENCODER LOSS: 0.008730864167096392\n",
            "ENCODER LOSS: 0.008676166053528521\n",
            "ENCODER LOSS: 0.008702840965673666\n",
            "ENCODER LOSS: 0.008805282943895824\n",
            "ENCODER LOSS: 0.008503717353313544\n",
            "ENCODER LOSS: 0.008265956761293033\n",
            "ENCODER LOSS: 0.008505478456979798\n",
            "ENCODER LOSS: 0.008809057981704034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDY8zcpN--c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "89a75c99-3861-43d6-8dcd-e0b2053f53fa"
      },
      "source": [
        "\n",
        "# plt.imshow(x[0][0])\n",
        "dat = initialise_dataset_HDF5_randn()\n",
        "enc.eval()\n",
        "x = dat[200:201]\n",
        "plt.figure()\n",
        "x = x.cuda()\n",
        "with torch.no_grad():\n",
        "    x = x.double()\n",
        "#     print(test.type)\n",
        "    \n",
        "    \n",
        "    out = enc(x)\n",
        "#     out.detatch()\n",
        "    out  = out.cpu()\n",
        "    \n",
        "    x = x.cpu()\n",
        "    print(\"x:\")\n",
        "    plt.imshow(x[0][0])\n",
        "    print(\"outcome:\")\n",
        "    plt.figure()\n",
        "    \n",
        "    \n",
        "    plt.imshow(out[0][0])\n",
        "    \n",
        "#     print(out.dtype)\n",
        "#     plt.imshow(out[0][0])\n",
        "#     print(out.shape)\n",
        "#     # why are all these values 0.5?\n",
        "    \n",
        "#     print(out[0][0][4][14])\n",
        "#     out1 = enc.encode(x)\n",
        "#     print(out1.shape)\n",
        "#     plt.figure()\n",
        "#     plt.imshow(out1[0][0])\n",
        "#     # decode now\n",
        "#     plt.figure()\n",
        "#     out2 = enc.decode(out1)\n",
        "#     print(out2.shape)\n",
        "#     plt.imshow(out2[0][0])\n",
        "#     plt.figure()\n",
        "#     plt.imshow(enc(dat[0:1])[0][0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "x:\n",
            "outcome:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE+VJREFUeJzt3XmQXWWZx/Hvr5POypqAsUmQRJNA\nkJJEM+w6LCIIFDAMi+BYUaJRJwqMiIJTg1KDUzqjIDPjUJMBNE4hm4IwQAEhAoJiSCIBsoDEEIrE\nhEZM2AlZnvnjnpx7T9udvp2+S3fe36cq1c973nPveSq3nz7vWe57FBGYWVpamp2AmTWeC98sQS58\nswS58M0S5MI3S5AL3yxBLnyzBPWq8CUdL+kZScslXVyrpMysvrS9N/BIGgD8HjgWWAXMB86OiKW1\nS8/M6mFgL157ELA8IlYASLoROAXosvAHaXAMYXgvNmlm2/I2b/BObFB36/Wm8EcDL1S0VwEHb+sF\nQxjOwTqmF5s0s22ZF3OrWq83hV8VSTOAGQBDGFbvzZlZFXpzcm81sHdFe0y2rCAiZkXE1IiY2srg\nXmzOzGqlN4U/H5ggaZykQcAngDtqk5aZ1dN2D/UjYpOkLwH3AgOA6yJiSc0yM7O66dUxfkTcDdxd\no1zMrEF8555Zglz4Zgly4ZslyIVvliAXvlmCXPhmCXLhmyXIhW+WIBe+WYJc+GYJcuGbJciFb5Yg\nF75Zglz4Zgly4ZslyIVvliAXvlmCXPhmCXLhmyXIhW+WoLo/UMOsP9jy4Sl5vPKkIYW+s457JI8v\nf9dThb5PPHd0Hr96SvnJVZv/9HKtU6wp7/HNEuTCN0uQC98sQT7Gtx3agEkT8vi5s/bM43NPv7ew\n3md2/c883rWleIzfQvnYfWNEoe/6sffn8ZEf+WIeD7u1nx/jS7pOUrukxRXLRkiaI+nZ7Ofu9U3T\nzGqpmqH+j4HjOyy7GJgbEROAuVnbzPqJbof6EfErSWM7LD4FODKLZwMPAl+vYV5mXdry11MK7ZUf\nLw/Nd5q0rtD326n/m8ctFfu5yuE7wBaKw/tqtW9+M4+HvPzOdr1HM2zvyb1REbEmi9cCo2qUj5k1\nQK/P6kdEANFVv6QZkhZIWrCRDb3dnJnVwPae1X9RUltErJHUBrR3tWJEzAJmAeyiEV3+gTDblucv\nOyyP7//Mvxb62gYM28YrB1T1/i9ufiuPV20aWug7+6HP5fGYO4ols/PTf87jlmWPV7WtvmB79/h3\nANOyeBpwe23SMbNGqOZy3g3Ao8C+klZJmg58BzhW0rPAR7O2mfUT1ZzVP7uLrmNqnIuZNYjv3LN+\n4WMnzs/jjsf0WyrOLf/lZbpy321vjMjjf7rlnMJ6+9xVviyn3zxR6JvIwi7z2rytpPsw36tvliAX\nvlmCPNS3fuHuZw7I4++3/bbQ92aU75ibMndmoW/o0+U78va55tk8HvvSo7VOsV/xHt8sQS58swS5\n8M0S5GN86xeuOWR2l30/eWW/PJ4w7XddrtdfL73Vg/f4Zgly4ZslyEN967Ne+sKheXzokPkVPd5f\n9Zb/B80S5MI3S5CH+tZn7XLamjweuI0JNfYd/Mc8vmfsgYW+NyaVZ4Vbt29ruaP4XR5eG18+59/2\nULFzp5uLdwruCLzHN0uQC98sQS58swT5GN/6jAHv37fQ/sI+9+Xxlq4ncuaooW/n8WGP3Fzoa1X5\n3MC259Uvv/+WU7cU+qZMPD+P9778N13m0Z94j2+WIBe+WYI81Lc+Y9JPni20/3anP/X4PYZqUKFd\nOYSvnLDjobdGFtb7afsheXzsiKWFvp9/9nt5fOGtny70bV76+x7n2Bd4j2+WIBe+WYJc+GYJ8jG+\n9Rkf3On5QrvjJbeurKl4VPVla44r9M1dUJ6kc9K/vJDHm1b/kaLyM/CuPevUQs+nr/ivPF725d0K\nfRO/WFWKfU41j9DaW9IDkpZKWiLp/Gz5CElzJD2b/dy9/umaWS1UM9TfBFwYEfsDhwAzJe0PXAzM\njYgJwNysbWb9QDXPzlsDrMni1yQtA0YDpwBHZqvNBh4Evl6XLC0Jl959RqF90hlX5vGwist0ayoe\naQ1w2j9flMcj/6c4X/4E5uXxphrkOHpczy8x9kU9OrknaSwwBZgHjMr+KACsBUZ18TIz62OqLnxJ\nOwE/By6IiFcr+yIioPObqSXNkLRA0oKNbOhVsmZWG1UVvqRWSkV/fUTcmi1+UVJb1t8GtHf22oiY\nFRFTI2JqK4NrkbOZ9VK3x/iSBFwLLIuIKyq67gCmAd/Jft5elwwtGeP/oTjTzSlzzsvj10eXf1VH\nzVldWG/kyto+B2/NkVu6X6mfq+Y6/uHAp4CnJC3Kln2DUsHfLGk68DxwZn1SNLNaq+as/iP8xQxl\nuWNqm46ZNYLv3LM+a/Dd5bn0K88O1eKyXEdvnXpQHj984hUdeofVYYvN5Xv1zRLkwjdLkIf61me0\nDCsOqTceVH4K7sA3NuZxzH+q5ttedWp5Xv1RA4Z2ud66h95daA9nRc1zaQTv8c0S5MI3S5AL3yxB\nPsa3pmo5cFIef/aWuwp9Hx46J48/vbz8zb24YBLbY8UZ5Uk0jj3ud4W+29quLufUoSwefrvcfs+V\nxdf113v8vMc3S5AL3yxBHupbU702fpc8PnX4+g695ctq/zfxzvLiu+uRSbkUOj6ua8bNn8/jcW/X\n9gtBzeI9vlmCXPhmCXLhmyXIx/jWVLs8VZ68cuE7mwt9Hxo0oOPqdTN/Q/m4ftr1Xyr0jfvmYw3L\no1G8xzdLkAvfLEEqTZDbGLtoRBwsT9pjndvy4SmF9rr9huTxK0eV59Kf8p4XCutdP+6+qt7/h+vf\nl8f/fv/xhb62R8p18MrZr1f1fgBS+XWvvzQ8jydd8ofieq2tefzOhL0KfS0PP1719rozL+byavy5\n22ePeY9vliAXvlmCPNS3fuHNvzk4j4fdNq/QF4dPzuPnZhZfd9fhP8zjfQaWH8PV0mGft2U7v25T\n+T6V73Fp+18V1hsx8I08vmDE0kLfyaOL6/aGh/pm1iUXvlmCXPhmCfIxvvUZf7zosEL7rE/9Mo9n\n7l6eAOPqdcXLfifs/GQeTxpU3b6s3sf423Lgr88ttPc5s3aTh9bsGF/SEEmPSXpC0hJJl2XLx0ma\nJ2m5pJukigeYm1mfVs2fxw3A0RFxIDAZOF7SIcB3gSsjYjywDphevzTNrJaqeXZeAFtvZWrN/gVw\nNHBOtnw28C3g6o6vN9uWOPTAPJ573r8V+nZtqRxElu98u2hk8XLYlj54quobaw8utN89+JU8ft9F\nxQlH6vFIsO5U9T8maUD2pNx2YA7wB2B9RGzNeRUwuj4pmlmtVVX4EbE5IiYDY4CDgP26eUlO0gxJ\nCyQt2MiG7UzTzGqpR2OkiFgPPAAcCuwmaeuhwhhgdRevmRURUyNiamvhmadm1izdHuNL2hPYGBHr\nJQ0FjqV0Yu8B4HTgRmAacHs9E7UdX8e9UMdLblu1qjhBx8Yqr0g/tqF8levcn87cxppF4/+7/G3A\nTS+sqvJVxUt7i9m5olX8dmEzVDMDTxswW9IASp/NzRFxp6SlwI2SLgceB66tY55mVkPVnNV/EpjS\nyfIVlI73zayf8Z171mcMfWhUoX3T+Ds7XW9777o77bDT8njT880fbteDv51nZl1y4ZslyNNrW5/x\n+reK94BNu/y4PJ499t5ev//uN7yWx3/+3L6Fvs1Lnun1+/cn3uObJciFb5YgF75Zgnw5z/qsDSeW\nJ6F86dw383jRIT8prLc9k2jUczKMZvLlPDPrkgvfLEEe6lu/03JA8VvhK79ZnqRj0WHXVfUemzv8\n3r//jvITcif+ff99Oq6H+mbWJRe+WYJc+GYJ8i271u9sWfx0of2eM8rxBy4/r9D3i7/7fh6Pby3P\nADW4pTiZx/QjfpXHDzOEHZ33+GYJcuGbJciX86yhBuy5Z6H99KXvzeMJX57XcfVe23T0h/L4mh9d\nlcdjBg4trLfknfLs9mfecEGhb9w3Hq15XvXiy3lm1iUXvlmCfFbfGmrl5ycU2vecXH5s1jmLvlro\nG3ltz4fYA0fvVWjv/s/P5fFeA7t+rkPlU3Y3DW/c4W+zeI9vliAXvlmCXPhmCfIxvjXUdef+R6G9\nz8Dyo7BPO/+Xhb5f3zU2jzetfTGPXzzvsMJ6LR99OY8v3Pf+Qt/pO63tcY4HTF5ZaO+Ij3qteo+f\nPSr7cUl3Zu1xkuZJWi7pJkmDunsPM+sbejLUPx9YVtH+LnBlRIwH1gHTa5mYmdVPVUN9SWOAE4Fv\nA1+RJOBo4JxsldnAt4Cr65Cj7UA+1OGKWuVseReOXFzo++ij5fabW8ovPHzIwg7v0fM59zqat6E8\nmcdbl7YV+lro+eFCX1ftHv8HwNcof04jgfURsfU+x1XA6M5eaGZ9T7eFL+kkoD0iFna3bhevnyFp\ngaQFG3fI0yRm/U81Q/3DgZMlnQAMAXYBrgJ2kzQw2+uPAVZ39uKImAXMgtKXdGqStZn1SreFHxGX\nAJcASDoS+GpEfFLSLcDpwI3ANOD2OuZpO4j9bppZaD9y+vfyeI8BxW/MTSlcJ9qYR60qTqKxcTt2\nJ49uKL7Ht987OY9beLznb9jP9OYGnq9TOtG3nNIx/7W1ScnM6q1HN/BExIPAg1m8Ajio9imZWb35\nzj1rqPFf+W2hfezYz+fxwoN/XNV7dBzab+ty3jWvlCf6eN+g9jz+4n3TCutNpP/Opb89fK++WYJc\n+GYJ8lDfmmqv75V/Bacefn6hb9xJK/L4hD3LT7O956UDCus9uWhcHrfsUbxXZOJ5z5cb7y5/uWfi\nkrSG9h15j2+WIBe+WYJc+GYJ8rz61i8M3HtMHm96YVUTM+nbPK++mXXJhW+WIF/Os37Bw/va8h7f\nLEEufLMEufDNEuTCN0uQC98sQS58swS58M0S5MI3S5AL3yxBLnyzBLnwzRLkwjdLkAvfLEEufLME\nVfW1XEkrgdeAzcCmiJgqaQRwEzAWWAmcGRHr6pOmmdVST/b4R0XE5IiYmrUvBuZGxARgbtY2s36g\nN0P9U4DZWTwbOLX36ZhZI1Rb+AHcJ2mhpBnZslERsSaL1wKjap6dmdVFtVNvHRERqyW9C5gj6enK\nzogISZ1O15v9oZgBMIRhvUrWzGqjqj1+RKzOfrYDt1F6PPaLktoAsp/tXbx2VkRMjYiprQyuTdZm\n1ivdFr6k4ZJ23hoDHwMWA3cAW581PA24vV5JmlltVTPUHwXcJmnr+j+NiHskzQduljQdeB44s35p\nmlktdVv4EbECOLCT5S8DfiyOWT/kO/fMEuTCN0uQC98sQS58swS58M0S5MI3S5AL3yxBLnyzBLnw\nzRLkwjdLkAvfLEEufLMEufDNEuTCN0uQC98sQS58swS58M0S5MI3S5AL3yxBLnyzBLnwzRLkwjdL\nkAvfLEEufLMEufDNElRV4UvaTdLPJD0taZmkQyWNkDRH0rPZz93rnayZ1Ua1e/yrgHsiYj9Kj9Na\nBlwMzI2ICcDcrG1m/UA1T8vdFfgIcC1ARLwTEeuBU4DZ2WqzgVPrlaSZ1VY1e/xxwEvAjyQ9Luma\n7HHZoyJiTbbOWkpP1TWzfqCawh8IfBC4OiKmAG/QYVgfEQFEZy+WNEPSAkkLNrKht/maWQ1UU/ir\ngFURMS9r/4zSH4IXJbUBZD/bO3txRMyKiKkRMbWVwbXI2cx6qdvCj4i1wAuS9s0WHQMsBe4ApmXL\npgG31yVDM6u5gVWu92XgekmDgBXAZyj90bhZ0nTgeeDM+qRoZrVWVeFHxCJgaiddx9Q2HTNrBN+5\nZ5YgF75Zglz4Zgly4ZslyIVvliAXvlmCXPhmCVLpNvsGbUx6idLNPnsAf2rYhjvXF3IA59GR8yjq\naR77RMSe3a3U0MLPNyotiIjObghKKgfn4TyalYeH+mYJcuGbJahZhT+rSdut1BdyAOfRkfMoqkse\nTTnGN7Pm8lDfLEENLXxJx0t6RtJySQ2blVfSdZLaJS2uWNbw6cEl7S3pAUlLJS2RdH4zcpE0RNJj\nkp7I8rgsWz5O0rzs87kpm3+h7iQNyOZzvLNZeUhaKekpSYskLciWNeN3pCFT2Tes8CUNAH4IfBzY\nHzhb0v4N2vyPgeM7LGvG9OCbgAsjYn/gEGBm9n/Q6Fw2AEdHxIHAZOB4SYcA3wWujIjxwDpgep3z\n2Op8SlO2b9WsPI6KiMkVl8+a8TvSmKnsI6Ih/4BDgXsr2pcAlzRw+2OBxRXtZ4C2LG4DnmlULhU5\n3A4c28xcgGHA74CDKd0oMrCzz6uO2x+T/TIfDdwJqEl5rAT26LCsoZ8LsCvwHNm5t3rm0cih/mjg\nhYr2qmxZszR1enBJY4EpwLxm5JINrxdRmiR1DvAHYH1EbMpWadTn8wPga8CWrD2ySXkEcJ+khZJm\nZMsa/bk0bCp7n9xj29OD14OknYCfAxdExKvNyCUiNkfEZEp73IOA/eq9zY4knQS0R8TCRm+7E0dE\nxAcpHYrOlPSRys4GfS69msq+JxpZ+KuBvSvaY7JlzVLV9OC1JqmVUtFfHxG3NjMXgCg9FekBSkPq\n3SRtnYexEZ/P4cDJklYCN1Ia7l/VhDyIiNXZz3bgNkp/DBv9ufRqKvueaGThzwcmZGdsBwGfoDRF\nd7M0fHpwSaL0KLJlEXFFs3KRtKek3bJ4KKXzDMso/QE4vVF5RMQlETEmIsZS+n34ZUR8stF5SBou\naeetMfAxYDEN/lyikVPZ1/ukSYeTFCcAv6d0PPmPDdzuDcAaYCOlv6rTKR1LzgWeBe4HRjQgjyMo\nDdOeBBZl/05odC7AB4DHszwWA5dmy98LPAYsB24BBjfwMzoSuLMZeWTbeyL7t2Tr72aTfkcmAwuy\nz+YXwO71yMN37pklyCf3zBLkwjdLkAvfLEEufLMEufDNEuTCN0uQC98sQS58swT9PzhwMmDLSMhM\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuzHvIdKGt8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f74edd43-b6c6-4899-d786-a669621ef1e9"
      },
      "source": [
        "%pwd\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/masters_project/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEdxeAIOR-eJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "394b3ffc-d7a3-451f-c037-8ec8b1ab0d8f"
      },
      "source": [
        "for i in enc.parameters():\n",
        "    print(i.size(), i.is_cuda)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 4, 4]) True\n",
            "torch.Size([32]) True\n",
            "torch.Size([64, 32, 3, 3]) True\n",
            "torch.Size([64]) True\n",
            "torch.Size([128, 64, 4, 4]) True\n",
            "torch.Size([128]) True\n",
            "torch.Size([128, 64, 4, 4]) True\n",
            "torch.Size([64]) True\n",
            "torch.Size([64, 32, 3, 3]) True\n",
            "torch.Size([32]) True\n",
            "torch.Size([32, 1, 4, 4]) True\n",
            "torch.Size([1]) True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C-vidbZELYp",
        "colab_type": "text"
      },
      "source": [
        "# LSTM inherited model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9taF12fENb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class LSTM_basis(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(LSTM_basis, self).__init__()\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}