{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdjQiLORit87",
        "colab_type": "text"
      },
      "source": [
        "Notebook for testing and visualising the trained models, instead of just editing in and out of the other note books. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1hCBBflpPE",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNCK1plivBa",
        "colab_type": "code",
        "outputId": "23f2eff3-2322-4487-cd4b-d99d92c9b1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pw1B9CRiq4b",
        "colab_type": "code",
        "outputId": "c7317829-ce55-4beb-cfd3-192338bdf948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.5)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=0d79eddedb6ce64e5a9493fea4bde2d35df228912b9767eee55e6878bc0dec89\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dROspCb3F4Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score, average_precision_score\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfGC8lSoPcJ-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjvzMDSmjvm",
        "colab_type": "code",
        "outputId": "007e9739-2831-4c0f-b313-e4ada2d1a925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.321s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GFSfjbmn9p",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng6nuRUemmId",
        "colab_type": "code",
        "outputId": "2749115a-1ca3-46f8-e3c9-bc3ce8414ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6ygxsDfm13g",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrqiJO2m3r7",
        "colab_type": "text"
      },
      "source": [
        "## LSTM CELL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABn4VwLm1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XqL4TQZm9ux",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Full Unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_4SSRxnrvii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6r5pzTnEp1",
        "colab_type": "text"
      },
      "source": [
        "## lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f9sKamnGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3OsS3LnJST",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OliGMQernKxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhOY6M2nNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaaxPlgInPbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_index = list(train_index)\n",
        "        \n",
        "        valid_index = list(valid_index)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgXbH9ufnRUQ",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeG22ZLUnSwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtVqEhenUxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-ycpijnWaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJNW6pcnYVS",
        "colab_type": "text"
      },
      "source": [
        "# training functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-1ba_mnaMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88roEYKncdq",
        "colab_type": "code",
        "outputId": "702b9421-2cf1-4ec5-ea1e-66117e542217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Qh0HFanfZd",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMIqmhTng9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "#         truth -= self.avg[0]\n",
        "#         truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxJN-sRn2Vx",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxHgHdoYn3qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7, threshold = 0.5):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     print(x[sample][0][0])\n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"sample\"+ str(sample) + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    plt.figure()\n",
        "    x[sample][0][0][threshold > x[sample][0][0]] = 0\n",
        "    plt.imshow(x[sample][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])\n",
        "    \n",
        "    fig.suptitle(\"Preceding sequence of: \" + name)\n",
        "    fig.savefig(name + \"sample\"+ str(sample) + \"preceding.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LLyGvaoTug",
        "colab_type": "text"
      },
      "source": [
        "## batch loss histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv6Zf6jzoVwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader, loss_func):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        #loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bWfVt3njrM",
        "colab_type": "text"
      },
      "source": [
        "#wrapper\n",
        "\n",
        "not put in "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1EsNMannU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7deYNPMonjoJ",
        "colab_type": "text"
      },
      "source": [
        "# code imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOBUBX2nvPV",
        "colab_type": "code",
        "outputId": "bffaf616-d9ac-4656-8819-4ef7283f5300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 5).to(device)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZFoI1Sk0On",
        "colab_type": "code",
        "outputId": "f829aa8a-7a96-474f-d48e-de1e30fb6fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "\n",
        "f = h5py.File('test_next_event.hdf5','r')\n",
        "print(f['predictor'].shape)\n",
        "f.close()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "(4624, 10, 5, 16, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFSO4IMoDo9",
        "colab_type": "text"
      },
      "source": [
        "## code loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38-COzcpoJe0",
        "colab_type": "code",
        "outputId": "a1237b01-5b7d-413f-e17d-20130670b7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\"\"\"now changed to fixed dataset\"\"\"\n",
        "\n",
        "avg = np.load(\"next_event_avg.npy\")\n",
        "std = np.load(\"next_event_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,1,1,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('test_next_event.hdf5', valid_frac = 0.1, dataset_length = 4624,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiIZuUAQoNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train, batch_size = 4000, shuffle = False) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMjpjcSxFTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"diff_pred_2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7B7f3ui0h_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgFsBi6oE2l",
        "colab_type": "code",
        "outputId": "0c7dd1fc-1b70-426b-ce0b-441768184dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 3)).to(device) # added data parrallel\n",
        "\n",
        "test_model.load_state_dict(torch.load(name + \".pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7lJB7uoIO7",
        "colab_type": "text"
      },
      "source": [
        "loading in averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m-yzx0WopWO",
        "colab_type": "code",
        "outputId": "80e01c4b-1c8f-4b32-fc44-d9f6ed9c1d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_image_save(test_model, train_loader, name + \"comparison\", sample = 15, threshold = 0)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n",
            "torch.Size([4000, 1, 5, 16, 16])\n",
            "torch.Size([4000, 16, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD1CAYAAABX2p5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\newAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAAfRCAYAAAC6ShHyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 2304x2304 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qceaV2m7ZdHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def f1(model, train_loader, avg = 'macro'):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "    x = x.cpu()\n",
        "    x[x>0] = 1\n",
        "    x[0>x] = 0\n",
        "#     print(x[0][0][0])\n",
        "    print(x[222,0,0].shape)\n",
        "    print(b[222].shape)\n",
        "#     print(b)\n",
        "    print(b[222].view(-1, 256).numpy().shape)\n",
        "    truth = set(list(b[222].view(256).numpy()))\n",
        "    pred = set(list(x[222,0,0].view(256).numpy()))\n",
        "    print(truth - pred)\n",
        "    scores = []\n",
        "    for i in range(len(b)):\n",
        "        score = f1_score(b[i].view(256).numpy(), x[i,0,0].view(256).numpy(), average=avg)\n",
        "        scores.append(score)\n",
        "        truth = set(list(b[i].view(256).numpy()))\n",
        "        pred = set(list(x[i,0,0].view(256).numpy()))\n",
        "        if len(truth - pred) > 0:\n",
        "            print(i)\n",
        "#     score = f1_score(b[222].numpy(), b[222].numpy(), average=avg)\n",
        "    return scores\n",
        "#     print(score)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     print(x[sample][0][0])\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSKhzR5rvPov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(model, train_loader, name = 'default', verbose = True, save = True, threshold = 0.4):\n",
        "    \"\"\"Calculate TN, FN, TP, FP for multilabel classification\"\"\"\n",
        "    model.eval()\n",
        "    sig = nn.Sigmoid()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "    x = x.cpu()\n",
        "    x = sig(x)\n",
        "    \n",
        "    x[x>threshold] = 1\n",
        "    x[threshold>x] = 0\n",
        "    \n",
        "    # reshape\n",
        "    truth = b.view(-1,256).numpy()\n",
        "    pred = x[:,0,0].view(-1,256).numpy()\n",
        "    tn = 0\n",
        "    tp = 0\n",
        "    fn = 0 \n",
        "    fp = 0\n",
        "    \n",
        "    print(truth.shape)\n",
        "    print(pred.shape)\n",
        "    for i in range(len(b)):\n",
        "        for j in range(256):\n",
        "            # true positive\n",
        "            if (truth[i][j] == 1) and (pred[i][j] == 1):\n",
        "                tp += 1\n",
        "            # true negative\n",
        "            if (truth[i][j] == 0) and (pred[i][j] == 0):\n",
        "                tn += 1\n",
        "            \n",
        "            #false positive\n",
        "            if (truth[i][j] == 0) and (pred[i][j] == 1):\n",
        "                fp +=1\n",
        "            #false negative\n",
        "            if (truth[i][j] == 1) and (pred[i][j] == 0):\n",
        "                fn += 1\n",
        "\n",
        "    prec = tp / (tp + fp)\n",
        "    rec = tp/ (tp + fn)\n",
        "    \n",
        "    f_1 = 2 * prec * rec / (prec + rec)                \n",
        "                \n",
        "    if verbose:\n",
        "        print(\"tn:\" ,tn)\n",
        "        print(\"tp:\" , tp)\n",
        "        print(\"fn:\" , fn)\n",
        "        print(\"fp\" ,fp)\n",
        "        print(\"prec:\" ,prec)\n",
        "        print(\"rec:\" , rec)\n",
        "        print(\"f1: \", f_1)\n",
        "    \n",
        "    if save:\n",
        "        f = open(name + \"metrics.csv\", 'w')\n",
        "        for i in [tn, tp, fn, fp, prec, rec, f_1]:\n",
        "        \n",
        "            f.write(str(i) + \"\\n\")\n",
        "\n",
        "        f.close()\n",
        "    \n",
        "                \n",
        "            \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6iVIEUNEPR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def area_under_curve_metrics(model, train_loader, name = 'default', verbose = True, save = True):\n",
        "    sig = nn.Sigmoid()\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "        \n",
        "    x = x.cpu()\n",
        "    truth = b.view(-1,256).numpy()\n",
        "    pred = sig(x[:,0,0].view(-1,256)).numpy()\n",
        "#     truth = b.contiguous().view(-1).numpy()\n",
        "#     pred = sig(x[:,0,0].contiguous().view(-1)).numpy()\n",
        "#     fpr, tpr, thresholds = roc_curve(truth, pred)\n",
        "#     plt.plot(fpr, tpr)\n",
        "#     plt.plot(fpr, fpr)\n",
        "    r = roc_auc_score(truth, pred)\n",
        "    av = average_precision_score(truth, pred)\n",
        "    if verbose:\n",
        "        print(r)\n",
        "        print(av)\n",
        "    \n",
        "    if save:\n",
        "        f = open(name + \"metrics.csv\", 'a')\n",
        "        for i in [r,av]:\n",
        "        \n",
        "            f.write(str(i) + \"\\n\")\n",
        "\n",
        "        f.close()\n",
        "    \n",
        "        \n",
        "        \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDKnjygZerpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def brier_score(model, train_loader, name = 'default', verbose = True, save = True):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "    x = x.cpu()\n",
        "    x[x>0] = 1\n",
        "    x[0>x] = 0\n",
        "    \n",
        "    diff = (x[:,0,0] - b)**2\n",
        "    brier = np.average(diff)\n",
        "    \n",
        "    if verbose:\n",
        "        print(brier)\n",
        "        \n",
        "    if save:\n",
        "        f = open(name + \"metrics.csv\", 'a')\n",
        "        f.write(str(brier) + \"\\n\")\n",
        "        f.close()\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgdaoLwaU8j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def full_metrics(model, train_loader, name = 'default'):\n",
        "    metrics(model, train_loader, name = name)\n",
        "    area_under_curve_metrics(model, train_loader, name = name)\n",
        "    brier_score(model, train_loader, name = name)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWepJCa5W_sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZs5gRhzGYwK",
        "colab_type": "code",
        "outputId": "e5ea4c2c-8d4d-47f9-a61d-7a847f6a7a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "\n",
        "\n",
        "full_metrics(test_model, train_loader, name)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n",
            "(4000, 256)\n",
            "(4000, 256)\n",
            "tn: 968641\n",
            "tp: 12173\n",
            "fn: 20834\n",
            "fp 22352\n",
            "prec: 0.3525850832729906\n",
            "rec: 0.368800557457509\n",
            "f1:  0.36051057276550375\n",
            "FINISHING ONE PASS\n",
            "0.8785357924367548\n",
            "0.3060580317468836\n",
            "FINISHING ONE PASS\n",
            "0.041435546875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMOgofhvhWKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPsmKD10Kg31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def curves(model, train_loader, name):\n",
        "#     dataframe = pd.dataframe()\n",
        "    sig = nn.Sigmoid()\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "        \n",
        "    x = x.cpu()\n",
        "    truth = b.view(-1,256).numpy()\n",
        "    pred = sig(x[:,0,0].view(-1,256)).numpy()\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "#     for i in range(16):\n",
        "    leg = []\n",
        "    \n",
        "    colormap = plt.cm.nipy_spectral\n",
        "    colors = [colormap(i) for i in np.linspace(0, 1,16)]\n",
        "    ax.set_prop_cycle('color', colors)\n",
        "    for j in range(16):\n",
        "        leg.append((str(j) + \",\" + str(j)))\n",
        "        t = b[:,j,j].contiguous().view(-1).numpy()\n",
        "        p = sig(x[:,0,0,j,j].contiguous().view(-1)).numpy()\n",
        "        fpr, tpr, thresholds = roc_curve(t, p)\n",
        "        plt.plot(fpr, tpr)\n",
        "    leg.append(\"Baseline\")\n",
        "    plt.plot(fpr, fpr)\n",
        "    plt.title(\"ROC curves of diagonal labels. \\n Predictors: hyd_population, distance to capital, sum precipitation\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Postitive Rate\")\n",
        "    plt.legend(leg)\n",
        "    plt.xlim(0, 1)\n",
        "    plt.ylim(0,1)\n",
        "    \n",
        "    plt.savefig(name + \"roc_curve.pdf\")\n",
        "    plt.show()\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXD5JpCaLIzd",
        "colab_type": "code",
        "outputId": "1d564dbb-4f10-441b-e62f-147cf0820ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "curves(test_model, train_loader, name)\n",
        "# sns.set()\n",
        "# x = [1,2,3]\n",
        "# y = [4, 5,7]\n",
        "# ax = sns.lineplot(x, y, palette= 'red')\n",
        "# ax.plot([1,2], [11,22])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-69428d99c9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcurves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# sns.set()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# x = [1,2,3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# y = [4, 5,7]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ax = sns.lineplot(x, y, palette= 'red')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-d9d62ef70b3d>\u001b[0m in \u001b[0;36mcurves\u001b[0;34m(model, train_loader, name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ed0989d64317>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_copy_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#         print(\"length of out_states:\", len(out_states))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-94820f97d583>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, copy_in, copy_out)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_debug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.83 GiB (GPU 0; 11.17 GiB total capacity; 5.51 GiB already allocated; 1.66 GiB free; 3.67 GiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94-OCXRDP3cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etMgGdJjf2Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brier_score(test_model, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HLsqwEvahiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    scores = f1(test_model, train_loader, avg = 'binary')\n",
        "    np.save(name + \"scores\", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFLTv_en0WN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics(test_model, train_loader, name = name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdiCx0wFnYxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.average(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfe7BIv-liRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "plot = sns.distplot(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8h8Kkd7X86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot.set_title(\"Histogram of average F1 Score per Image prediction\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdEHaB5b8EQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oszwtyDuVvX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a, b in train_loader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK7oAiBWWX-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.count_nonzero(b) / (2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjwUwgS2W3GC",
        "colab_type": "text"
      },
      "source": [
        "# testing flipping the input direction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0nD-LmrX2UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for d, b in train_loader:\n",
        "    break\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnMHy4qTW7a9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up some axes\n",
        "a = d\n",
        "a = a.numpy()\n",
        "c = np.flip(a, 1)\n",
        "\n",
        "# c = torch.flip(a, (0,1))\n",
        "fig, axes = plt.subplots(10,2, figsize = (16,16))\n",
        "#     print(x.shape)\n",
        "#     print(b.shape)\n",
        "#     axes[0].imshow(x[sample][0][0])\n",
        "#     axes[1].imshow(b[sample])\n",
        "    \n",
        "\n",
        "for i in range(10):\n",
        "    axes[i,0].imshow(a[0][i][0])\n",
        "    axes[i,1].imshow(c[0][i][0])\n",
        "    \n",
        "plt.show()\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j08NdPNhZoJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c.shape\n",
        "c = np.array(c)\n",
        "torch.tensor(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY3GRCuQYkQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBo6C1MAZdGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = torch.tensor(c)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSGYIr8YYKox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(10,2, figsize = (16,16))\n",
        "#     print(x.shape)\n",
        "#     print(b.shape)\n",
        "#     axes[0].imshow(x[sample][0][0])\n",
        "#     axes[1].imshow(b[sample])\n",
        "    \n",
        "\n",
        "for i in range(10):\n",
        "    axes[i,0].imshow(a[0][i][0])\n",
        "    axes[i,1].imshow(e.numpy()[0][i][0])\n",
        "    \n",
        "plt.show()\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwsDysmeW87k",
        "colab_type": "text"
      },
      "source": [
        "# after flipping\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQF2DnA6yB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d) // 3\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
        "\n",
        "losses = batch_loss_histogram(test_model, train_loader, loss_func = c)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ic2GUlrX799",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights // 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sirv8aO61kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pbxmoet7IUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cPmIoZ3JNl",
        "colab_type": "text"
      },
      "source": [
        "## making histograms to check kernel size effect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEBDQBR3VKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns\n",
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d).to(device)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCoJCKbhiPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mloIqpwpW6Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a,b in train_loader:\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHbcXFd1pU6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = a.to(device)\n",
        "b = b.to(device)\n",
        "c(a[0][0][0],b[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoIbwcFpW99P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b[0]\n",
        "# sdaddasdasadad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVeZgua3NNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvtfNvMrMQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEulvwY35_DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change in all - train_index  = list\n",
        "\n",
        "\n",
        "\n",
        "# truth = train[:][1]\n",
        "truth.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHdhEAmCAYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.application_boolean\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96Eneh2CFCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4AYML9CG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX25bMZtCS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[1]\n",
        "plt.imshow(ans[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHhfnU1A8Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = truth.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-lOg4RmBHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR7kZg8BJc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[t>0] = 1\n",
        "t[t<0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdBvH9PE2G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ndgb4yy_4Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incident_map = np.sum(t, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6BoXcdbFD-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap = sns.heatmap(incident_map).set_title(\"Total Number of UCDP Events in Training Set of 46898\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UlhsFIUIdbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot_fig = heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"heatmap_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD8oDV2LRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LIRp9NI0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors = (46898  - incident_map)// incident_map\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8uk9UI6hGaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84UQbluAaTTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDO2uxF3LUSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"weights_bce\", multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6MygGdJzni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_heatmap = sns.heatmap(multiplicative_factors)\n",
        "pyplot_fig = second_heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"multiplicative_factors_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Coy8QM7DA",
        "colab_type": "text"
      },
      "source": [
        "# applying weight function to lossy dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htD4jvXUN-gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.tensor(multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIF2EHZODYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func  = nn.BCEWithLogitsLoss(pos_weight= weights)\n",
        "loss_default = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-X4tXNanfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra_KNeqBapXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d[1 > d] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhnCUQDawzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMsFFKJ7WaKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(a[0][-1][0],b[0]))\n",
        "print(loss_default(a[0][-1][0], b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo_Gr8PXhS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.ones_like(a[0][-1][0])\n",
        "c *= -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8aP4eTX7cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizNoE4vXoGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(c,b[0]))\n",
        "print(loss_default(c, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyngsiPa5Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(d,b[0]))\n",
        "print(loss_default(d, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9AGiQKOePU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1 = batch_loss_histogram(test_model, train_loader, loss_func)\n",
        "l2 = batch_loss_histogram(test_model, train_loader, loss_default)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-l3gnzjPGyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(l1)\n",
        "plt.figure()\n",
        "sns.distplot(l2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}