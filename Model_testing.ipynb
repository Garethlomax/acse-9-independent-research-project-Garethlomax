{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdjQiLORit87",
        "colab_type": "text"
      },
      "source": [
        "Notebook for testing and visualising the trained models, instead of just editing in and out of the other note books. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1hCBBflpPE",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNCK1plivBa",
        "colab_type": "code",
        "outputId": "41052ea6-8c14-4892-b91b-a297574cfa27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pw1B9CRiq4b",
        "colab_type": "code",
        "outputId": "6c8d9b8b-3733-4ed4-ac4b-09c68a0685e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3521 sha256=7ef81d94801b1be94edd4fcbe8baa187c080efc1e38d4ce2ea1da891cad00e12\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjvzMDSmjvm",
        "colab_type": "code",
        "outputId": "1a399dd6-2585-47ee-b811-43c094ce41b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.334s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GFSfjbmn9p",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng6nuRUemmId",
        "colab_type": "code",
        "outputId": "a6ad537b-bd26-48b6-bb84-3fdd5db7f1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6ygxsDfm13g",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrqiJO2m3r7",
        "colab_type": "text"
      },
      "source": [
        "## LSTM CELL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABn4VwLm1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XqL4TQZm9ux",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Full Unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_4SSRxnrvii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6r5pzTnEp1",
        "colab_type": "text"
      },
      "source": [
        "## lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f9sKamnGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3OsS3LnJST",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OliGMQernKxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhOY6M2nNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaaxPlgInPbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_index = list(train_index)\n",
        "        \n",
        "        valid_index = list(valid_index)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgXbH9ufnRUQ",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeG22ZLUnSwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtVqEhenUxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-ycpijnWaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJNW6pcnYVS",
        "colab_type": "text"
      },
      "source": [
        "# training functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-1ba_mnaMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88roEYKncdq",
        "colab_type": "code",
        "outputId": "deb9cbb6-df10-4750-f2d0-dddd7b8b0b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Qh0HFanfZd",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMIqmhTng9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "#         truth -= self.avg[0]\n",
        "#         truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxJN-sRn2Vx",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxHgHdoYn3qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7, threshold = 0.5):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     print(x[sample][0][0])\n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"sample\"+ str(sample) + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    plt.figure()\n",
        "    x[sample][0][0][threshold > x[sample][0][0]] = 0\n",
        "    plt.imshow(x[sample][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LLyGvaoTug",
        "colab_type": "text"
      },
      "source": [
        "## batch loss histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv6Zf6jzoVwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader, loss_func):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        #loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bWfVt3njrM",
        "colab_type": "text"
      },
      "source": [
        "#wrapper\n",
        "\n",
        "not put in "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1EsNMannU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7deYNPMonjoJ",
        "colab_type": "text"
      },
      "source": [
        "# code imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOBUBX2nvPV",
        "colab_type": "code",
        "outputId": "8d3df641-4d9b-4e9f-bea2-654649e53cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 5).to(device)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFSO4IMoDo9",
        "colab_type": "text"
      },
      "source": [
        "## code loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38-COzcpoJe0",
        "colab_type": "code",
        "outputId": "1e1f3505-8f60-47fe-b9f4-77c9186789d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "\n",
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('data_min_events_25.hdf5', valid_frac = 0.1, dataset_length = 52109,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiIZuUAQoNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(valid, batch_size = 2000, shuffle = False) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMjpjcSxFTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"bce_w_2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7B7f3ui0h_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgFsBi6oE2l",
        "colab_type": "code",
        "outputId": "025438ec-4633-4bd1-99cc-49eee9b4a18d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 3)).to(device) # added data parrallel\n",
        "\n",
        "test_model.load_state_dict(torch.load(name + \".pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7lJB7uoIO7",
        "colab_type": "text"
      },
      "source": [
        "loading in averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m-yzx0WopWO",
        "colab_type": "code",
        "outputId": "48e267e0-2d24-4c3c-bc28-209c6b4ba638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_image_save(test_model, train_loader, name + \"comparison\", sample = 10, threshold = 0.76)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n",
            "torch.Size([2000, 1, 5, 16, 16])\n",
            "torch.Size([2000, 16, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD1CAYAAABX2p5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLDP/HwNW6c/KTkZYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npUYZfqlRhl9qlOGXGvV/2wDHAI0hG+oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAAbuCAYAAAAIX+1GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAlCBJAgRAAJQgSQIEQA8P8Bo3Ztt7TF0kQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 2304x2304 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0nD-LmrX2UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQF2DnA6yB7",
        "colab_type": "code",
        "outputId": "33b82741-bb53-420d-f344-6062c2919744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
        "\n",
        "losses = batch_loss_histogram(test_model, train_loader, loss_func = c)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ic2GUlrX799",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "a0c9cf7c-e4d0-48ba-e69a-e73a086d3e1f"
      },
      "source": [
        "weights // 2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[26., 21., 20., 19., 18., 18., 17., 17., 17., 19., 20., 22., 23., 25.,\n",
              "         29., 37.],\n",
              "        [21., 18., 17., 16., 16., 15., 15., 15., 15., 16., 16., 18., 19., 20.,\n",
              "         24., 28.],\n",
              "        [20., 17., 15., 15., 14., 14., 13., 14., 14., 14., 15., 15., 17., 18.,\n",
              "         20., 27.],\n",
              "        [18., 16., 16., 15., 14., 13., 14., 14., 13., 13., 15., 15., 16., 17.,\n",
              "         19., 25.],\n",
              "        [19., 16., 15., 14., 13., 12., 12., 13., 13., 13., 13., 14., 15., 16.,\n",
              "         20., 24.],\n",
              "        [19., 16., 15., 14., 13., 12., 13., 12., 13., 13., 13., 14., 14., 15.,\n",
              "         19., 23.],\n",
              "        [18., 17., 15., 13., 13., 12., 12., 12., 12., 12., 13., 14., 14., 16.,\n",
              "         18., 22.],\n",
              "        [19., 17., 15., 14., 13., 12., 12., 12., 13., 12., 13., 13., 14., 16.,\n",
              "         18., 22.],\n",
              "        [19., 17., 14., 14., 13., 12., 13., 12., 13., 13., 13., 13., 14., 15.,\n",
              "         17., 22.],\n",
              "        [21., 17., 15., 15., 13., 13., 13., 13., 12., 12., 13., 14., 15., 16.,\n",
              "         18., 21.],\n",
              "        [21., 17., 15., 14., 14., 13., 13., 13., 12., 12., 14., 14., 14., 15.,\n",
              "         17., 20.],\n",
              "        [23., 17., 15., 14., 14., 13., 13., 13., 13., 13., 14., 14., 15., 16.,\n",
              "         18., 20.],\n",
              "        [23., 19., 17., 15., 15., 15., 13., 13., 13., 14., 14., 14., 15., 16.,\n",
              "         17., 22.],\n",
              "        [24., 20., 18., 17., 16., 16., 15., 14., 15., 14., 14., 15., 16., 16.,\n",
              "         18., 23.],\n",
              "        [30., 24., 20., 18., 18., 17., 16., 16., 16., 16., 15., 16., 17., 18.,\n",
              "         19., 24.],\n",
              "        [36., 29., 24., 21., 22., 20., 19., 20., 18., 19., 19., 19., 19., 21.,\n",
              "         22., 27.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sirv8aO61kZ",
        "colab_type": "code",
        "outputId": "04f7c230-3dde-4c59-89ad-2029919d7b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(losses)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efb75d23f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pbxmoet7IUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cPmIoZ3JNl",
        "colab_type": "text"
      },
      "source": [
        "## making histograms to check kernel size effect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEBDQBR3VKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns\n",
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d).to(device)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCoJCKbhiPr",
        "colab_type": "code",
        "outputId": "577e6d98-85f3-452f-e541-a058512b2e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[52., 43., 40., 38., 36., 36., 34., 34., 34., 38., 41., 44., 47., 51.,\n",
              "         59., 74.],\n",
              "        [43., 37., 35., 33., 32., 31., 30., 31., 30., 32., 33., 36., 38., 41.,\n",
              "         48., 57.],\n",
              "        [41., 35., 31., 30., 29., 28., 27., 28., 28., 29., 31., 31., 34., 37.,\n",
              "         41., 54.],\n",
              "        [37., 32., 32., 30., 28., 27., 28., 28., 27., 27., 30., 30., 32., 35.,\n",
              "         39., 51.],\n",
              "        [38., 32., 31., 28., 27., 25., 25., 27., 26., 27., 27., 28., 30., 32.,\n",
              "         40., 49.],\n",
              "        [38., 32., 31., 28., 27., 25., 26., 25., 26., 26., 27., 28., 29., 31.,\n",
              "         38., 47.],\n",
              "        [37., 34., 31., 27., 26., 25., 24., 24., 25., 25., 27., 28., 29., 32.,\n",
              "         36., 44.],\n",
              "        [38., 34., 31., 28., 26., 25., 25., 25., 26., 25., 26., 26., 28., 32.,\n",
              "         36., 45.],\n",
              "        [39., 34., 29., 28., 26., 25., 27., 25., 26., 26., 27., 27., 29., 31.,\n",
              "         35., 44.],\n",
              "        [43., 35., 31., 30., 27., 27., 27., 26., 25., 25., 27., 28., 30., 32.,\n",
              "         37., 42.],\n",
              "        [42., 34., 30., 29., 28., 27., 26., 27., 25., 25., 28., 28., 29., 31.,\n",
              "         34., 41.],\n",
              "        [46., 35., 31., 28., 29., 27., 26., 26., 27., 26., 28., 28., 30., 32.,\n",
              "         36., 41.],\n",
              "        [47., 38., 34., 30., 30., 30., 27., 27., 27., 28., 28., 29., 30., 33.,\n",
              "         35., 45.],\n",
              "        [49., 41., 36., 34., 32., 32., 30., 29., 30., 29., 29., 31., 32., 33.,\n",
              "         37., 46.],\n",
              "        [60., 48., 41., 37., 36., 34., 33., 32., 32., 32., 31., 32., 34., 37.,\n",
              "         39., 49.],\n",
              "        [72., 59., 49., 43., 44., 41., 39., 40., 36., 38., 38., 39., 39., 42.,\n",
              "         45., 55.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mloIqpwpW6Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a,b in train_loader:\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHbcXFd1pU6-",
        "colab_type": "code",
        "outputId": "ce6d9e3b-3bc9-4edc-9b0e-1a390280a8bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = a.to(device)\n",
        "b = b.to(device)\n",
        "c(a[0][0][0],b[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0166, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoIbwcFpW99P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b[0]\n",
        "# sdaddasdasadad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVeZgua3NNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvtfNvMrMQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEulvwY35_DP",
        "colab_type": "code",
        "outputId": "3bd12c8d-9fc5-43e9-e725-6d65d7c658f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# change in all - train_index  = list\n",
        "\n",
        "\n",
        "\n",
        "# truth = train[:][1]\n",
        "truth.shape\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-4c85bc0da656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'truth' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHdhEAmCAYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.application_boolean\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96Eneh2CFCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4AYML9CG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX25bMZtCS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[1]\n",
        "plt.imshow(ans[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHhfnU1A8Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = truth.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-lOg4RmBHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR7kZg8BJc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[t>0] = 1\n",
        "t[t<0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdBvH9PE2G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ndgb4yy_4Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incident_map = np.sum(t, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6BoXcdbFD-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap = sns.heatmap(incident_map).set_title(\"Total Number of UCDP Events in Training Set of 46898\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UlhsFIUIdbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot_fig = heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"heatmap_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD8oDV2LRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LIRp9NI0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors = (46898  - incident_map)// incident_map\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8uk9UI6hGaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84UQbluAaTTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDO2uxF3LUSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"weights_bce\", multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6MygGdJzni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_heatmap = sns.heatmap(multiplicative_factors)\n",
        "pyplot_fig = second_heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"multiplicative_factors_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Coy8QM7DA",
        "colab_type": "text"
      },
      "source": [
        "# applying weight function to lossy dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htD4jvXUN-gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.tensor(multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIF2EHZODYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func  = nn.BCEWithLogitsLoss(pos_weight= weights)\n",
        "loss_default = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-X4tXNanfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra_KNeqBapXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d[1 > d] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhnCUQDawzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMsFFKJ7WaKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(a[0][-1][0],b[0]))\n",
        "print(loss_default(a[0][-1][0], b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo_Gr8PXhS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.ones_like(a[0][-1][0])\n",
        "c *= -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8aP4eTX7cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizNoE4vXoGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(c,b[0]))\n",
        "print(loss_default(c, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyngsiPa5Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(d,b[0]))\n",
        "print(loss_default(d, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9AGiQKOePU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1 = batch_loss_histogram(test_model, train_loader, loss_func)\n",
        "l2 = batch_loss_histogram(test_model, train_loader, loss_default)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-l3gnzjPGyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(l1)\n",
        "plt.figure()\n",
        "sns.distplot(l2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}