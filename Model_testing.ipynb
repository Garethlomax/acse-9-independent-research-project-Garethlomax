{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdjQiLORit87",
        "colab_type": "text"
      },
      "source": [
        "Notebook for testing and visualising the trained models, instead of just editing in and out of the other note books. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1hCBBflpPE",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNCK1plivBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3349b754-57fe-4e1c-f821-9859fabfefda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pw1B9CRiq4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "729851f8-9472-4479-a717-e1ba2bce67ff"
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3521 sha256=1537fe72ead6fb3c977fc5887d70db994190e51d9f6bbcaab33031d188d87e9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjvzMDSmjvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ca3266d6-1ff7-47a7-e2ab-35f42fc57359"
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.514s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GFSfjbmn9p",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng6nuRUemmId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4854d38f-4101-4c67-f767-34ced53098c7"
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6ygxsDfm13g",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrqiJO2m3r7",
        "colab_type": "text"
      },
      "source": [
        "## LSTM CELL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABn4VwLm1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XqL4TQZm9ux",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Full Unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_4SSRxnrvii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6r5pzTnEp1",
        "colab_type": "text"
      },
      "source": [
        "## lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f9sKamnGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3OsS3LnJST",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OliGMQernKxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhOY6M2nNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaaxPlgInPbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_index = list(train_index)\n",
        "        \n",
        "        valid_index = list(valid_index)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgXbH9ufnRUQ",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeG22ZLUnSwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtVqEhenUxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-ycpijnWaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJNW6pcnYVS",
        "colab_type": "text"
      },
      "source": [
        "# training functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-1ba_mnaMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88roEYKncdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76e71d6a-398d-44b8-fd14-5a2612b76ed1"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Qh0HFanfZd",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMIqmhTng9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "#         truth -= self.avg[0]\n",
        "#         truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxJN-sRn2Vx",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxHgHdoYn3qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LLyGvaoTug",
        "colab_type": "text"
      },
      "source": [
        "## batch loss histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv6Zf6jzoVwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader, loss_func):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        #loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bWfVt3njrM",
        "colab_type": "text"
      },
      "source": [
        "#wrapper\n",
        "\n",
        "not put in "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1EsNMannU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7deYNPMonjoJ",
        "colab_type": "text"
      },
      "source": [
        "# code imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOBUBX2nvPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e6206933-1131-442b-f806-305201c022c2"
      },
      "source": [
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 3).to(device)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFSO4IMoDo9",
        "colab_type": "text"
      },
      "source": [
        "## code loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38-COzcpoJe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "88be2f41-6732-4568-a3b7-67eb933615c7"
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "\n",
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('data_min_events_25.hdf5', valid_frac = 0.1, dataset_length = 52109,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiIZuUAQoNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(valid, batch_size = 2000, shuffle = False) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMjpjcSxFTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"bce_corrected_norm\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7B7f3ui0h_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgFsBi6oE2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f686020-cff6-48d9-bd7e-c898b57e7103"
      },
      "source": [
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 3)).to(device) # added data parrallel\n",
        "\n",
        "test_model.load_state_dict(torch.load(name + \".pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7lJB7uoIO7",
        "colab_type": "text"
      },
      "source": [
        "loading in averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m-yzx0WopWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "865194ea-f87e-4134-b568-e8d15d5c06ca"
      },
      "source": [
        "test_image_save(test_model, train_loader, name + \"comparison\", sample = 1200)\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n",
            "torch.Size([2000, 1, 5, 16, 16])\n",
            "torch.Size([2000, 16, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD1CAYAAABX2p5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAAbuCAYAAAAIX+1GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 2304x2304 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cPmIoZ3JNl",
        "colab_type": "text"
      },
      "source": [
        "## making histograms to check kernel size effect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEBDQBR3VKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mloIqpwpW6Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for a,b in train_loader:\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoIbwcFpW99P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b[0]\n",
        "# sdaddasdasadad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVeZgua3NNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvtfNvMrMQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEulvwY35_DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change in all - train_index  = list\n",
        "\n",
        "\n",
        "\n",
        "# truth = train[:][1]\n",
        "truth.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHdhEAmCAYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.application_boolean\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96Eneh2CFCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4AYML9CG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX25bMZtCS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[1]\n",
        "plt.imshow(ans[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHhfnU1A8Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = truth.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-lOg4RmBHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR7kZg8BJc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[t>0] = 1\n",
        "t[t<0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdBvH9PE2G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ndgb4yy_4Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incident_map = np.sum(t, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6BoXcdbFD-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap = sns.heatmap(incident_map).set_title(\"Total Number of UCDP Events in Training Set of 46898\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UlhsFIUIdbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot_fig = heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"heatmap_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD8oDV2LRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LIRp9NI0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors = (46898  - incident_map)// incident_map\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84UQbluAaTTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDO2uxF3LUSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"weights_bce\", multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6MygGdJzni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_heatmap = sns.heatmap(multiplicative_factors)\n",
        "pyplot_fig = second_heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"multiplicative_factors_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Coy8QM7DA",
        "colab_type": "text"
      },
      "source": [
        "# applying weight function to lossy dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htD4jvXUN-gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.tensor(multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIF2EHZODYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func  = nn.BCEWithLogitsLoss(pos_weight= weights)\n",
        "loss_default = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-X4tXNanfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra_KNeqBapXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d[1 > d] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhnCUQDawzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMsFFKJ7WaKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(a[0][-1][0],b[0]))\n",
        "print(loss_default(a[0][-1][0], b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo_Gr8PXhS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.ones_like(a[0][-1][0])\n",
        "c *= -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8aP4eTX7cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizNoE4vXoGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(c,b[0]))\n",
        "print(loss_default(c, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyngsiPa5Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(d,b[0]))\n",
        "print(loss_default(d, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9AGiQKOePU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1 = batch_loss_histogram(test_model, train_loader, loss_func)\n",
        "l2 = batch_loss_histogram(test_model, train_loader, loss_default)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-l3gnzjPGyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(l1)\n",
        "plt.figure()\n",
        "sns.distplot(l2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}