{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdjQiLORit87",
        "colab_type": "text"
      },
      "source": [
        "Notebook for testing and visualising the trained models, instead of just editing in and out of the other note books. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1hCBBflpPE",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNCK1plivBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6f24421-6c0e-4230-afae-4d7aefe51ee1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pw1B9CRiq4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "40ad4970-5679-4906-d8df-c8bf41bc6126"
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjvzMDSmjvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "bfea6ad6-629c-4a40-dc04-d966a43d1e84"
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.539s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GFSfjbmn9p",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng6nuRUemmId",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8d244d51-6635-431b-e782-eff94472e267"
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6ygxsDfm13g",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrqiJO2m3r7",
        "colab_type": "text"
      },
      "source": [
        "## LSTM CELL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABn4VwLm1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XqL4TQZm9ux",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Full Unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_4SSRxnrvii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6r5pzTnEp1",
        "colab_type": "text"
      },
      "source": [
        "## lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f9sKamnGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3OsS3LnJST",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OliGMQernKxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhOY6M2nNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaaxPlgInPbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_index = list(train_index)\n",
        "        \n",
        "        valid_index = list(valid_index)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgXbH9ufnRUQ",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeG22ZLUnSwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtVqEhenUxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-ycpijnWaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJNW6pcnYVS",
        "colab_type": "text"
      },
      "source": [
        "# training functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-1ba_mnaMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88roEYKncdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7341f73-34ce-40ec-acd7-4c03b18aaee5"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Qh0HFanfZd",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMIqmhTng9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "#         truth -= self.avg[0]\n",
        "#         truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxJN-sRn2Vx",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxHgHdoYn3qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LLyGvaoTug",
        "colab_type": "text"
      },
      "source": [
        "## batch loss histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv6Zf6jzoVwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader, loss_func):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        #loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bWfVt3njrM",
        "colab_type": "text"
      },
      "source": [
        "#wrapper\n",
        "\n",
        "not put in "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1EsNMannU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7deYNPMonjoJ",
        "colab_type": "text"
      },
      "source": [
        "# code imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOBUBX2nvPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "60d9812f-c9db-4983-c281-264ed493e53f"
      },
      "source": [
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 3).to(device)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFSO4IMoDo9",
        "colab_type": "text"
      },
      "source": [
        "## code loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38-COzcpoJe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "acefb039-0252-4a1e-8dcf-04e15c5355c8"
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "\n",
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('data_min_events_25.hdf5', valid_frac = 0.1, dataset_length = 52109,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiIZuUAQoNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(valid, batch_size = 2000, shuffle = False) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMjpjcSxFTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"bce_fixed\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7B7f3ui0h_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgFsBi6oE2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7342e0e8-bf99-4ec8-f134-6666119997df"
      },
      "source": [
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 3)).to(device) # added data parrallel\n",
        "\n",
        "test_model.load_state_dict(torch.load(name + \".pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7lJB7uoIO7",
        "colab_type": "text"
      },
      "source": [
        "loading in averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m-yzx0WopWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69cd3690-02d5-48af-d623-e437c59d4694"
      },
      "source": [
        "test_image_save(test_model, train_loader, name + \"comparison\", sample = 222)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n",
            "torch.Size([2000, 1, 5, 16, 16])\n",
            "torch.Size([2000, 16, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD1CAYAAABX2p5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nceI3M6uY/w+NqSZL3WG/KQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAAbuCAYAAAAIX+1GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4CCYAQ6CGQD/D8gb2J0aNLJ+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 2304x2304 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQF2DnA6yB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6165dc2-049e-4ab7-c80d-211ed109b29f"
      },
      "source": [
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
        "\n",
        "losses = batch_loss_histogram(test_model, train_loader, loss_func = c)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sirv8aO61kZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "df2aee89-ba71-4fc0-9079-310ccc559dc9"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(losses)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f36a0be10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEic+f9yCXVN+P9zlAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pbxmoet7IUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cPmIoZ3JNl",
        "colab_type": "text"
      },
      "source": [
        "## making histograms to check kernel size effect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEBDQBR3VKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns\n",
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d).to(device)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCoJCKbhiPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "5f3a8477-c793-4cf5-99d9-1e8c00d7e6a7"
      },
      "source": [
        "weights"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[52., 43., 40., 38., 36., 36., 34., 34., 34., 38., 41., 44., 47., 51.,\n",
              "         59., 74.],\n",
              "        [43., 37., 35., 33., 32., 31., 30., 31., 30., 32., 33., 36., 38., 41.,\n",
              "         48., 57.],\n",
              "        [41., 35., 31., 30., 29., 28., 27., 28., 28., 29., 31., 31., 34., 37.,\n",
              "         41., 54.],\n",
              "        [37., 32., 32., 30., 28., 27., 28., 28., 27., 27., 30., 30., 32., 35.,\n",
              "         39., 51.],\n",
              "        [38., 32., 31., 28., 27., 25., 25., 27., 26., 27., 27., 28., 30., 32.,\n",
              "         40., 49.],\n",
              "        [38., 32., 31., 28., 27., 25., 26., 25., 26., 26., 27., 28., 29., 31.,\n",
              "         38., 47.],\n",
              "        [37., 34., 31., 27., 26., 25., 24., 24., 25., 25., 27., 28., 29., 32.,\n",
              "         36., 44.],\n",
              "        [38., 34., 31., 28., 26., 25., 25., 25., 26., 25., 26., 26., 28., 32.,\n",
              "         36., 45.],\n",
              "        [39., 34., 29., 28., 26., 25., 27., 25., 26., 26., 27., 27., 29., 31.,\n",
              "         35., 44.],\n",
              "        [43., 35., 31., 30., 27., 27., 27., 26., 25., 25., 27., 28., 30., 32.,\n",
              "         37., 42.],\n",
              "        [42., 34., 30., 29., 28., 27., 26., 27., 25., 25., 28., 28., 29., 31.,\n",
              "         34., 41.],\n",
              "        [46., 35., 31., 28., 29., 27., 26., 26., 27., 26., 28., 28., 30., 32.,\n",
              "         36., 41.],\n",
              "        [47., 38., 34., 30., 30., 30., 27., 27., 27., 28., 28., 29., 30., 33.,\n",
              "         35., 45.],\n",
              "        [49., 41., 36., 34., 32., 32., 30., 29., 30., 29., 29., 31., 32., 33.,\n",
              "         37., 46.],\n",
              "        [60., 48., 41., 37., 36., 34., 33., 32., 32., 32., 31., 32., 34., 37.,\n",
              "         39., 49.],\n",
              "        [72., 59., 49., 43., 44., 41., 39., 40., 36., 38., 38., 39., 39., 42.,\n",
              "         45., 55.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mloIqpwpW6Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a,b in train_loader:\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHbcXFd1pU6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "289de0b9-c198-47b0-ee9e-af332ee45496"
      },
      "source": [
        "a = a.to(device)\n",
        "b = b.to(device)\n",
        "c(a[0][0][0],b[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0166, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoIbwcFpW99P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b[0]\n",
        "# sdaddasdasadad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVeZgua3NNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvtfNvMrMQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEulvwY35_DP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "829da925-80f7-40f5-f8b8-e78efa04129f"
      },
      "source": [
        "# change in all - train_index  = list\n",
        "\n",
        "\n",
        "\n",
        "# truth = train[:][1]\n",
        "truth.shape\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-4c85bc0da656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'truth' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHdhEAmCAYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.application_boolean\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96Eneh2CFCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4AYML9CG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX25bMZtCS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[1]\n",
        "plt.imshow(ans[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHhfnU1A8Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = truth.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-lOg4RmBHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR7kZg8BJc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[t>0] = 1\n",
        "t[t<0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdBvH9PE2G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ndgb4yy_4Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incident_map = np.sum(t, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6BoXcdbFD-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap = sns.heatmap(incident_map).set_title(\"Total Number of UCDP Events in Training Set of 46898\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UlhsFIUIdbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot_fig = heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"heatmap_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD8oDV2LRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LIRp9NI0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors = (46898  - incident_map)// incident_map\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8uk9UI6hGaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84UQbluAaTTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDO2uxF3LUSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"weights_bce\", multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6MygGdJzni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_heatmap = sns.heatmap(multiplicative_factors)\n",
        "pyplot_fig = second_heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"multiplicative_factors_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Coy8QM7DA",
        "colab_type": "text"
      },
      "source": [
        "# applying weight function to lossy dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htD4jvXUN-gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.tensor(multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIF2EHZODYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func  = nn.BCEWithLogitsLoss(pos_weight= weights)\n",
        "loss_default = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-X4tXNanfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra_KNeqBapXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d[1 > d] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhnCUQDawzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMsFFKJ7WaKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(a[0][-1][0],b[0]))\n",
        "print(loss_default(a[0][-1][0], b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo_Gr8PXhS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.ones_like(a[0][-1][0])\n",
        "c *= -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8aP4eTX7cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizNoE4vXoGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(c,b[0]))\n",
        "print(loss_default(c, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyngsiPa5Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(d,b[0]))\n",
        "print(loss_default(d, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9AGiQKOePU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1 = batch_loss_histogram(test_model, train_loader, loss_func)\n",
        "l2 = batch_loss_histogram(test_model, train_loader, loss_default)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-l3gnzjPGyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(l1)\n",
        "plt.figure()\n",
        "sns.distplot(l2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}