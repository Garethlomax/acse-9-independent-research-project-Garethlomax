{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/Model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdjQiLORit87",
        "colab_type": "text"
      },
      "source": [
        "Notebook for testing and visualising the trained models, instead of just editing in and out of the other note books. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1hCBBflpPE",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJNCK1plivBa",
        "colab_type": "code",
        "outputId": "038b7932-1453-4a5a-b7bb-02d85253e19b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pw1B9CRiq4b",
        "colab_type": "code",
        "outputId": "75ba80a5-5260-48d8-e4f6-18ca48a85364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3521 sha256=4270e1244d48985450c7c479d0422be8d4d62461aceaed802cae9fe5340d14ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjvzMDSmjvm",
        "colab_type": "code",
        "outputId": "4a027c4c-0a93-415d-9393-e93efac2b964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.332s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GFSfjbmn9p",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng6nuRUemmId",
        "colab_type": "code",
        "outputId": "784e5514-3a82-4610-f07a-048af41f60f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6ygxsDfm13g",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYrqiJO2m3r7",
        "colab_type": "text"
      },
      "source": [
        "## LSTM CELL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABn4VwLm1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XqL4TQZm9ux",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Full Unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_4SSRxnrvii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB6r5pzTnEp1",
        "colab_type": "text"
      },
      "source": [
        "## lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f9sKamnGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ3OsS3LnJST",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OliGMQernKxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFhOY6M2nNkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaaxPlgInPbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_index = list(train_index)\n",
        "        \n",
        "        valid_index = list(valid_index)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgXbH9ufnRUQ",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeG22ZLUnSwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FtVqEhenUxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-ycpijnWaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnJNW6pcnYVS",
        "colab_type": "text"
      },
      "source": [
        "# training functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-1ba_mnaMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88roEYKncdq",
        "colab_type": "code",
        "outputId": "31b89a56-21fd-463e-987a-d1a7ecbf6134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Qh0HFanfZd",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMIqmhTng9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "#         truth -= self.avg[0]\n",
        "#         truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJxJN-sRn2Vx",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxHgHdoYn3qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     print(x[sample][0][0])\n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"sample\"+ str(sample) + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    plt.figure()\n",
        "    x[sample][0][0][0.761593 > x[sample][0][0]] = 0\n",
        "    plt.imshow(x[sample][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LLyGvaoTug",
        "colab_type": "text"
      },
      "source": [
        "## batch loss histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv6Zf6jzoVwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader, loss_func):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        #loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bWfVt3njrM",
        "colab_type": "text"
      },
      "source": [
        "#wrapper\n",
        "\n",
        "not put in "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1EsNMannU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7deYNPMonjoJ",
        "colab_type": "text"
      },
      "source": [
        "# code imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOBUBX2nvPV",
        "colab_type": "code",
        "outputId": "0a9bfa84-fc6e-42bf-aeeb-26539a20ef6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 5).to(device)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFSO4IMoDo9",
        "colab_type": "text"
      },
      "source": [
        "## code loading "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38-COzcpoJe0",
        "colab_type": "code",
        "outputId": "0338dd27-c078-41ec-d738-680150204e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "\n",
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('data_min_events_25.hdf5', valid_frac = 0.1, dataset_length = 52109,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiIZuUAQoNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(valid, batch_size = 2000, shuffle = False) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMjpjcSxFTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"bce_kern5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7B7f3ui0h_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgFsBi6oE2l",
        "colab_type": "code",
        "outputId": "9a8c092a-f8dd-4fbd-cb24-25c18c017ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 5)).to(device) # added data parrallel\n",
        "\n",
        "test_model.load_state_dict(torch.load(name + \".pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p7lJB7uoIO7",
        "colab_type": "text"
      },
      "source": [
        "loading in averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m-yzx0WopWO",
        "colab_type": "code",
        "outputId": "c0382d0d-02be-4ac5-dea1-db20ea09513d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_image_save(test_model, train_loader, name + \"comparison\", sample = 123)\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n",
            "torch.Size([2000, 1, 5, 16, 16])\n",
            "torch.Size([2000, 16, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD1CAYAAABX2p5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVYwTv5lZxTjxm5lVzP8H2yQwSLUdO5sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\napThlxpl+KVGGX6pUYZfapThlxr1f+ok1BYTUYZOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAAbuCAYAAAAIX+1GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 2304x2304 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0nD-LmrX2UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQF2DnA6yB7",
        "colab_type": "code",
        "outputId": "e7e5f110-a05a-495e-df3d-4d3ee81bbc33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
        "\n",
        "losses = batch_loss_histogram(test_model, train_loader, loss_func = c)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ic2GUlrX799",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "8fae8a78-dbe5-46bb-82be-9e722ae98a61"
      },
      "source": [
        "weights // 2"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[26., 21., 20., 19., 18., 18., 17., 17., 17., 19., 20., 22., 23., 25.,\n",
              "         29., 37.],\n",
              "        [21., 18., 17., 16., 16., 15., 15., 15., 15., 16., 16., 18., 19., 20.,\n",
              "         24., 28.],\n",
              "        [20., 17., 15., 15., 14., 14., 13., 14., 14., 14., 15., 15., 17., 18.,\n",
              "         20., 27.],\n",
              "        [18., 16., 16., 15., 14., 13., 14., 14., 13., 13., 15., 15., 16., 17.,\n",
              "         19., 25.],\n",
              "        [19., 16., 15., 14., 13., 12., 12., 13., 13., 13., 13., 14., 15., 16.,\n",
              "         20., 24.],\n",
              "        [19., 16., 15., 14., 13., 12., 13., 12., 13., 13., 13., 14., 14., 15.,\n",
              "         19., 23.],\n",
              "        [18., 17., 15., 13., 13., 12., 12., 12., 12., 12., 13., 14., 14., 16.,\n",
              "         18., 22.],\n",
              "        [19., 17., 15., 14., 13., 12., 12., 12., 13., 12., 13., 13., 14., 16.,\n",
              "         18., 22.],\n",
              "        [19., 17., 14., 14., 13., 12., 13., 12., 13., 13., 13., 13., 14., 15.,\n",
              "         17., 22.],\n",
              "        [21., 17., 15., 15., 13., 13., 13., 13., 12., 12., 13., 14., 15., 16.,\n",
              "         18., 21.],\n",
              "        [21., 17., 15., 14., 14., 13., 13., 13., 12., 12., 14., 14., 14., 15.,\n",
              "         17., 20.],\n",
              "        [23., 17., 15., 14., 14., 13., 13., 13., 13., 13., 14., 14., 15., 16.,\n",
              "         18., 20.],\n",
              "        [23., 19., 17., 15., 15., 15., 13., 13., 13., 14., 14., 14., 15., 16.,\n",
              "         17., 22.],\n",
              "        [24., 20., 18., 17., 16., 16., 15., 14., 15., 14., 14., 15., 16., 16.,\n",
              "         18., 23.],\n",
              "        [30., 24., 20., 18., 18., 17., 16., 16., 16., 16., 15., 16., 17., 18.,\n",
              "         19., 24.],\n",
              "        [36., 29., 24., 21., 22., 20., 19., 20., 18., 19., 19., 19., 19., 21.,\n",
              "         22., 27.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sirv8aO61kZ",
        "colab_type": "code",
        "outputId": "1515ddcd-3662-4166-b097-2f35ad22b3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(losses)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7bda7b33c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pbxmoet7IUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cPmIoZ3JNl",
        "colab_type": "text"
      },
      "source": [
        "## making histograms to check kernel size effect "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiEBDQBR3VKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns\n",
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d).to(device)\n",
        "c = nn.BCEWithLogitsLoss(pos_weight=weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHCoJCKbhiPr",
        "colab_type": "code",
        "outputId": "e5b17023-a8ff-4e10-a0b7-ba1b73d6059d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[52., 43., 40., 38., 36., 36., 34., 34., 34., 38., 41., 44., 47., 51.,\n",
              "         59., 74.],\n",
              "        [43., 37., 35., 33., 32., 31., 30., 31., 30., 32., 33., 36., 38., 41.,\n",
              "         48., 57.],\n",
              "        [41., 35., 31., 30., 29., 28., 27., 28., 28., 29., 31., 31., 34., 37.,\n",
              "         41., 54.],\n",
              "        [37., 32., 32., 30., 28., 27., 28., 28., 27., 27., 30., 30., 32., 35.,\n",
              "         39., 51.],\n",
              "        [38., 32., 31., 28., 27., 25., 25., 27., 26., 27., 27., 28., 30., 32.,\n",
              "         40., 49.],\n",
              "        [38., 32., 31., 28., 27., 25., 26., 25., 26., 26., 27., 28., 29., 31.,\n",
              "         38., 47.],\n",
              "        [37., 34., 31., 27., 26., 25., 24., 24., 25., 25., 27., 28., 29., 32.,\n",
              "         36., 44.],\n",
              "        [38., 34., 31., 28., 26., 25., 25., 25., 26., 25., 26., 26., 28., 32.,\n",
              "         36., 45.],\n",
              "        [39., 34., 29., 28., 26., 25., 27., 25., 26., 26., 27., 27., 29., 31.,\n",
              "         35., 44.],\n",
              "        [43., 35., 31., 30., 27., 27., 27., 26., 25., 25., 27., 28., 30., 32.,\n",
              "         37., 42.],\n",
              "        [42., 34., 30., 29., 28., 27., 26., 27., 25., 25., 28., 28., 29., 31.,\n",
              "         34., 41.],\n",
              "        [46., 35., 31., 28., 29., 27., 26., 26., 27., 26., 28., 28., 30., 32.,\n",
              "         36., 41.],\n",
              "        [47., 38., 34., 30., 30., 30., 27., 27., 27., 28., 28., 29., 30., 33.,\n",
              "         35., 45.],\n",
              "        [49., 41., 36., 34., 32., 32., 30., 29., 30., 29., 29., 31., 32., 33.,\n",
              "         37., 46.],\n",
              "        [60., 48., 41., 37., 36., 34., 33., 32., 32., 32., 31., 32., 34., 37.,\n",
              "         39., 49.],\n",
              "        [72., 59., 49., 43., 44., 41., 39., 40., 36., 38., 38., 39., 39., 42.,\n",
              "         45., 55.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mloIqpwpW6Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a,b in train_loader:\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHbcXFd1pU6-",
        "colab_type": "code",
        "outputId": "c1ab1f40-04a4-4653-cebc-d29c2b6c40fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = a.to(device)\n",
        "b = b.to(device)\n",
        "c(a[0][0][0],b[0])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0166, device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoIbwcFpW99P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b[0]\n",
        "# sdaddasdasadad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVeZgua3NNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYvtfNvMrMQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEulvwY35_DP",
        "colab_type": "code",
        "outputId": "e6331e8b-b405-4d2c-9c4f-ce57bc6ace00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# change in all - train_index  = list\n",
        "\n",
        "\n",
        "\n",
        "# truth = train[:][1]\n",
        "truth.shape\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-4c85bc0da656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'truth' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHdhEAmCAYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.application_boolean\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C96Eneh2CFCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = train[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX4AYML9CG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX25bMZtCS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans[1]\n",
        "plt.imshow(ans[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqHhfnU1A8Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = truth.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-lOg4RmBHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR7kZg8BJc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[t>0] = 1\n",
        "t[t<0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdBvH9PE2G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ndgb4yy_4Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incident_map = np.sum(t, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6BoXcdbFD-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "heatmap = sns.heatmap(incident_map).set_title(\"Total Number of UCDP Events in Training Set of 46898\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UlhsFIUIdbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot_fig = heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"heatmap_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgD8oDV2LRJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LIRp9NI0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors = (46898  - incident_map)// incident_map\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8uk9UI6hGaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84UQbluAaTTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multiplicative_factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDO2uxF3LUSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"weights_bce\", multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6MygGdJzni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "second_heatmap = sns.heatmap(multiplicative_factors)\n",
        "pyplot_fig = second_heatmap.get_figure()\n",
        "pyplot_fig.savefig(\"multiplicative_factors_min_event_25_occurances.pdf\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2Coy8QM7DA",
        "colab_type": "text"
      },
      "source": [
        "# applying weight function to lossy dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htD4jvXUN-gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = torch.tensor(multiplicative_factors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjIF2EHZODYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func  = nn.BCEWithLogitsLoss(pos_weight= weights)\n",
        "loss_default = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-X4tXNanfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra_KNeqBapXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d[1 > d] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHhnCUQDawzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMsFFKJ7WaKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(a[0][-1][0],b[0]))\n",
        "print(loss_default(a[0][-1][0], b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo_Gr8PXhS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.ones_like(a[0][-1][0])\n",
        "c *= -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8aP4eTX7cD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizNoE4vXoGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(c,b[0]))\n",
        "print(loss_default(c, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beyngsiPa5Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss_func(d,b[0]))\n",
        "print(loss_default(d, b[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9AGiQKOePU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1 = batch_loss_histogram(test_model, train_loader, loss_func)\n",
        "l2 = batch_loss_histogram(test_model, train_loader, loss_default)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-l3gnzjPGyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(l1)\n",
        "plt.figure()\n",
        "sns.distplot(l2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}