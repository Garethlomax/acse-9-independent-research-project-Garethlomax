{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/full_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1onVYuKcDt",
        "colab_type": "text"
      },
      "source": [
        "#imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgHHu2lwKF0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "45598b93-dd2e-45e4-e872-baa8b66d8d97"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2k695HbKic0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "52c9cd7f-00dd-49dc-dd74-d5645006f731"
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3521 sha256=5d99e3d6b5e3a5c719524830614b9fab1b91f26a2e03b5e66c2e78e8cd72809a\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0y9nWYUKmsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5eaf1804-7284-48e2-b664-9acb3511780e"
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.201s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHqL0wCqKr6O",
        "colab_type": "text"
      },
      "source": [
        "## snippet to investigate ram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8VGlxIDKq8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "ba2cf12a-50b5-47db-85f9-02ffbff358d4"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=c2e14566453ffd5badfcfbee6ab3e0f9c36fd276e682e901e1e3ae80b9f688b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 309.2 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbWslp2UKzwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "571ebe37-4f7c-4ed5-9274-351321e0e4d9"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Fp3Nk3K03D",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqrux9tK2ap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc08f528-fd9a-40f0-c5a2-7e3fb133c16f"
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--S3DiL3KcVy",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CELL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj3Icdv2K8z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dR0F-kKKcYD",
        "colab_type": "text"
      },
      "source": [
        "# lstm full unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jt5nXmELFjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSvkO-LjLL_h",
        "colab_type": "text"
      },
      "source": [
        "# lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NYS0hX5LI0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbyJ0SfNLVVT",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8YZKbahLin2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qppFhApXLlIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_iKjRtJ-PL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z4SHaDXKcap",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khitUnTHLu0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPCRgC06L0ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d6g-caEL4-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BL54iWHMUtj",
        "colab_type": "text"
      },
      "source": [
        "#TRAINING FUNCTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtQQVIoxMWnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R8deKvmMblY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63c29851-ffc8-421b-962f-0d029cf0a87c"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "        # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, criterion = nn.MSELoss()):\n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad: # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x.to(device) # send to cuda.\n",
        "            y.to(device)\n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction, y)\n",
        "            \n",
        "            \n",
        "    return validloss, validaccuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88zV9JwqN3c7",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAdu0-tVN51S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "        truth -= self.avg[0]\n",
        "        truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG-2m6rnOLPz",
        "colab_type": "text"
      },
      "source": [
        "# wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS33z7MHOMIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrapper_full(name, optimizer,  structure, loss_func, avg, std, application_boolean, lr = None, epochs = 50, kernel_size = 3, batch_size = 50):\n",
        "    f = open(name + \".csv\", 'w') # open csv file for saving\n",
        "    \n",
        "    model = LSTMencdec_onestep(structure, 5, kernel_size = kernel_size).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr, amsgrad= True)\n",
        "\n",
        "    # put in structure.\n",
        "    f.write(\"Structure: \\n\")\n",
        "\n",
        "    for i in range(len(structure)):\n",
        "        for j in range(len(structure[0])):\n",
        "            f.write(\"{},\".format(structure[i,j]))\n",
        "        f.write(\"\\n\") # new line\n",
        "\n",
        "    f.write(\"Parameters:\\n\")\n",
        "    f.write(\"optimizer, epochs, learning rate, kernel size \\n\")\n",
        "    \n",
        "    if lr != None:\n",
        "        # optimizer problems\n",
        "        \n",
        "        f.write(\"{},{},{},{},{}\\n\".format(\"test\", epochs, lr, kernel_size, batch_size))\n",
        "    else:\n",
        "        f.write(\"{},{},{},{},{}\\n\".format(\"othertest\", epochs, \"Default\", kernel_size, batch_size))\n",
        "        \n",
        "    f.write(\"loss_func:\\n\")\n",
        "    f.write(loss_func.__repr__() + \"\\n\")\n",
        "    \n",
        "    f.write(\"optimizer:\\n\")\n",
        "    f.write(optimizer.__repr__() + \"\\n\")\n",
        "    \n",
        "    f.write(\"\\n\\n\\n\")\n",
        "    f.write(\"TRAINING\\n\")\n",
        "    \n",
        "    # now we define the training functions\n",
        "#     train, valid = initialise_dataset_HDF5()\n",
        "    \n",
        "    index_map = np.arange(0, 84485,1)# dummy index_map just to make sure trains correctly. \n",
        "    train = HDF5Dataset_with_avgs('data_prio_run_test4.hdf5', index_map,avg, std, apbln)\n",
        "    \n",
        "    # put model together with different size\n",
        "    # model test - put it together.\n",
        "    # now we train the model\n",
        "    \n",
        "    \n",
        "    \n",
        "    # ignore this one.\n",
        "    \n",
        "#     model, optimizer = train_main(test_model, 1, train, valid, epochs = epochs, batch_size = 50)\n",
        "\n",
        "    loss_func = loss_func\n",
        "    \n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr = lr, amsgrad= True)\n",
        "    \n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    f.close()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "#     validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        # does is matter that we arent returning the model?\n",
        "        _, loss = train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        f = open(name + \".csv\", 'a') # open csv file for saving\n",
        "\n",
        "        f.write(str(loss) + \"\\n\")\n",
        "        \n",
        "        f.close()\n",
        "        \n",
        "        torch.save(optimizer.state_dict(), name+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), name+str(epoch)+\".pth\")\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mdz5tVBMlur",
        "colab_type": "text"
      },
      "source": [
        "# RUN CODE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TPlTW4-Mnnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# changed \n",
        "structure = np.array([[24,48,0,0,0],[0,48,24,12,5]])\n",
        "\n",
        "# test_model = LSTMencdec_onestep(structure, 1, kernel_size = 3).to(device)\n",
        "# print(\"seq length\", test_model.decoder.seq_length)\n",
        "# optim = torch.optim.Adam(test_model.parameters())\n",
        "\n",
        "\n",
        "\n",
        "# train_enc = train_enc_dec(test_model,)\n",
        "\n",
        "\n",
        "# train_main(test_model, 1, train, valid, epochs = 2, batch_size = 50)\n",
        "\n",
        "# model, optimizer = train_main(test_model, 1, train, valid, epochs = 50, batch_size = 50)\n",
        "\n",
        "\n",
        "# torch.save(optimizer.state_dict(), F\"Finished_opt_bce.pth\")\n",
        "# torch.save(model.state_dict(), F\"Finished_mod_bce.pth\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q29pFNMoOg4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = np.zeros((50,1,1,16,16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nefIDQzoOnbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a9e6ca0-4031-4ef0-c9af-679d1a2020f4"
      },
      "source": [
        "test1[:,0,0].shape\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 16, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kulxvr-3G9RZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14ab0074-ff09-4398-c635-5e9dbe6fdc3c"
      },
      "source": [
        "%pwd\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/masters_project/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuOuuQUBW8v6",
        "colab_type": "text"
      },
      "source": [
        "# trying to unfuck averaging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKk1EIXUXwFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1af6947-99ac-4776-c403-334b161a4bdf"
      },
      "source": [
        "avg"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.48881898e-01, 1.48213964e-02, 2.99932087e-03, 1.37238125e-02,\n",
              "       6.74098740e+02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRTblglIXyl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d3ab5f73-9f14-4a5d-bc42-a1027d18ec2a"
      },
      "source": [
        "std"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.92430099e+00, 1.19819853e-01, 5.40919057e-02, 9.55901022e-02,\n",
              "       6.00709686e+02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ELkwJ8HMMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee65d1b1-2406-4d3c-9b38-c86ab2eddf6d"
      },
      "source": [
        "# %cd ..\n",
        "index_map = np.arange(0,84485,1)\n",
        "train = HDF5Dataset_with_avgs('data_prio_run_test4.hdf5', list(index_map),avg, std, apbln)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nquiRWWaeV_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "60f3153d-ea71-4929-f177-1a055c9956db"
      },
      "source": [
        "pred = train[0:200][0]\n",
        "\n",
        "tru = train[0:200][1] "
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictor shape: torch.Size([200, 10, 5, 16, 16])\n",
            "truth shape: torch.Size([200, 16, 16])\n",
            "predictor shape: torch.Size([200, 10, 5, 16, 16])\n",
            "truth shape: torch.Size([200, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CghmBSi7nkrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe3aecd5-6612-47e6-9af8-eeae73b7cce9"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 5, 16, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWef8waDnqAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9017858-a1bb-4187-bf34-ed87dc3b13c5"
      },
      "source": [
        "tru.shape"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 16, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5lUsVkdnzIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1babc63f-d7b1-4036-f9d6-18b7f1ba82cb"
      },
      "source": [
        "b(pred[:,-1,0],tru)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(20.1687, dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQpw9FEKoYZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tot = 0\n",
        "for i in range(200):\n",
        "    print(i)\n",
        "    print(b(pred[i][-1][0], tru[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca_cEykSooKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41de0341-e07d-4a4b-e76d-305dd5b822de"
      },
      "source": [
        ""
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4033.7339, dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQUaOOUregUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "7127fb8c-ef22-4ca4-e74b-c074ab74a4d8"
      },
      "source": [
        "plt.imshow(pred[0][-1][0])"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faa1ae35ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nowy/1CjDLzXK8EuN+h/amaWgaSnV3wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tttv1E-ck9GX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "e0099e61-b20d-4633-e6b0-a041f25f2ffe"
      },
      "source": [
        "plt.imshow(tru[0])"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faa1a0fa160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nowy/1Kj/AwLE0acjTX81AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMj4c3H9eoG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "235c3b11-48be-4f4d-a950-61a3b4be23f4"
      },
      "source": [
        "plt.imshow(tru)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faa1a0d0198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADQ1JREFUeJzt3X+sZPVZx/H3pywLsl1hEaUUiIAh\nJNiokA2F2mDjKl2QsG3SP5ZYhdKENIqCqSFbSWzjH6a1Wn82NAgoKoFGCu2mActK2xgTWQvr8nMp\nLBSBdflRa4C2sbDl8Y85a+5e7t29d+ac2bv7fb+SyT0z5ztznntmPvecOffMPKkqJLXnLfu7AEn7\nh+GXGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlRhl9q1LJpLmx5DqvDWTHNRUpN+V++x2v1gyxk7FTD\nfzgreGfWTHORUlM21z0LHutuv9SoicKfZG2SbybZnmRDX0VJGt7Y4U9yCPBZ4HzgdODiJKf3VZik\nYU2y5T8L2F5VT1XVa8CtwLp+ypI0tEnCfzzw7Izrz3W3SToADH60P8nlwOUAh3PE0IuTtECTbPl3\nACfOuH5Cd9sequq6qlpdVasP5bAJFiepT5OE/xvAqUlOTrIcWA9s7KcsSUMbe7e/qnYluQL4CnAI\ncGNVPdJbZZIGNdF7/qq6E7izp1okTZFn+EmNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuN\nMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1KhJ2nWdmORrSR5N8kiSK/ssTNKw\nJvkCz13AR6tqS5KVwP1JNlXVoz3VJmlAY2/5q2pnVW3ppl8FtmG7LumA0Uu7riQnAWcAm+eYZ7su\naQma+IBfkrcCXwCuqqpXZs+3XZe0NE0U/iSHMgr+zVV1ez8lSZqGSY72B7gB2FZVn+mvJEnTMMmW\n/+eBXwN+McnW7nJBT3VJGtgkjTr/FUiPtUiaIs/wkxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUYZf\napThlxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUYZfapThlxpl+KVG9fHV3Yck+Y8kX+6jIEnT0ceW\n/0pG3XokHUAm/d7+E4BfAa7vpxxJ0zLplv/PgKuBN3qoRdIUTdK040Lgxaq6fx/jLk9yX5L7XucH\n4y5OUs8mbdpxUZKngVsZNe/4h9mD7NUnLU2TtOj+WFWdUFUnAeuBr1bVB3urTNKg/D+/1Kix23XN\nVFVfB77ex2NJmg63/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y\n/FKjDL/UKMMvNcrwS40y/FKjDL/UqEmbdhyV5LYkjyXZluScvgqTNKxJv8Pvz4F/qqoPJFkOHNFD\nTZKmYOzwJzkSOBe4FKCqXgNe66csSUObZLf/ZOAl4G+6Lr3XJ1nRU12SBjZJ+JcBZwLXVtUZwPeA\nDbMH2a5LWpomCf9zwHNVtbm7fhujPwZ7sF2XtDRN0q7reeDZJKd1N60BHu2lKkmDm/Ro/28BN3dH\n+p8CPjR5SZKmYaLwV9VWYHVPtUiaIs/wkxrVS6NOTVcOXb7o+9TrnoKhPbnllxpl+KVGGX6pUYZf\napThlxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUYZfapThlxrlp/r2o3E+nQd+Qk/9cMsvNcrwS42a\ntF3X7yR5JMnDSW5JcnhfhUka1tjhT3I88NvA6qp6B3AIsL6vwiQNa9Ld/mXAjyRZxqhP339NXpKk\naZjke/t3AH8MPAPsBF6uqrv7KkzSsCbZ7V8FrGPUs+/twIokH5xjnO26pCVokt3+XwK+VVUvVdXr\nwO3Au2YPsl2XtDRNEv5ngLOTHJEkjNp1beunLElDm+Q9/2ZGzTm3AA91j3VdT3VJGtik7bo+Dny8\np1okTZFn+EmNMvxSo/xU337kp/MOPAfTJzHd8kuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK\n8EuNMvxSowy/1CjDLzXqoP1gz8H0AQwtHeO+PsZ5PQ79WnTLLzXK8EuN2mf4k9yY5MUkD8+47egk\nm5I80f1cNWyZkvq2kC3/3wJrZ922Abinqk4F7umuSzqA7DP8VfUvwHdm3bwOuKmbvgl4X891SRrY\nuO/5j62qnd3088CxPdUjaUomPuBXVQXUfPNt1yUtTeOG/4UkxwF0P1+cb6DtuqSladzwbwQu6aYv\nAb7UTzmSpmUh/+q7Bfg34LQkzyX5MPBJ4JeTPMGoYecnhy1TUt/2eXpvVV08z6w1PdciaYo8w09q\nlOGXGnXQfqrPT+dpKVmKr0e3/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMv\nNcrwS406aD/YIy0l3/rDcxZ9n8cvvXbR9znrvd9f8Fi3/FKjDL/UKMMvNWrcXn2fTvJYkgeT3JHk\nqGHLlNS3cXv1bQLeUVU/AzwOfKznuiQNbKxefVV1d1Xt6q7eC5wwQG2SBtTHe/7LgLvmm2m7Lmlp\nmij8Sa4BdgE3zzfGdl3S0jT2ST5JLgUuBNZ0zTolHUDGCn+StcDVwC9U1cJPKZK0ZIzbq++vgJXA\npiRbk3xu4Dol9WzcXn03DFCLpCnyDD+pUZnmsbofzdH1ztjcV1qIt6xcuej73Pvdjbz8w29nQY+/\n6EeXdFAw/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS42yV5+0RL3x\n6quLvk/VGwse65ZfapThlxo1VruuGfM+mqSSHDNMeZKGMm67LpKcCJwHPNNzTZKmYKx2XZ0/ZfT1\n3X5nv3QAGus9f5J1wI6qemABY23XJS1Bi/5XX5IjgN9jtMu/T1V1HXAdjL7Ac7HLkzSMcbb8PwWc\nDDyQ5GlGHXq3JHlbn4VJGtait/xV9RDwE7uvd38AVlfVt3usS9LAxm3XJekAN267rpnzT+qtGklT\n4xl+UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81\nKlXT+1q9JC8B/znP7GOApfBtQNaxJ+vY01Kv4yer6scX8gBTDf/eJLmvqlZbh3VYx3TqcLdfapTh\nlxq1lMJ/3f4uoGMde7KOPR00dSyZ9/ySpmspbfklTdFUw59kbZJvJtmeZMMc8w9L8vlu/uYkJw1Q\nw4lJvpbk0SSPJLlyjjHvSfJykq3d5ff7rmPGsp5O8lC3nPvmmJ8kf9GtkweTnNnz8k+b8XtuTfJK\nkqtmjRlsfczVAj7J0Uk2JXmi+7lqnvte0o15IsklA9Tx6SSPdev9jiRHzXPfvT6HPdTxiSQ7Zqz/\nC+a5717z9SZVNZULcAjwJHAKsBx4ADh91pjfAD7XTa8HPj9AHccBZ3bTK4HH56jjPcCXp7RengaO\n2cv8C4C7gABnA5sHfo6eZ/S/4qmsD+Bc4Ezg4Rm3/RGwoZveAHxqjvsdDTzV/VzVTa/quY7zgGXd\n9KfmqmMhz2EPdXwC+N0FPHd7zdfsyzS3/GcB26vqqap6DbgVWDdrzDrgpm76NmBNkvRZRFXtrKot\n3fSrwDbg+D6X0bN1wN/VyL3AUUmOG2hZa4Anq2q+E7F6V3O3gJ/5OrgJeN8cd30vsKmqvlNV/wNs\nAtb2WUdV3V1Vu7qr9zLqSzmoedbHQiwkX3uYZviPB56dcf053hy6/x/TrfSXgR8bqqDubcUZwOY5\nZp+T5IEkdyX56aFqAAq4O8n9SS6fY/5C1ltf1gO3zDNvWusD4Niq2tlNPw8cO8eYaa4XgMsY7YHN\nZV/PYR+u6N5+3DjP26BFr49mD/gleSvwBeCqqnpl1uwtjHZ9fxb4S+CLA5by7qo6Ezgf+M0k5w64\nrHklWQ5cBPzjHLOnuT72UKN92v36L6kk1wC7gJvnGTL0c3gto+7YPwfsBP6kjwedZvh3ACfOuH5C\nd9ucY5IsA44E/rvvQpIcyij4N1fV7bPnV9UrVfXdbvpO4NAkx/RdR/f4O7qfLwJ3MNp9m2kh660P\n5wNbquqFOWqc2vrovLD7rU3388U5xkxlvSS5FLgQ+NXuD9GbLOA5nEhVvVBVP6yqN4C/nufxF70+\nphn+bwCnJjm528qsBzbOGrMR2H3U9gPAV+db4ePqjiHcAGyrqs/MM+Ztu481JDmL0Xoa4o/QiiQr\nd08zOsD08KxhG4Ff7476nw28PGOXuE8XM88u/7TWxwwzXweXAF+aY8xXgPOSrOp2g8/rbutNkrXA\n1cBFVfX9ecYs5DmctI6Zx3jeP8/jLyRfe+rjCOUijmRewOjo+pPANd1tf8Bo5QIczmi3czvw78Ap\nA9Twbka7kQ8CW7vLBcBHgI90Y64AHmF0xPRe4F0DrY9TumU80C1v9zqZWUuAz3br7CFg9QB1rGAU\n5iNn3DaV9cHoD85O4HVG71M/zOg4zz3AE8A/A0d3Y1cD18+472Xda2U78KEB6tjO6H307tfJ7v9E\nvR24c2/PYc91/H333D/IKNDHza5jvnzt7eIZflKjmj3gJ7XO8EuNMvxSowy/1CjDLzXK8EuNMvxS\nowy/1Kj/AwLE0acjTX81AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHqZrAbPk_bW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "bdedaa52-0f46-4bdc-a1b6-1933adfd790d"
      },
      "source": [
        "tru"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,  0.0822, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440,  0.0822, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,  0.0822, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440,  0.0822, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,  0.0822, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,  2.9846,  6.5181],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,  0.2084],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440],\n",
              "        [-0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440,\n",
              "         -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440, -0.0440]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAQ4Ai4nervO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a7b543a-5b85-401b-be05-fd43022e0251"
      },
      "source": [
        "b(pred[0][0], tru)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3388, dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oFJmQRyRI-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b715c43-8a45-402c-8184-f63b4198a84e"
      },
      "source": [
        "# d = train[20000]\n",
        "d = train[20000:20010]\n",
        "print(d[0].shape)\n",
        "plt.imshow(d[1][0])\n",
        "o = d[0][0]\n",
        "for i in range(10):\n",
        "    plt.figure()\n",
        "    plt.imshow(o[i][0])\n",
        "    "
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictor shape: torch.Size([10, 10, 5, 16, 16])\n",
            "truth shape: torch.Size([10, 16, 16])\n",
            "torch.Size([10, 10, 5, 16, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1CjDLzXK8EuNMvxSo/4Pizzcx/ZiHvEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv9Qowy81yvBLjfo/2tXGnqCYZ3oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNer/AFSWw9LUflmlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADP9JREFUeJzt3X2sZPVdx/H3Rx5lS2ER5TkChpBg\no4VsKGCDjasUkLBt0j+WtAqlCWkUhaaGbCWxjX+1VlufmjYIKCqBRgqWNCCstI0xlrWwLo/Lw4II\nbJcHxUBtY4H26x9z1ty93Lt7d+acw11+71cyuWfm/GbOd3+zn3vOnDsz31QVktrzY292AZLeHIZf\napThlxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUXuPubF9s1/tz4oxNyk15X/5Hq/WD7KUsaOGf39W\n8K6sHnOTUlM21F1LHuthv9SomcKf5OwkjybZkmRdX0VJGt7U4U+yF/AF4BzgJOCCJCf1VZikYc2y\n5z8V2FJVT1bVq8CNwJp+ypI0tFnCfxTwzJzrz3a3SdoDDH62P8klwCUA+3PA0JuTtESz7Pm3AsfM\nuX50d9sOquqqqlpVVav2Yb8ZNiepT7OE/9vACUmOS7IvsBa4tZ+yJA1t6sP+qno9yaXAHcBewLVV\n9VBvlUka1Eyv+avqNuC2nmqRNCLf4Sc1yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBL\njTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqNmadd1TJJvJHk4yUNJLuuzMEnDmuUL\nPF8HPl5VG5McCNybZH1VPdxTbZIGNPWev6q2VdXGbvm7wGZs1yXtMXpp15XkWOBkYMMC62zXJS1D\nM5/wS/I24CvA5VX1yvz1tuuSlqeZwp9kHybBv76qbu6nJEljmOVsf4BrgM1V9bn+SpI0hln2/L8A\n/BrwS0k2dZdze6pL0sBmadT5z0B6rEXSiHyHn9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMM\nv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81qo+v7t4ryb8l+VofBUkaRx97/suY\ndOuRtAeZ9Xv7jwZ+Fbi6n3IkjWXWPf8fA1cAP+qhFkkjmqVpx3nAC1V17y7GXZLkniT3vMYPpt2c\npJ7N2rTj/CRPATcyad7xt/MH2atPWp5madH9iao6uqqOBdYCX6+qD/VWmaRB+Xd+qVFTt+uaq6q+\nCXyzj8eSNA73/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKj\nDL/UKMMvNcrwS40y/FKjDL/UqFmbdhyc5KYkjyTZnOT0vgqTNKxZv8PvT4B/qKoPJNkXOKCHmiSN\nYOrwJzkIOBO4CKCqXgVe7acsSUOb5bD/OOBF4C+7Lr1XJ1nRU12SBjZL+PcGTgG+WFUnA98D1s0f\nZLsuaXmaJfzPAs9W1Ybu+k1MfhnswHZd0vI0S7uu54BnkpzY3bQaeLiXqiQNbtaz/b8FXN+d6X8S\n+PDsJUkaw0zhr6pNwKqeapE0It/hJzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuN\nMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNmrVd18eSPJTkwSQ3JNm/r8IkDWvq8Cc5Cvht\nYFVVvQPYC1jbV2GShjXrYf/ewI8n2ZtJn77vzF6SpDHM8r39W4E/BJ4GtgEvV9WdfRUmaVizHPav\nBNYw6dl3JLAiyYcWGGe7LmkZmuWw/5eBf6+qF6vqNeBm4Iz5g2zXJS1Ps4T/aeC0JAckCZN2XZv7\nKUvS0GZ5zb+BSXPOjcAD3WNd1VNdkgY2a7uuTwKf7KkWSSPyHX5Sowy/1CjDLzXK8EuNMvxSowy/\n1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1Khdhj/JtUleSPLg\nnNsOSbI+yePdz5XDlimpb0vZ8/8VcPa829YBd1XVCcBd3XVJe5Bdhr+q/gl4ad7Na4DruuXrgPf1\nXJekgU37mv+wqtrWLT8HHNZTPZJGMvMJv6oqoBZbb7suaXmaNvzPJzkCoPv5wmIDbdclLU/Thv9W\n4MJu+ULgq/2UI2ksS/lT3w3At4ATkzyb5CPAp4FfSfI4k4adnx62TEl922W7rqq6YJFVq3uuRdKI\nfIef1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuN\n2uXn+dW2O76zaar7vffId/Zcifrmnl9qlOGXGmX4pUZN26vvs0keSXJ/kluSHDxsmZL6Nm2vvvXA\nO6rq54DHgE/0XJekgU3Vq6+q7qyq17urdwNHD1CbpAH18Zr/YuD2xVbarktanmYKf5IrgdeB6xcb\nY7suaXma+k0+SS4CzgNWd806Je1Bpgp/krOBK4BfrKrv91uSpDFM26vvz4EDgfVJNiX50sB1SurZ\ntL36rhmgFkkj8h1+UqNG/VTfa4et4LkPnrHb9zv88/8yQDVvvuc+tvtzAePOh5/Oe+tyzy81yvBL\njTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81KmN+A9fbc0i9K6tH2940\nLnnsyd2+zzXvP2eqbf3woUenut80nwYc+5ORh33r7bt9n+dPf2WAStqyoe7ilXopSxnrnl9qlOGX\nGjVVu6456z6epJIcOkx5koYybbsukhwDnAU83XNNkkYwVbuuzueZfH2339kv7YGmes2fZA2wtaru\nW8JY23VJy9Buf4FnkgOA32VyyL9LVXUVcBVM/tS3u9uTNIxp9vw/AxwH3JfkKSYdejcmObzPwiQN\na7f3/FX1APBT2693vwBWVdV/9liXpIFN265L0h5u2nZdc9cf21s1kkbjO/ykRvnBHuktxA/2SNol\nwy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9SoUT/Vl+RF4D8WWX0o\nsBy+Dcg6dmQdO1rudfx0Vf3kUh5g1PDvTJJ7qmqVdViHdYxTh4f9UqMMv9So5RT+q97sAjrWsSPr\n2NFbpo5l85pf0riW055f0ohGDX+Ss5M8mmRLknULrN8vyZe79RuSHDtADcck+UaSh5M8lOSyBca8\nJ8nLSTZ1l9/ru44523oqyQPddu5ZYH2S/Gk3J/cnOaXn7Z8459+5KckrSS6fN2aw+VioBXySQ5Ks\nT/J493PlIve9sBvzeJILB6jjs0ke6eb9liQHL3LfnT6HPdTxqSRb58z/uYvcd6f5eoOqGuUC7AU8\nARwP7AvcB5w0b8xvAF/qltcCXx6gjiOAU7rlA4HHFqjjPcDXRpqXp4BDd7L+XOB2IMBpwIaBn6Pn\nmPyteJT5AM4ETgEenHPbHwDruuV1wGcWuN8hwJPdz5Xd8sqe6zgL2Ltb/sxCdSzlOeyhjk8Bv7OE\n526n+Zp/GXPPfyqwpaqerKpXgRuBNfPGrAGu65ZvAlYnWdLXEC9VVW2rqo3d8neBzcBRfW6jZ2uA\nv66Ju4GDkxwx0LZWA09U1WJvxOpdLdwCfu7/g+uA9y1w1/cC66vqpar6b2A9cHafdVTVnVX1enf1\nbiZ9KQe1yHwsxVLytYMxw38U8Myc68/yxtD9/5hu0l8GfmKogrqXFScDGxZYfXqS+5LcnuRnh6oB\nKODOJPcmuWSB9UuZt76sBW5YZN1Y8wFwWFVt65afAw5bYMyY8wJwMZMjsIXs6jnsw6Xdy49rF3kZ\ntNvz0ewJvyRvA74CXF5Vr8xbvZHJoe/PA38G/P2Apby7qk4BzgF+M8mZA25rUUn2Bc4H/m6B1WPO\nxw5qckz7pv5JKsmVwOvA9YsMGfo5/CKT7tjvBLYBf9THg44Z/q3AMXOuH93dtuCYJHsDBwH/1Xch\nSfZhEvzrq+rm+eur6pWq+p9u+TZgnySH9l1H9/hbu58vALcwOXybaynz1odzgI1V9fwCNY42H53n\nt7+06X6+sMCYUeYlyUXAecAHu19Eb7CE53AmVfV8Vf2wqn4E/MUij7/b8zFm+L8NnJDkuG4vsxa4\ndd6YW4HtZ20/AHx9sQmfVncO4Rpgc1V9bpExh28/15DkVCbzNMQvoRVJDty+zOQE04Pzht0K/Hp3\n1v804OU5h8R9uoBFDvnHmo855v4/uBD46gJj7gDOSrKyOww+q7utN0nOBq4Azq+q7y8yZinP4ax1\nzD3H8/5FHn8p+dpRH2cod+NM5rlMzq4/AVzZ3fb7TCYXYH8mh51bgH8Fjh+ghnczOYy8H9jUXc4F\nPgp8tBtzKfAQkzOmdwNnDDQfx3fbuK/b3vY5mVtLgC90c/YAsGqAOlYwCfNBc24bZT6Y/MLZBrzG\n5HXqR5ic57kLeBz4R+CQbuwq4Oo59724+7+yBfjwAHVsYfI6evv/k+1/iToSuG1nz2HPdfxN99zf\nzyTQR8yvY7F87eziO/ykRjV7wk9qneGXGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlR/wd8t8yfhk3f\nRQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns675aaKlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n47F6JCMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJHzwzCmHogM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c07d70f-9ddc-408e-fb4e-780716c638d1"
      },
      "source": [
        "%pwd\n",
        "%cd data"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9IZQNO4Ft1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acfe4366-299f-4bfb-b4e5-e6613d278497"
      },
      "source": [
        "%cd \n",
        "b = nn.MSELoss()\n",
        "\n",
        "avg = np.load(\"dset4_avg.npy\")\n",
        "std = np.load(\"dset4_std.npy\")\n",
        "apbln = [1,0,0,0,1] # think this is correct\n",
        "    \n",
        "wrapper_full(\"first_run_full_data\", 10, structure, b, avg, std, apbln, lr = 0.005, epochs = 200, batch_size = 200)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24 0\n",
            "48 48\n",
            "0 24\n",
            "0 12\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[24 48]\n",
            "[48 24 12  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n",
            "/content/drive/My Drive/masters_project/data\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "0\n",
            "MSE_LOSS: 145302.2203587354\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "1\n",
            "MSE_LOSS: 72652.03628519017\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "2\n",
            "MSE_LOSS: 48438.182867390635\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "3\n",
            "MSE_LOSS: 36329.51423142968\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "4\n",
            "MSE_LOSS: 29065.089749351067\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "5\n",
            "MSE_LOSS: 24223.370107759405\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "6\n",
            "MSE_LOSS: 20763.350747561744\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "7\n",
            "MSE_LOSS: 18168.19658851392\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "8\n",
            "MSE_LOSS: 16149.767855407812\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "9\n",
            "MSE_LOSS: 29016.42144649172\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "10\n",
            "MSE_LOSS: 26378.628576756226\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "11\n",
            "MSE_LOSS: 24181.089932838895\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "12\n",
            "MSE_LOSS: 22321.14780907466\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "13\n",
            "MSE_LOSS: 20726.955830952094\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "14\n",
            "MSE_LOSS: 19345.25486245273\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "15\n",
            "MSE_LOSS: 18136.619976238242\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "16\n",
            "MSE_LOSS: 17135.691968259252\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "17\n",
            "MSE_LOSS: 16183.904008511166\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "18\n",
            "MSE_LOSS: 15332.625080427446\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "19\n",
            "MSE_LOSS: 14566.129946865145\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "20\n",
            "MSE_LOSS: 13873.821603890783\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "21\n",
            "MSE_LOSS: 13245.23440608071\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "22\n",
            "MSE_LOSS: 12671.977734298865\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "23\n",
            "MSE_LOSS: 12144.20712467201\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "24\n",
            "MSE_LOSS: 11660.689702437128\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "25\n",
            "MSE_LOSS: 11212.36972954659\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "26\n",
            "MSE_LOSS: 10797.123362641103\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "27\n",
            "MSE_LOSS: 15584.953845470876\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "28\n",
            "MSE_LOSS: 15047.712558312734\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "29\n",
            "MSE_LOSS: 14546.292443653623\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "30\n",
            "MSE_LOSS: 14077.529951917733\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "31\n",
            "MSE_LOSS: 13637.631436559912\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "32\n",
            "MSE_LOSS: 13227.852569797495\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "33\n",
            "MSE_LOSS: 12838.85790827671\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "34\n",
            "MSE_LOSS: 12472.100136269786\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "35\n",
            "MSE_LOSS: 16148.945278851179\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "36\n",
            "MSE_LOSS: 19626.309340155876\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "37\n",
            "MSE_LOSS: 19111.178115612125\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "38\n",
            "MSE_LOSS: 18633.237617432333\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "39\n",
            "MSE_LOSS: 18167.572350153805\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "40\n",
            "MSE_LOSS: 17725.923739954887\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "41\n",
            "MSE_LOSS: 17303.92273109082\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "42\n",
            "MSE_LOSS: 16909.489482984798\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "43\n",
            "MSE_LOSS: 16525.241037304946\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "44\n",
            "MSE_LOSS: 16158.802055126233\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "45\n",
            "MSE_LOSS: 15818.544274491667\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "46\n",
            "MSE_LOSS: 15481.98968398388\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "47\n",
            "MSE_LOSS: 15159.475944024312\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "48\n",
            "MSE_LOSS: 14850.277693536658\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "49\n",
            "MSE_LOSS: 14553.304671087228\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "50\n",
            "MSE_LOSS: 14268.02133898738\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "51\n",
            "MSE_LOSS: 13993.663369721671\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "52\n",
            "MSE_LOSS: 13730.742253668821\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "53\n",
            "MSE_LOSS: 13485.328296420452\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "54\n",
            "MSE_LOSS: 13241.767251961202\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "55\n",
            "MSE_LOSS: 13005.49748743925\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "56\n",
            "MSE_LOSS: 15317.859872763693\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "57\n",
            "MSE_LOSS: 15053.796472349359\n",
            "FINISHING ONE PASS\n",
            "torch.Size([50, 1, 5, 16, 16])\n",
            "torch.Size([50, 16, 16])\n",
            "BATCH:\n",
            "58\n",
            "MSE_LOSS: 14798.666729327972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-a102ad0d7820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapbln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# think this is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwrapper_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first_run_full_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapbln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-204b3c4fa103>\u001b[0m in \u001b[0;36mwrapper_full\u001b[0;34m(name, optimizer, structure, loss_func, avg, std, application_boolean, lr, epochs, kernel_size, batch_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# does is matter that we arent returning the model?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_enc_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# open csv file for saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-f69231e37303>\u001b[0m in \u001b[0;36mtrain_enc_dec\u001b[0;34m(model, optimizer, dataloader, loss_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# enables training for model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print(\"training\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# send to cuda.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-079a2bf33118>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;34m\"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m# is of batch size, seq length,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}