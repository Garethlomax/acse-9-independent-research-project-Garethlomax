{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/full_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1onVYuKcDt",
        "colab_type": "text"
      },
      "source": [
        "#imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgHHu2lwKF0S",
        "colab_type": "code",
        "outputId": "caa5f802-4b58-4a79-eb50-320ab9b120aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2k695HbKic0",
        "colab_type": "code",
        "outputId": "4b498dea-42ab-4a40-978c-5b479fe95688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3521 sha256=b7328c07369ce5b805ac37a72e1f99d4a7f084a159e66eed6b00a20134cad71e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0y9nWYUKmsy",
        "colab_type": "code",
        "outputId": "dd3d3a5f-8663-496d-c1bf-ecb2e8680e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.519s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHqL0wCqKr6O",
        "colab_type": "text"
      },
      "source": [
        "## snippet to investigate ram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8VGlxIDKq8t",
        "colab_type": "code",
        "outputId": "fdbb3abb-01f0-4b68-91a7-193530154923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=28caf21ab46e116cc15c68182297ab6ce447c44874166a5d0aadf06cdce74489\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.9 GB  | Proc size: 309.0 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbWslp2UKzwn",
        "colab_type": "code",
        "outputId": "db2b17e8-90d6-4da6-a441-9ded80a3bfac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Fp3Nk3K03D",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqrux9tK2ap",
        "colab_type": "code",
        "outputId": "7107a89c-d629-48de-f3a9-eb043f456b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--S3DiL3KcVy",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CELL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj3Icdv2K8z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dR0F-kKKcYD",
        "colab_type": "text"
      },
      "source": [
        "# lstm full unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jt5nXmELFjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSvkO-LjLL_h",
        "colab_type": "text"
      },
      "source": [
        "# lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NYS0hX5LI0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbyJ0SfNLVVT",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8YZKbahLin2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qppFhApXLlIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_iKjRtJ-PL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z4SHaDXKcap",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khitUnTHLu0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPCRgC06L0ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d6g-caEL4-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BL54iWHMUtj",
        "colab_type": "text"
      },
      "source": [
        "#TRAINING FUNCTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtQQVIoxMWnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R8deKvmMblY",
        "colab_type": "code",
        "outputId": "8ae810aa-05fa-49b2-899a-99579636ef14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88zV9JwqN3c7",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAdu0-tVN51S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "        truth -= self.avg[0]\n",
        "        truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG-2m6rnOLPz",
        "colab_type": "text"
      },
      "source": [
        "# wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS33z7MHOMIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrapper_full(name, optimizer,  structure, loss_func, avg, std, application_boolean, lr = None, epochs = 50, kernel_size = 3, batch_size = 50):\n",
        "    f = open(name + \".csv\", 'w') # open csv file for saving\n",
        "    \n",
        "    model = LSTMencdec_onestep(structure, 5, kernel_size = kernel_size).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr, amsgrad= True)\n",
        "\n",
        "    # put in structure.\n",
        "    f.write(\"Structure: \\n\")\n",
        "\n",
        "    for i in range(len(structure)):\n",
        "        for j in range(len(structure[0])):\n",
        "            f.write(\"{},\".format(structure[i,j]))\n",
        "        f.write(\"\\n\") # new line\n",
        "\n",
        "    f.write(\"Parameters:\\n\")\n",
        "    f.write(\"optimizer, epochs, learning rate, kernel size \\n\")\n",
        "    \n",
        "    if lr != None:\n",
        "        # optimizer problems\n",
        "        \n",
        "        f.write(\"{},{},{},{},{}\\n\".format(\"test\", epochs, lr, kernel_size, batch_size))\n",
        "    else:\n",
        "        f.write(\"{},{},{},{},{}\\n\".format(\"othertest\", epochs, \"Default\", kernel_size, batch_size))\n",
        "        \n",
        "    f.write(\"loss_func:\\n\")\n",
        "    f.write(loss_func.__repr__() + \"\\n\")\n",
        "    \n",
        "    f.write(\"optimizer:\\n\")\n",
        "    f.write(optimizer.__repr__() + \"\\n\")\n",
        "    \n",
        "    f.write(\"\\n\\n\\n\")\n",
        "    f.write(\"TRAINING\\n\")\n",
        "    \n",
        "    # now we define the training functions\n",
        "#     train, valid = initialise_dataset_HDF5()\n",
        "    \n",
        "#     index_map = np.arange(0, 93620,1)# dummy index_map just to make sure trains correctly. \n",
        "#     train = HDF5Dataset_with_avgs('data_prio_run_test5.hdf5', list(index_map),avg, std, apbln)\n",
        "    \"\"\"CHANGED THE ABOVE TO LIST - BETTER INDEXING?\"\"\"\n",
        "    # put model together with different size\n",
        "    # model test - put it together.\n",
        "    # now we train the model\n",
        "    \n",
        "    train, valid = initialise_dataset_HDF5_full('data_prio_run_test5.hdf5', valid_frac = 0.1, dataset_length = 93620,avg = avg, std = std, application_boolean=application_boolean)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # ignore this one.\n",
        "    \n",
        "#     model, optimizer = train_main(test_model, 1, train, valid, epochs = epochs, batch_size = 50)\n",
        "\n",
        "    loss_func = loss_func\n",
        "    \n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr = lr, amsgrad= True)\n",
        "    \n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    f.close()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    valid_loader = DataLoader(valid, batch_size = 2000, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        # does is matter that we arent returning the model?\n",
        "        _, loss = train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        torch.save(optimizer.state_dict(), name+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), name+str(epoch)+\".pth\")\n",
        "        \n",
        "        valid_loss = validate(model, valid_loader, loss_func = loss_func) # validation - need to shuffle split.\n",
        "        \n",
        "        f = open(name + \".csv\", 'a') # open csv file for saving\n",
        "\n",
        "        f.write(str(loss) + \",\" + str(valid_loss) + \"\\n\")\n",
        "        \n",
        "        f.close()\n",
        "\n",
        "#         torch.save(optimizer.state_dict(), name+str(epoch)+\".pth\")\n",
        "#         torch.save(model.state_dict(), name+str(epoch)+\".pth\")\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mdz5tVBMlur",
        "colab_type": "text"
      },
      "source": [
        "# RUN CODE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TPlTW4-Mnnn",
        "colab_type": "code",
        "outputId": "57d448a4-dda3-4504-f66d-0ade36a1b4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# changed \n",
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 3).to(device)\n",
        "# print(\"seq length\", test_model.decoder.seq_length)\n",
        "# optim = torch.optim.Adam(test_model.parameters())\n",
        "\n",
        "\n",
        "\n",
        "# train_enc = train_enc_dec(test_model,)\n",
        "\n",
        "\n",
        "# train_main(test_model, 1, train, valid, epochs = 2, batch_size = 50)\n",
        "\n",
        "# model, optimizer = train_main(test_model, 1, train, valid, epochs = 50, batch_size = 50)\n",
        "\n",
        "\n",
        "# torch.save(optimizer.state_dict(), F\"Finished_opt_bce.pth\")\n",
        "# torch.save(model.state_dict(), F\"Finished_mod_bce.pth\")\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TYKFxzkqYOm",
        "colab_type": "text"
      },
      "source": [
        "# testing produced model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A24NFOEfrVZF",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTfdUYlVrUhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uutCfsFirX9j",
        "colab_type": "text"
      },
      "source": [
        "## regular "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl08yN7IqZ_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa04dc8c-e9df-4d57-b789-99f9ed946cfd"
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 3)).to(device) # added data parrallel\n",
        "test_model.load_state_dict(torch.load(F\"valid_test149.pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnOz5ZgIqrWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "623dae2c-2ca2-44ac-cb6c-e4d916d6cb30"
      },
      "source": [
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('data_min_events_25.hdf5', valid_frac = 0.1, dataset_length = 52109,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGIPCB90HL8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(valid, batch_size = 2000, shuffle = True) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyss5kSqex1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_loader = DataLoader(train, batch_size = 200, shuffle = False) # implement moving MNIST data input\n",
        "\n",
        "# test_image_save(test_model, train_loader, \"reduced_dataset_149_epochs_sample_167\", sample = 167)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmd9vsfQv_PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOV4WOMc-WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del test_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndy7HcwXWg_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2e6b3a9-a4d5-4fb4-9b7a-12715e64f9b5"
      },
      "source": [
        "losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVcGC-jWabOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save(\"distribution_of_loss_5000valid_min_events_25.npy\", losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STLS9_A-XG79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBiLvpXXKM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "3ee3dccb-7fb7-45af-857f-f465a36816d4"
      },
      "source": [
        "sns.distplot(losses)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5fdc109b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RLGW6HT78tI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4zigH0Y79eH",
        "colab_type": "text"
      },
      "source": [
        "# dummy code for testing softmax ect\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHfNKQgV8Gb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a,b in train_loader:\n",
        "    break\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNDqZAwTVM11",
        "colab_type": "text"
      },
      "source": [
        "## testing bceloss with logits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT4S3bMiVgI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fd26fd01-62d9-49b4-b8ea-ec5877be506d"
      },
      "source": [
        "bce = nn.BCEWithLogitsLoss()\n",
        "mse = nn.MSELoss()\n",
        "bce_plain = nn.BCELoss()\n",
        "sig = nn.Sigmoid()\n",
        "\n",
        "i = np.array([0,0,1])\n",
        "j = np.array([-10,-10, 10])\n",
        "i_t = torch.tensor(i).double()\n",
        "j_t = torch.tensor(j).double()\n",
        "\n",
        "# a1 = a[0][0][0]\n",
        "# a2 = a[0][0][1]\n",
        "# print(bce_plain(a1,a1))\n",
        "# print(bce(a1,a1))\n",
        "# print(mse(a1,a1))\n",
        "# a3 = sig(a1)\n",
        "# print(bce_plain(i_t,i_t))\n",
        "# print(bce(i_t, i_t))\n",
        "print(bce(j_t, i_t))\n",
        "print(mse(j_t, i_t))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.5399e-05, dtype=torch.float64)\n",
            "tensor(93.6667, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4E1n3oQWzZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0bd197b-5d55-48ef-a1f7-173ac3192233"
      },
      "source": [
        "b.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2000, 16, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-jIe1Q3VQmO",
        "colab_type": "text"
      },
      "source": [
        "## softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAS2F_8eVL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z-waVy58dWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3d1fd4b1-8c75-43ef-f7b3-a14fda550998"
      },
      "source": [
        "\n",
        "plt.imshow(a[12][0][0])\n",
        "\n",
        "d = a[12][0][1]\n",
        "# soft = nn.Softmax2d()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY3F2FraEZvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "17a988b4-183e-4805-af54-dc99b7617b7b"
      },
      "source": [
        "plt.imshow(d)\n",
        "d = d.view(-1)\n",
        "l = nn.functional.softmax(d, dim = 0)\n",
        "l = l.view(16,16)\n",
        "plt.figure()\n",
        "plt.imshow(l)\n",
        "\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5fdc6dc278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfqlRhl9qlOGXGmX4pUb9P1eD0dmRVYTOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noFaOcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikUZPKYlFsER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b16a2bba-f656-482a-a061-5fdaf361106f"
      },
      "source": [
        "l.sum()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000, dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKxqDbbSFQQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "af4bac12-1bbd-4ab4-9dd3-77b35631f3b2"
      },
      "source": [
        "print(l)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.4250, 0.0115, 0.0006, 0.0006, 0.0006, 0.0070, 0.3146, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0772, 0.0025, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0017, 0.0038, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0013, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0007, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0014,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
            "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,\n",
            "         0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006]],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyop50eJEYL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = nn.Softmax(2)(d.view(*d.size()[:2], -1)).view_as(d)\n",
        "\n",
        "# print(a[0][0][0:1].shape)\n",
        "# ans = soft(a[0][0:1][0:1])\n",
        "# ans = nn.functional.softmax(a[0][0][0])\n",
        "plt.figure()\n",
        "# plt.imshow(ans[0][0])\n",
        "plt.imshow(y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiCSbQPeAu8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c378f211-2095-48ce-a6e5-f92c0690a6bc"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02,  3.6060e+01, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02,  8.1706e+01,  1.4554e-01,  1.8510e+00,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "          1.3494e+00, -5.5105e-02,  1.4554e-01, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02,  2.9545e+00, -5.5105e-02,  1.2491e+00,  2.2523e+00,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02,  9.4810e-01, -5.5105e-02,  1.0484e+00, -5.5105e-02,\n",
              "          3.4618e-01],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02,  1.6503e+00, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02],\n",
              "        [-5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02, -5.5105e-02,\n",
              "         -5.5105e-02, -5.5105e-02, -5.5105e-02,  2.4586e-01, -5.5105e-02,\n",
              "         -5.5105e-02]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZRQUpSV8EFx",
        "colab_type": "text"
      },
      "source": [
        "# end of dummy code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giegZ9y1J6JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# events = []\n",
        "# # len(np.where(a[0,:,0] > 0)[0])\n",
        "# for i in range(200):\n",
        "#     print(len(np.where(a[i,:,0] > 0)[0]))\n",
        "#     events.append(len(np.where(a[i,:,0] > 0)[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsIuiteQMaAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k = np.bincount(events)\n",
        "# plt.plot(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5-S4UHXNCPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(events)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8c1ea4qK7-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP0ZWy5nwDO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a.shape\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(10):\n",
        "#     plt.figure()\n",
        "    \n",
        "#     plt.imshow(a[78][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8M9PO3Aqapo",
        "colab_type": "text"
      },
      "source": [
        "# more training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU4BDp-b3O7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pwd\n",
        "# %cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2FAh1DC2_oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k = h5py.File(\"data_prio_run_test5.hdf5\", 'r')\n",
        "# print(k['predictor'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaJb4x183W6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k.close()\n",
        "# k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf7jg7zc3nRd",
        "colab_type": "code",
        "outputId": "5e8a9d04-7fea-454c-ad8f-f492ec27fc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%pwd\n",
        "%cd /content/drive/My\\ Drive/masters_project/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lhoqrmP2Tws",
        "colab_type": "code",
        "outputId": "c2d48bb3-2e17-4947-8e48-56c9ea718c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "b = nn.MSELoss()\n",
        "\n",
        "avg = np.load(\"dset5_avg.npy\")\n",
        "std = np.load(\"dset5_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "    \n",
        "wrapper_full(\"valid_test\", 10, structure, b, avg, std, apbln, lr = 0.005, epochs = 1, batch_size = 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n",
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "0\n",
            "MSE_LOSS: 1.7294187123608953\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "1\n",
            "MSE_LOSS: 1.7636074693314892\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "2\n",
            "MSE_LOSS: 1.7299998539582235\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "3\n",
            "MSE_LOSS: 1.704885969381194\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "4\n",
            "MSE_LOSS: 1.7058646044361248\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "5\n",
            "MSE_LOSS: 1.7069451073157247\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "6\n",
            "MSE_LOSS: 1.6974868950286748\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "7\n",
            "MSE_LOSS: 1.6781633440856911\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "8\n",
            "MSE_LOSS: 1.6749964453564747\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "9\n",
            "MSE_LOSS: 1.679622567997067\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "10\n",
            "MSE_LOSS: 1.6829038790456872\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "11\n",
            "MSE_LOSS: 1.6704121601682564\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "12\n",
            "MSE_LOSS: 1.6706351084779194\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "13\n",
            "MSE_LOSS: 1.6694494718395678\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "14\n",
            "MSE_LOSS: 1.659349935106095\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "15\n",
            "MSE_LOSS: 1.672306795920245\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "16\n",
            "MSE_LOSS: 1.6661316380067164\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "17\n",
            "MSE_LOSS: 1.6697224041624013\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "18\n",
            "MSE_LOSS: 1.6696521773425197\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "19\n",
            "MSE_LOSS: 1.6693500912861825\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "20\n",
            "MSE_LOSS: 1.6714335192446783\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "21\n",
            "MSE_LOSS: 1.6697227792799374\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "22\n",
            "MSE_LOSS: 1.6737414576740264\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "23\n",
            "MSE_LOSS: 1.6741169691730364\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "24\n",
            "MSE_LOSS: 1.6760240353744624\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "25\n",
            "MSE_LOSS: 1.6789059319918904\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "26\n",
            "MSE_LOSS: 1.6799562086038253\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "27\n",
            "MSE_LOSS: 1.6785990874251364\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "28\n",
            "MSE_LOSS: 1.6788800352415012\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "29\n",
            "MSE_LOSS: 1.678996449444791\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "30\n",
            "MSE_LOSS: 1.6776635565915148\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "31\n",
            "MSE_LOSS: 1.6809514966370236\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "32\n",
            "MSE_LOSS: 1.6793207078197028\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "33\n",
            "MSE_LOSS: 1.6756457546704944\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "34\n",
            "MSE_LOSS: 1.6749738496754003\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "35\n",
            "MSE_LOSS: 1.6741671645480651\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "36\n",
            "MSE_LOSS: 1.669122074298539\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "37\n",
            "MSE_LOSS: 1.662549475647329\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "38\n",
            "MSE_LOSS: 1.6615108365639746\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "39\n",
            "MSE_LOSS: 1.6545041052521015\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "40\n",
            "MSE_LOSS: 1.652937479176311\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "41\n",
            "MSE_LOSS: 1.6512963072739812\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "42\n",
            "MSE_LOSS: 1.6508832123199833\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "43\n",
            "MSE_LOSS: 1.6502546807422485\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "44\n",
            "MSE_LOSS: 1.6513529265176412\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "45\n",
            "MSE_LOSS: 1.6502477405500493\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "46\n",
            "MSE_LOSS: 1.6512846730504283\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "47\n",
            "MSE_LOSS: 1.650704726593182\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "48\n",
            "MSE_LOSS: 1.6519995864852395\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "49\n",
            "MSE_LOSS: 1.6499553678357908\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "50\n",
            "MSE_LOSS: 1.6476867523199406\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "51\n",
            "MSE_LOSS: 1.6461460871182145\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "52\n",
            "MSE_LOSS: 1.6443838976321221\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "53\n",
            "MSE_LOSS: 1.6432132607296945\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "54\n",
            "MSE_LOSS: 1.6439764098735834\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "55\n",
            "MSE_LOSS: 1.6417575302405774\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "56\n",
            "MSE_LOSS: 1.6395516758094193\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "57\n",
            "MSE_LOSS: 1.638609201050739\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "58\n",
            "MSE_LOSS: 1.637302574417477\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "59\n",
            "MSE_LOSS: 1.6371411242498966\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "60\n",
            "MSE_LOSS: 1.6374937707528485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-0346444901c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mapbln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# think this is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwrapper_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapbln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-65fc03697745>\u001b[0m in \u001b[0;36mwrapper_full\u001b[0;34m(name, optimizer, structure, loss_func, avg, std, application_boolean, lr, epochs, kernel_size, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# does is matter that we arent returning the model?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_enc_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-871fb556def9>\u001b[0m in \u001b[0;36mtrain_enc_dec\u001b[0;34m(model, optimizer, dataloader, loss_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# enables training for model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print(\"training\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# send to cuda.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-285a4e7b49bc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;34m\"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m#         print(\"predictor shape:\", predictor.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# is of batch size, seq length,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q29pFNMoOg4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = np.zeros((50,1,1,16,16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nefIDQzoOnbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1[:,0,0].shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kulxvr-3G9RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pwd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuOuuQUBW8v6",
        "colab_type": "text"
      },
      "source": [
        "# trying to unfuck averaging \n",
        "\n",
        "todo - put simple occurance of conflict as prediction - occurance of massive events - way bigger than average lead to issues with non gaussian distribution of event sizes. \n",
        "use binary to predict.\n",
        "re run dataset creation tonight and add single binary prediction\n",
        "- powerlaw transformation?\n",
        "- double check what the loss function is comparing. \n",
        "- make example where it imshows just for fun so can see what the inputs are.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L2iuV5GqdMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pwd\n",
        "# %cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKk1EIXUXwFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avg = np.load(\"dset4_avg.npy\")\n",
        "# std = np.load(\"dset4_std.npy\")\n",
        "# apbln = [1,0,0,0,1] # think this is correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRTblglIXyl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ELkwJ8HMMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd ..\n",
        "# index_map = np.arange(0,84485,1)\n",
        "# train = HDF5Dataset_with_avgs('data_prio_run_test4.hdf5', list(index_map),avg, std, apbln)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nquiRWWaeV_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred = train[0:200][0]\n",
        "\n",
        "# tru = train[0:200][1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CghmBSi7nkrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWef8waDnqAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tru.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGalPmdIqvg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj9hQMw7siXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -4.4e-2 == -0.044"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdOToLkq_Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # event 164 has massive mseloss due to large error\n",
        "# pred[164][-1][0].unique(return_counts = True) # why not lots of -0.44 ect \n",
        "# # plt.imshow(pred[164][-1][0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubUHdh1qrSr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tru[164].unique(return_counts = True) \n",
        "# # pred[164][-1][0].shape\n",
        "\n",
        "\n",
        "# # plt.imshow(tru[164])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5lUsVkdnzIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b(pred[164][-1][0],tru[164])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQpw9FEKoYZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tot = 0\n",
        "# for i in range(200):\n",
        "#     print(i)\n",
        "#     print(b(pred[i][-1][0], tru[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca_cEykSooKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQUaOOUregUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(pred[0][-1][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tttv1E-ck9GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(tru[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMj4c3H9eoG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(tru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHqZrAbPk_bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tru"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAQ4Ai4nervO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b(pred[0][0], tru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oFJmQRyRI-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # d = train[20000]\n",
        "# d = train[20000:20010]\n",
        "# print(d[0].shape)\n",
        "# plt.imshow(d[1][0])\n",
        "# o = d[0][0]\n",
        "# for i in range(10):\n",
        "#     plt.figure()\n",
        "#     plt.imshow(o[i][0])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJHzwzCmHogM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pwd\n",
        "# %cd data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9IZQNO4Ft1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd \n",
        "# b = nn.MSELoss()\n",
        "\n",
        "# avg = np.load(\"dset4_avg.npy\")\n",
        "# std = np.load(\"dset4_std.npy\")\n",
        "# apbln = [1,0,0,0,1] # think this is correct\n",
        "    \n",
        "# wrapper_full(\"first_run_full_data\", 10, structure, b, avg, std, apbln, lr = 0.005, epochs = 200, batch_size = 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X5y90Hn9ALr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}