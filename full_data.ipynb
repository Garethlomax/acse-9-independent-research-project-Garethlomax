{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "full_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-Garethlomax/blob/full_data_run/full_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1onVYuKcDt",
        "colab_type": "text"
      },
      "source": [
        "#imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgHHu2lwKF0S",
        "colab_type": "code",
        "outputId": "caa5f802-4b58-4a79-eb50-320ab9b120aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2k695HbKic0",
        "colab_type": "code",
        "outputId": "4b498dea-42ab-4a40-978c-5b479fe95688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/MovingMNIST-master\n",
        "\n",
        "# all torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "# importing moving mnist test set.\n",
        "from MovingMNIST import MovingMNIST\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorch-summary-master\n",
        "from torchsummary import summary\n",
        "\n",
        "# %cd /content/drive/My \\Drive/masters_project/python_modules/pytorch_modelsize-master\n",
        "\n",
        "%cd /content/drive/My \\Drive/masters_project/python_modules/pytorchvis-master\n",
        "\n",
        "!pip install torchviz\n",
        "\n",
        "%cd /content/drive/My\\ Drive/masters_project/python_modules/pytorch-ssim-master\n",
        "import pytorch_ssim # cite this \n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/python_modules/MovingMNIST-master\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "[Errno 2] No such file or directory: '/content/drive/My Drive/masters_project/python_modules/pytorchvis-master'\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-summary-master\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3521 sha256=b7328c07369ce5b805ac37a72e1f99d4a7f084a159e66eed6b00a20134cad71e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "/content/drive/My Drive/masters_project/python_modules/pytorch-ssim-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0y9nWYUKmsy",
        "colab_type": "code",
        "outputId": "dd3d3a5f-8663-496d-c1bf-ecb2e8680e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "h5py.run_tests()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".....................................................x...................................................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss..................\n",
            "----------------------------------------------------------------------\n",
            "Ran 457 tests in 1.519s\n",
            "\n",
            "OK (skipped=14, expected failures=6)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHqL0wCqKr6O",
        "colab_type": "text"
      },
      "source": [
        "## snippet to investigate ram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8VGlxIDKq8t",
        "colab_type": "code",
        "outputId": "fdbb3abb-01f0-4b68-91a7-193530154923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=28caf21ab46e116cc15c68182297ab6ce447c44874166a5d0aadf06cdce74489\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.9 GB  | Proc size: 309.0 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbWslp2UKzwn",
        "colab_type": "code",
        "outputId": "db2b17e8-90d6-4da6-a441-9ded80a3bfac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Fp3Nk3K03D",
        "colab_type": "text"
      },
      "source": [
        "## cuda imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poqrux9tK2ap",
        "colab_type": "code",
        "outputId": "7107a89c-d629-48de-f3a9-eb043f456b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    print(\"GPUs:\", torch.cuda.device_count())\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")\n",
        "    \n",
        "    \n",
        "import random\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "  \n",
        "set_seed(42)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n",
            "GPUs: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--S3DiL3KcVy",
        "colab_type": "text"
      },
      "source": [
        "# LSTM CELL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj3Icdv2K8z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: CUDIFY EVERYTHING\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSTMunit(nn.Module):\n",
        "    def __init__(self, input_channel_no, hidden_channels_no, kernel_size, stride = 1):\n",
        "        super(LSTMunit, self).__init__()\n",
        "        \"\"\"base unit for an overall convLSTM structure. convLSTM exists in keras but\n",
        "        not pytorch. LSTMunit repersents one cell in an overall convLSTM encoder decoder format\n",
        "        the structure of convLSTMs lend themselves well to compartmentalising the LSTM\n",
        "        cells. \n",
        "    \n",
        "        Each cell takes an input the data at the current timestep Xt, and a hidden\n",
        "        representation from the previous timestep Ht-1\n",
        "    \n",
        "        Each cell outputs Ht\n",
        "        \"\"\"\n",
        "    \n",
        "    \n",
        "        self.input_channels = input_channel_no\n",
        "    \n",
        "        self.output_channels = hidden_channels_no\n",
        "    \n",
        "        self.kernel_size = kernel_size\n",
        "    \n",
        "        self.padding = (int((self.kernel_size - 1) / 2 ), int((self.kernel_size - 1) / 2 ))#to ensure output image same dims as input\n",
        "        # as in conv nowcasting - see references \n",
        "        self.stride = stride # for same reasons as above\n",
        "        \n",
        "        # need convolutions, cells, tanh, sigmoid?\n",
        "        # need input size for the lstm - on size of layers.\n",
        "        # cannot do this because of the modules not being registered when stored in a list\n",
        "        # can if we convert it to a parameter dict\n",
        "    \n",
        "        # list of names of filter to put in dictionary.\n",
        "        # some of these are not convolutions\n",
        "        \"\"\"TODO: CHANGE THIS LAYOUT OF CONVOLUTIONAL LAYERS. \"\"\"\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.filter_name_list = ['Wxi', 'Wxf', 'Wxc', 'Wxo','Whi', 'Whf', 'Whc', 'Who']\n",
        "        \n",
        "        \"\"\" TODO : DEAL WITH BIAS HERE. \"\"\" \n",
        "        \"\"\" TODO: CAN INCLUDE BIAS IN ONE OF THE CONVOLUTIONS BUT NOT ALL OF THEM - OR COULD INCLUDE IN ALL? \"\"\"\n",
        "\n",
        "        # list of concolution instances for each lstm cell step\n",
        "       #  nn.Conv2d(1, 48, kernel_size=3, stride=1, padding=0),\n",
        "        self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False).cuda() for i in range(4)]\n",
        "#         self.conv_list = [nn.Conv2d(self.input_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = False) for i in range(4)]\n",
        "\n",
        "#         self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True)).double() for i in range(4)]\n",
        "\n",
        "        self.conv_list = self.conv_list + [(nn.Conv2d(self.output_channels, self.output_channels, kernel_size =  self.kernel_size, stride = self.stride, padding = self.padding, bias = True).cuda()).double() for i in range(4)]\n",
        "#         self.conv_list = nn.ModuleList(self.conv_list)\n",
        "        # stores nicely in dictionary for compact readability.\n",
        "        # most ML code is uncommented and utterly unreadable. Here we try to avoid this\n",
        "        self.conv_dict = nn.ModuleDict(zip(self.filter_name_list, self.conv_list))\n",
        "    \n",
        "        # may be able to combine all the filters and combine all the things to be convolved - as long as there is no cross layer convolution\n",
        "        # technically the filter will be the same? - check this later.\n",
        "    \n",
        "        # set up W_co, W_cf, W_co as variables.\n",
        "        \"\"\" TODO: decide whether this should be put into function. \"\"\"\n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: put correct dimensions of tensor in shape\"\"\"\n",
        "        \n",
        "        # of dimensions seq length, hidden layers, height, width\n",
        "        \"\"\"TODO: DEFINE THESE SYMBOLS. \"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN CONSTRUCTOR.\"\"\"\n",
        "        shape = [1, self.output_channels, 16, 16]\n",
        "        \n",
        "        self.Wco = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wcf = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        self.Wci = nn.Parameter((torch.zeros(shape).double()).cuda(), requires_grad = True)\n",
        "        \n",
        "        \n",
        "#         self.Wco = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wcf = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wci = nn.Parameter((torch.zeros(shape).double()), requires_grad = True)\n",
        "#         self.Wco.name = \"test\"\n",
        "#         self.Wco = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wcf = torch.zeros(shape, requires_grad = True).double()\n",
        "#         self.Wci = torch.zeros(shape, requires_grad = True).double()\n",
        "\n",
        "        # activation functions.\n",
        "        self.tanh = torch.tanh\n",
        "        self.sig  = torch.sigmoid\n",
        "\n",
        "#     (1, 6, kernel_size=5, padding=2, stride=1).double()\n",
        "    def forward(self, x, h, c):\n",
        "        \"\"\" put the various nets in here - instanciate the other convolutions.\"\"\"\n",
        "        \"\"\"TODO: SORT BIAS OUT HERE\"\"\"\n",
        "        \"\"\"TODO: PUT THIS IN SELECTOR FUNCTION? SO ONLY PUT IN WXI ECT TO MAKE EASIER TO DEBUG?\"\"\"\n",
        "#         print(\"size of x is:\")\n",
        "#         print(x.shape)\n",
        "        # ERROR IS IN LINE 20\n",
        "        #print(self.conv_dict['Wxi'](x).shape)\n",
        "#         print(\"X:\")\n",
        "#         print(x.is_cuda)\n",
        "#         print(\"H:\")\n",
        "#         print(h.is_cuda)\n",
        "#         print(\"C\")\n",
        "#         print(c.is_cuda)\n",
        "        \n",
        "        i_t = self.sig(self.conv_dict['Wxi'](x) + self.conv_dict['Whi'](h) + self.Wci * c)\n",
        "        f_t = self.sig(self.conv_dict['Wxf'](x) + self.conv_dict['Whf'](h) + self.Wcf * c)\n",
        "        c_t = f_t * c + i_t * self.tanh(self.conv_dict['Wxc'](x) + self.conv_dict['Whc'](h))\n",
        "        o_t = self.sig(self.conv_dict['Wxo'](x) + self.conv_dict['Who'](h) + self.Wco * c_t)\n",
        "        h_t = o_t * self.tanh(c_t)\n",
        "        \n",
        "        return h_t, c_t\n",
        "    \n",
        "    def copy_in(self):\n",
        "        \"\"\"dummy function to copy in the internals of the output in the various architectures i.e encoder decoder format\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dR0F-kKKcYD",
        "colab_type": "text"
      },
      "source": [
        "# lstm full unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jt5nXmELFjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TODO: IMPORTANT \n",
        "WHEN COPYING STATES OVER, INITIAL STATE OF DECODER IS BOTH LAST H AND LAST C \n",
        "FROM THE LSTM BEING COPIED FROM.\n",
        "\n",
        "WE ALSO NEED TO INCLUDE THE ABILITY TO OUTPUT THE LAST H AND C AT EACH TIMESTEP\n",
        "AS INPUT.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\" SEQUENCE, BATCH SIZE, LAYERS, HEIGHT, WIDTH\"\"\"\n",
        "\n",
        "class LSTMmain(nn.Module):\n",
        "    \n",
        "    \n",
        "    \"\"\" collection of units to form encoder/ decoder branches - decide which are which\n",
        "    need funcitonality to copy in and copy out outputs.\n",
        "    \n",
        "    \n",
        "    layer output is array of booleans selectively outputing for each layer i.e \n",
        "    for three layer can have output on second and third but not first with \n",
        "    layer_output = [0,1,1]\"\"\"\n",
        "    \n",
        "    \"\"\"TODO: DECIDE ON OUTPUT OF HIDDEN CHANNEL LIST \"\"\"\n",
        "    def __init__(self, shape, input_channel_no, hidden_channel_no, kernel_size, layer_output, test_input, copy_bool = False, debug = False, save_outputs = True, decoder = False, second_debug = False):\n",
        "        super(LSTMmain, self).__init__()\n",
        "        \n",
        "        \"\"\"TODO: USE THIS AS BASIS FOR ENCODER DECODER.\"\"\"\n",
        "        \"\"\"TODO: SPECIFY SHAPE OF INPUT VECTOR\"\"\"\n",
        "        \n",
        "        \"\"\"TODO: FIGURE OUT HOW TO IMPLEMENT ENCODER DECODER ARCHITECUTRE\"\"\"\n",
        "        self.copy_bool = copy_bool\n",
        "        \n",
        "        self.test_input = test_input\n",
        "        \n",
        "        self.debug = debug\n",
        "        self.second_debug = second_debug\n",
        "        self.save_all_outputs = save_outputs\n",
        "        \n",
        "        self.shape = shape\n",
        "        \n",
        "        \"\"\"specify dimensions of shape - as in channel length ect. figure out once put it in a dataloader\"\"\"\n",
        "        \n",
        "        self.layers = len(test_input) #number of layers in the encoder. \n",
        "        \n",
        "        self.seq_length = shape[1]\n",
        "        \n",
        "        self.enc_len = len(shape)\n",
        "        \n",
        "        self.input_chans = input_channel_no\n",
        "        \n",
        "        self.hidden_chans = hidden_channel_no\n",
        "        \n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.layer_output = layer_output\n",
        "        \n",
        "        # initialise the different conv cells. \n",
        "#         self.unit_list = [LSTMunit(input_channel_no, hidden_channel_no, kernel_size) for i in range(self.enc_len)]\n",
        "        self.dummy_list = [input_channel_no] + list(self.test_input) # allows test input to be an array\n",
        "        if self.debug:\n",
        "            print(\"dummy_list:\")\n",
        "            print(self.dummy_list)\n",
        "            \n",
        "#         self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        self.unit_list = nn.ModuleList([(LSTMunit(self.dummy_list[i], self.dummy_list[i+1], kernel_size).double()).cuda() for i in range(len(self.test_input))])\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"number of units:\")\n",
        "            print(len(self.unit_list))\n",
        "#             print(\"number of \")\n",
        "\n",
        "#         self.unit_list = nn.ModuleList(self.unit_list)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, copy_in = False, copy_out = [False, False, False]):\n",
        "#     def forward(self, x):\n",
        "#         copy_in = False\n",
        "#         copy_out = [False, False, False]\n",
        "\n",
        "        \n",
        "#         print(\"IS X CUDA?\")\n",
        "#         print(x.is_cuda)\n",
        "        \"\"\"loop over layers, then over hidden states\n",
        "        \n",
        "        copy_in is either False or is [[h,c],[h,c]] ect.\n",
        "        \n",
        "        THIS IN NOW CHANGED TO COPY IN \n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        internal_outputs = []\n",
        "        \"\"\"TODO: HOW MANY OUTPUTS TO SAVE\"\"\"\n",
        "        \"\"\" S \"\"\"\n",
        "        \n",
        "        \"\"\" TODO: PUT INITIAL ZERO THROUGH THE SYSTEM TO DEFINE H AND C\"\"\"\n",
        "        \n",
        "        layer_output = [] # empty list to save each h and c for each step. \n",
        "        \"\"\"TODO: DECIDE WHETHER THE ABOVE SHOULD BE ARRAY OR NOT\"\"\"\n",
        "        \n",
        "        # x is 5th dimensional tensor.\n",
        "        # x is of size batch, sequence, layers, height, width\n",
        "        \n",
        "        \"\"\"TODO: INITIALISE THESE WITH VECTORS.\"\"\"\n",
        "        # these need to be of dimensions (batchsizze, hidden_dim, heigh, width)\n",
        "        \n",
        "        size = x.shape\n",
        "        \n",
        "        # need to re arrange the outputs. \n",
        "        \n",
        "        \n",
        "        \"\"\"TODO: SORT OUT H SIZING. \"\"\"\n",
        "        \n",
        "        batch_size = size[0]\n",
        "        # change this. h should be of dimensions hidden size, hidden size.\n",
        "        h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "        h_shape[1] = self.hidden_chans\n",
        "        if self.debug:\n",
        "            print(\"h_shape:\")\n",
        "            print(h_shape)\n",
        "        \n",
        "        # size should be (seq, batch_size, layers, height, weight)\n",
        "        \n",
        "        \n",
        "        empty_start_vectors = []\n",
        "        \n",
        "        \n",
        "        #### new method of copying vectors. copy_bool, assigned during object \n",
        "        # construction now deals iwth copying in values.\n",
        "        # copy in is still used to supply the tensor values. \n",
        "    \n",
        "        k = 0 # to count through our input state list.\n",
        "        for i in range(self.layers):\n",
        "            if self.copy_bool[i]: # if copy bool is true for this layer\n",
        "                # check purpose of h_shape in below code.\n",
        "                empty_start_vectors.append(copy_in[k])\n",
        "                # copies in state for that layer\n",
        "                \"\"\"TODO: CHECK IF THIS NEEDS TO BE DETATCHED OR NOT\"\"\"\n",
        "                k += 1 # iterate through input list.\n",
        "            \n",
        "            else: # i.e if false\n",
        "                assert self.copy_bool[i] == False, \"copy_bool arent bools\"\n",
        "                \n",
        "                h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "                h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "                empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "        del k # clear up k so no spare variables flying about.\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             \"\"\"CHANGED: NOW HAS COPY IN COPY OUT BASED ON [[0,0][H,C]] FORMAT\"\"\"\n",
        "#             if copy_in == False: # i.e if no copying in occurs then proceed as normal\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "# #                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "# #             elif copy_in[i] == [0,0]:\n",
        "#             elif isinstance(copy_in[i], list):\n",
        "\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 # if no copying in in alternate format\n",
        "#                 h_shape = list(x.shape[:1] + x.shape[2:]) # seq is second, we miss it with fancy indexing\n",
        "#                 h_shape[1] = self.dummy_list[i+1] # check indexing. \n",
        "#                 empty_start_vectors.append([(torch.zeros(h_shape).double()).cuda(), (torch.zeros(h_shape).double()).cuda()])\n",
        "                \n",
        "#             else: # copy in the provided vectors\n",
        "#                 assert (len(copy_in) == self.layers), \"Length disparity between layers, copy in format\"\n",
        "\n",
        "#                 \"\"\"TODO: DECIDE WHETHER TO CHANGE THIS TO AN ASSERT BASED OFF TYPE OF TENSOR.\"\"\"\n",
        "#                 empty_start_vectors.append(copy_in[i])\n",
        "                \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "#         empty_start_vectors = [[torch.zeros(h_shape), torch.zeros(h_shape)] for i in range(self.layers)]\n",
        "        \n",
        "        \n",
        "        \n",
        "        if self.debug:\n",
        "            for i in empty_start_vectors:\n",
        "                print(i[0].shape)\n",
        "            print(\" \\n \\n \\n\")\n",
        "        \n",
        "#         for i in range(self.layers):\n",
        "#             empty_start_vectors.append([torch.tensor()])\n",
        "        \n",
        "        total_outputs = []\n",
        "        \n",
        "        \n",
        "        for i in range(self.layers):\n",
        "            \n",
        "            \n",
        "            layer_output = []\n",
        "            if self.debug:\n",
        "                print(\"layer iteration:\")\n",
        "                print(i)\n",
        "            # for each in layer\n",
        "\n",
        "            \"\"\"AS WE PUT IN ZEROS EACH TIME THIS MAKES OUR LSTM STATELESS\"\"\"\n",
        "            # initialise with zero or noisy vectors \n",
        "            # at start of each layer put noisy vector in \n",
        "            # look at tricks paper to find more effective ideas of how to put this in\n",
        "            # do we have to initialise with 0 tensors after we go to the second layer\n",
        "            # or does the h carry over???\n",
        "            \"\"\"TODO: REVIEW THIS CHANGE\"\"\"\n",
        "            \n",
        "            # copy in for each layer. \n",
        "            # this is used for encoder decoder architectures.\n",
        "            # default is to put in empty vectors. \n",
        "            \n",
        "            \"\"\"TODO: REVIEW THIS SECTION\"\"\"\n",
        "            \"\"\"CHANGED: TO ALWAYS CHOOSE H AND C\"\"\"\n",
        "#             if copy_in == False:\n",
        "#                 h, c = empty_start_vectors[i]\n",
        "#             else: h, c = copy_in[i]\n",
        "\n",
        "            h, c = empty_start_vectors[i] \n",
        "                \n",
        "            if self.debug:\n",
        "                print(\"new h shape\")\n",
        "                print(h.shape)\n",
        "                \n",
        "            \"\"\"TODO: DO WE HAVE TO PUT BLANK VECTORS IN AT EACH TIMESTEP?\"\"\"\n",
        "            \n",
        "            # need to initialise zero states for c and h. \n",
        "            for j in range(self.seq_length):\n",
        "                if self.debug:\n",
        "                    print(\"inner loop iteration:\")\n",
        "                    print(j)\n",
        "                if self.debug:\n",
        "                    print(\"x dtype is:\" , x.dtype)\n",
        "                # for each step in the sequence\n",
        "                # put x through \n",
        "                # i.e put through each x value at a given time.\n",
        "                \n",
        "                \"\"\"TODO: PUT H IN FROM PREVIOUS LAYER, BUT C SHOULD BE ZEROS AT START\"\"\"\n",
        "                \n",
        "                if self.debug:\n",
        "                    print(\"inner loop size:\")\n",
        "                    print(x[:,j].shape)\n",
        "                    print(\"h size:\")\n",
        "                    print(h.shape)\n",
        "                    \n",
        "                h, c = self.unit_list[i](x[:,j], h, c)\n",
        "                \n",
        "                # this is record for each output in given layer.\n",
        "                # this depends whether copying out it enabld \n",
        "#                 i\n",
        "                layer_output.append([h, c])\n",
        "                \n",
        "            \"\"\"TODO: IMPLEMENT THIS\"\"\"\n",
        "#             if self.save_all_outputs[i]:\n",
        "#                 total_outputs.append(layer_outputs[:,0]) # saves h from each of the layer outputs\n",
        "                \n",
        "            # output \n",
        "            \"\"\"OUTSIDE OF SEQ LOOP\"\"\"\n",
        "            \"\"\"TODO: CHANGE TO NEW OUTPUT METHOD.\"\"\"\n",
        "            if copy_out[i] == True:\n",
        "                # if we want to copy out the contents of this layer:\n",
        "                internal_outputs.append(layer_output[-1])\n",
        "                # saves last state and memory which can be subsequently unrolled.\n",
        "                # when used in an encoder decoder format.\n",
        "            \"\"\"removed else statement\"\"\"\n",
        "#             else:\n",
        "#                 internal_outputs.append([0,0])\n",
        "                # saves null variable so we can check whats being sent out.\n",
        "            \n",
        "            \n",
        "            h_output = [i[0] for i in layer_output] #layer_output[:,0] # take h from each timestep.\n",
        "            if self.debug:\n",
        "                print(\"h_output is of size:\")\n",
        "                print(h_output[0].shape)\n",
        "                \n",
        "                      \n",
        "            \"\"\"TODO: REVIEW IF 1 IS THE CORRECT AXIS TO CONCATENATE THE VECTORS ALONG\"\"\"\n",
        "            # we now use h as the predictor input to the other layers.\n",
        "            \"\"\"TODO: STACK TENSORS ALONG NEW AXIS. \"\"\"\n",
        "            \n",
        "            \n",
        "            x = torch.stack(h_output,0)\n",
        "            x = torch.transpose(x, 0, 1)\n",
        "            if self.second_debug:\n",
        "                print(\"x shape in LSTM main:\" , x.shape)\n",
        "            if self.debug:\n",
        "                print(\"x reshaped dimensions:\")\n",
        "                print(x.shape)\n",
        "        \n",
        "#         x = torch.zeros(x.shape)\n",
        "#         x.requires_grad = True\n",
        "        return x , internal_outputs # return new h in tensor form. do we need to cudify this stuff\n",
        "\n",
        "    def initialise(self):\n",
        "        \"\"\"put through zeros to start everything\"\"\"\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSvkO-LjLL_h",
        "colab_type": "text"
      },
      "source": [
        "# lstm enc dec onestep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NYS0hX5LI0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test2 = LSTMmain(shape, 1, 3, 5, [1], test_input = [1,2], debug = False).double()\n",
        "\n",
        "\n",
        "\n",
        "class LSTMencdec_onestep(nn.Module):\n",
        "    \"\"\"structure is overall architecture of \"\"\"\n",
        "    def __init__(self, structure, input_channels, kernel_size = 5, debug = True):\n",
        "        super(LSTMencdec_onestep, self).__init__()\n",
        "#         assert isinstance(structure, np.array), \"structure should be a 2d numpy array\"\n",
        "        assert len(structure.shape) == 2, \"structure should be a 2d numpy array with two rows\"\n",
        "        self.debug = debug\n",
        "        \n",
        "        \"\"\"TODO: MAKE KERNEL SIZE A LIST SO CAN SPECIFY AT EACH JUNCTURE.\"\"\"\n",
        "        shape = [1,10,3,16,16]\n",
        "        \n",
        "        self.structure = structure\n",
        "        \"\"\"STRUCTURE IS AN ARRAY - CANNOT USE [] + [] LIST CONCATENATION - WAS ADDING ONE ONTO THE ARRAY THING.\"\"\"\n",
        "        self.input_channels = input_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        \"\"\"TODO: ASSERT THAT DATATYPE IS INT.\"\"\"\n",
        "        \n",
        "        self.enc_shape, self.dec_shape, self.enc_copy_out, self.dec_copy_in = self.input_test()\n",
        "        \n",
        "        if self.debug:\n",
        "            print(\"enc_shape, dec_shape, enc_copy_out, dec_copy_in:\")\n",
        "            print(self.enc_shape)\n",
        "            print(self.dec_shape)\n",
        "            print(self.enc_copy_out)\n",
        "            print(self.dec_copy_in)\n",
        "            \n",
        "        \n",
        "        \n",
        "#         self.sig = nn.Sigmoid()\n",
        "        \n",
        "         # why does this have +1 at third input and decoder hasnt?????? \n",
        "        \n",
        "        self.encoder = LSTMmain(shape, self.input_channels, len(self.enc_shape)+1, self.kernel_size, layer_output = self.enc_copy_out, test_input = self.enc_shape, copy_bool = [False for k in range(len(self.enc_shape))]  ).cuda()\n",
        "        # now one step in sequence\n",
        "        shape = [1,1,1,64,64]\n",
        "\n",
        "        self.decoder = LSTMmain(shape, self.enc_shape[-1], len(self.dec_shape), self.kernel_size, layer_output = 1, test_input = self.dec_shape, copy_bool = self.dec_copy_in,  second_debug = False).cuda()\n",
        "        \n",
        "        \n",
        "        \n",
        "        # initialise encoder and decoder network\n",
        "    \n",
        "    def input_test(self):\n",
        "        \"\"\"check input structure to make sure there is overlap between encoder \n",
        "        and decoder.\n",
        "        \"\"\"\n",
        "        copy_grid = []\n",
        "        # finds dimensions of the encoder\n",
        "        enc_layer = self.structure[0]\n",
        "        enc_shape = enc_layer[enc_layer!=0]\n",
        "        dec_layer = self.structure[1]\n",
        "        dec_shape = dec_layer[dec_layer!=0]\n",
        "#         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        #set up boolean grid of where the overlaps are.\n",
        "        for i in range(len(enc_layer)):\n",
        "            if self.debug:\n",
        "                print(enc_layer[i], dec_layer[i])\n",
        "            if (enc_layer[i] != 0) and (dec_layer[i] != 0):\n",
        "                copy_grid.append(True)\n",
        "            else:\n",
        "                copy_grid.append(False)\n",
        "                \n",
        "                \n",
        "        enc_overlap = copy_grid[:len(enc_layer)-1]\n",
        "        \n",
        "        num_dec_zeros = len(dec_layer[dec_layer==0]) # will this break if no zeros?\n",
        "        \n",
        "        dec_overlap = copy_grid[num_dec_zeros:]\n",
        "        \n",
        "        return enc_shape, dec_shape, enc_overlap, dec_overlap\n",
        "        \n",
        "#         dec_overlap = copy_grid[]                \n",
        "        \n",
        "                \n",
        "                \n",
        "#         [[1,2,3,0],\n",
        "#          [0,2,3,1]]\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x, out_states = self.encoder(x, copy_in = False, copy_out = self.enc_copy_out)\n",
        "        \n",
        "#         print(\"length of out_states:\", len(out_states))\n",
        "#         print(\"contents out outstates are as follows:\")\n",
        "#         for i in out_states:\n",
        "#             print(\"----------------------------------\")\n",
        "#             print(\"first object type:\", type(i[0]))\n",
        "# #             print(\"length of object:\", len(i[0]))\n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        dummy_input = torch.zeros(x.shape)\n",
        "        # technically a conditional loader - put x in there \n",
        "        # puts in the last one as input - should make shorter. \n",
        "        # presume coming out in the correct order - next try reversing to see if that helps \n",
        "        x = x[:,-1:,:,:,:]\n",
        "#         print(\"x shape encoder:\", x.shape)\n",
        "#         print(x.shape)\n",
        "        \n",
        "        \n",
        "        res, _ = self.decoder(x, copy_in = out_states, copy_out = [False, False, False,False, False])\n",
        "        print(\"FINISHING ONE PASS\")\n",
        "#         res = self.sig(res)\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbyJ0SfNLVVT",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8YZKbahLin2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        \n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qppFhApXLlIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5(valid_frac = 0.1, dataset_length = 9000):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset(\"train_set.hdf5\", index_map = train_index)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset(\"test_set.hdf5\", index_map = valid_index)\n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_iKjRtJ-PL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset_HDF5_full(dataset, valid_frac = 0.1, dataset_length = 9000, avg = 0, std = 0, application_boolean = [0,0,0,0,0]):\n",
        "    \"\"\"\n",
        "    Returns datasets for training and validation. \n",
        "    \n",
        "    Loads in datasets segmenting for validation fractions.\n",
        "   \n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    if valid_frac != 0:\n",
        "        \n",
        "        dummy = np.array(range(dataset_length)) # clean this up - not really needed\n",
        "        \n",
        "        train_index, valid_index = validation_split(dummy, n_splits = 1, valid_fraction = 0.1, random_state = 0)\n",
        "        \n",
        "        train_dataset = HDF5Dataset_with_avgs(dataset,train_index, avg, std, application_boolean)\n",
        "        \n",
        "        valid_dataset = HDF5Dataset_with_avgs(dataset,valid_index, avg, std, application_boolean)\n",
        "        \n",
        "        \n",
        "        return train_dataset, valid_dataset\n",
        "        \n",
        "    else:\n",
        "        print(\"not a valid fraction for validation\") # turn this into an assert.\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z4SHaDXKcap",
        "colab_type": "text"
      },
      "source": [
        "# shuffling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khitUnTHLu0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation_split(data, n_splits = 1, valid_fraction = 0.1, random_state = 0):\n",
        "    \"\"\"\n",
        "    Function to produce a validation set from test set.\n",
        "    THIS SHUFFLES THE SAMPLES. __NOT__ THE SEQUENCES.\n",
        "    \"\"\"\n",
        "    dummy_array = np.zeros(len(data))\n",
        "    split = StratifiedShuffleSplit(n_splits, test_size = valid_fraction, random_state = 0)\n",
        "    generator = split.split(torch.tensor(dummy_array), torch.tensor(dummy_array))\n",
        "    return [(a,b) for a, b in generator][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPCRgC06L0ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unsqueeze_data(data):\n",
        "    \"\"\"\n",
        "    Takes in moving MNIST object - must then account for \n",
        "    \"\"\"\n",
        "    \n",
        "    # split moving mnist data into predictor and ground truth.\n",
        "    predictor = data[:][0].unsqueeze(2)\n",
        "    predictor = predictor.double()\n",
        "        \n",
        "    truth = data[:][1].unsqueeze(2)# this should be the moving mnist sent in\n",
        "    truth = truth.double()\n",
        "    \n",
        "    return predictor, truth\n",
        "    # the data should now be unsqueezed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d6g-caEL4-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialise_dataset(data):\n",
        "    # unsqueeze data, adding a channel dimension for later convolution. \n",
        "    # this also gets rid of the annoying tuple format\n",
        "    predictor, truth = unsqueeze_data(data)\n",
        "    \n",
        "    train_index, valid_index = validation_split(data)\n",
        "    \n",
        "    train_predictor = predictor[train_index]\n",
        "    valid_predictor = predictor[valid_index]\n",
        "    \n",
        "    train_truth = truth[train_index]\n",
        "    valid_truth = truth[valid_index]\n",
        "    \n",
        "    train_dataset = SequenceDataset(train_predictor, train_truth)\n",
        "    valid_dataset = SequenceDataset(valid_predictor, valid_truth)\n",
        "    \n",
        "    return train_dataset, valid_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BL54iWHMUtj",
        "colab_type": "text"
      },
      "source": [
        "#TRAINING FUNCTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtQQVIoxMWnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comb_loss_func(pred, y):\n",
        "    \"\"\"hopefully should work like kl and bce for VAE\"\"\"\n",
        "    mse = nn.MSELoss()\n",
        "    ssim = pytorch_ssim.SSIM()\n",
        "    mse_loss = mse(pred, y[:,:1,:,:,:])\n",
        "    ssim_loss = -ssim(pred[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    return mse_loss + ssim_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R8deKvmMblY",
        "colab_type": "code",
        "outputId": "8ae810aa-05fa-49b2-899a-99579636ef14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/My\\ Drive/masters_project/data/models\n",
        "def train_enc_dec(model, optimizer, dataloader, loss_func = nn.MSELoss()):\n",
        "    \"\"\"\n",
        "    training function \n",
        "    \n",
        "    by default mseloss\n",
        "    \n",
        "    could try brier score.\n",
        "    \n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    model.train() # enables training for model. \n",
        "    tot_loss = 0\n",
        "    for x, y in dataloader:\n",
        "#         print(\"training\")\n",
        "        x = x.to(device) # send to cuda.\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad() # zeros saved gradients in the optimizer.\n",
        "        # prevents multiple stacking of gradients\n",
        "        # this is important to do before we evaluate the model as the \n",
        "        # model is currenly in model.train() mode\n",
        "        \n",
        "        prediction = model(x) #x should be properly formatted - of size\n",
        "        \"\"\"THIS DOESNT DEAL WITH SEQUENCE LENGTH VARIANCE OF PREDICTION OR Y\"\"\"\n",
        "        \n",
        "#         print(\"the size of prediction is:\", prediction.shape)\n",
        "        #last image sequence.\n",
        "    \n",
        "        \"\"\"ACTUAL FUNCTION THATS BEEN COMMENTED OUT.\"\"\"\n",
        "#         loss = loss_func(prediction, y[:,:1,:,:,:])\n",
        "        \"\"\"CHANGED BECAUSE \"\"\"\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        loss = loss_func(prediction[:,0,0], y)\n",
        "        \n",
        "\n",
        "#         loss = comb_loss_func(prediction, y)\n",
        "#         print(prediction.shape)\n",
        "#         print(y[:,:1,:,:,:].shape)\n",
        "        \"\"\"commented out \"\"\"\n",
        "#         loss = - loss_func(prediction[:,0,:,:,:], y[:,0,:,:,:])\n",
        "    \n",
        "# ssim_out = -ssim_loss(train[0][0][-1:],  x[0])\n",
        "# ssim_value = - ssim_out.data\n",
        "    \n",
        "    \n",
        "        \n",
        "        loss.backward() # differentiates to find minimum.\n",
        "#         printm()\n",
        "\n",
        "        ##\n",
        "\n",
        "    # implement the interpreteable stuff here.\n",
        "        # as it is very unlikely we predict every pixel correctly we will not \n",
        "        # use accuracy. \n",
        "        # technically this is a regression problem, not a classification.\n",
        "        \n",
        "        \n",
        "        optimizer.step() # steps forward the optimizer.\n",
        "        # uses loss.backward() to give gradient. \n",
        "        # loss is negative.\n",
        "#         del x # make sure the garbage is collected.\n",
        "#         del y\n",
        "        \"\"\"commented it out\"\"\"\n",
        "        tot_loss += loss.item() # .data.item() \n",
        "        print(\"BATCH:\")\n",
        "        print(i)\n",
        "        i += 1\n",
        "#         if i == 20:\n",
        "#             break\n",
        "        print(\"MSE_LOSS:\", tot_loss / i)\n",
        "    return model, tot_loss / i # trainloss, trainaccuracy \n",
        "\n",
        "def validate(model, dataloader, loss_func = nn.MSELoss()):\n",
        "    \n",
        "    \"\"\"as for train_enc_dec but without training - and acting upon validation\n",
        "    data set\n",
        "    \"\"\"\n",
        "    tot_loss = 0\n",
        "    i = 0\n",
        "    model.eval() # puts out of train mode so we do not mess up our gradients\n",
        "    for x, y in dataloader:\n",
        "        with torch.no_grad(): # no longer have to specify tensors \n",
        "            # as volatile = True. as of modern pytorch use torch.no_grad.\n",
        "            \n",
        "            x = x.to(device) # send to cuda. need to change = sign as to(device)\n",
        "            y = y.to(device) # produces a copy on thd gpu not moves it. \n",
        "            prediction = model(x)\n",
        "            \n",
        "            loss = loss_func(prediction[:,0,0], y)\n",
        "            \n",
        "            tot_loss += loss.item()\n",
        "            i += 1\n",
        "            \n",
        "            print(\"MSE_VALIDATION_LOSS:\", tot_loss / i)\n",
        "            \n",
        "    \n",
        "    \n",
        "    return tot_loss / i # returns total loss averaged across the dataset. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_main(model, params, train, valid, epochs = 30, batch_size = 1):\n",
        "    # make sure model is ported to cuda\n",
        "    # make sure seed has been specified if testing comparative approaches\n",
        "    \n",
        "#     if model.is_cuda == False:\n",
        "#         model.to(device)\n",
        "    \n",
        "    # initialise optimizer on model parameters \n",
        "    # chann\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, amsgrad= True)\n",
        "    loss_func = nn.MSELoss()\n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    validation_loader = DataLoader(valid, batch_size = batch_size, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        \n",
        "        torch.save(optimizer.state_dict(), F\"Adam_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), F\"Test_new_ams_changed\"+str(epoch)+\".pth\")\n",
        "        \n",
        "        \n",
        "#         validate(model, validation_loader)\n",
        "        \n",
        "    return model, optimizer\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88zV9JwqN3c7",
        "colab_type": "text"
      },
      "source": [
        "# hdf5 with avgs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAdu0-tVN51S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HDF5Dataset_with_avgs(Dataset):\n",
        "    \"\"\"dataset wrapper for hdf5 dataset to allow for lazy loading of data. This \n",
        "    allows ram to be conserved. \n",
        "    \n",
        "    As the hdf5 dataset is not partitioned into test and validation, the dataset \n",
        "    takes a shuffled list of indices to allow specification of training and \n",
        "    validation sets.\n",
        "    \n",
        "    MAKE SURE TO CALL DEL ON GENERATED OBJECTS OTHERWISE WE WILL CLOG UP RAM\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path, index_map, avg, std, application_boolean, transform = None):\n",
        "        \n",
        "        %cd /content/drive/My \\Drive/masters_project/data \n",
        "        # changes directory to the one where needed.\n",
        "        \n",
        "        self.path = path\n",
        "        \n",
        "        self.index_map = index_map # maps to the index in the validation split\n",
        "        # due to hdf5 lazy loading index map must be in ascending order.\n",
        "        # this may be an issue as we should shuffle our dataset.\n",
        "        # this will be raised as an issue as we consider a work around.\n",
        "        # we should keep index map shuffled, and take the selection from the \n",
        "        # shuffled map and select in ascending order. \n",
        "        self.avg = avg\n",
        "        self.std = std\n",
        "        self.application_boolean = application_boolean\n",
        "        \n",
        "        self.file = h5py.File(path, 'r')\n",
        "        \n",
        "#         for i in range(len(application_boolean)):\n",
        "#             # i.e gaussian transformation doesnt happen. (x - mu / sigma)\n",
        "#             if application_boolean == 0:\n",
        "#                 self.avg[i] = 0\n",
        "#                 self.std[i] = 1\n",
        "        \n",
        "        \n",
        "         \n",
        "          \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.index_map)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        \n",
        "        i = self.index_map[i] # index maps from validation set to select new orders\n",
        "#         print(i)\n",
        "        if isinstance(i, list): # if i is a list. \n",
        "            i.sort() # sorts into ascending order as specified above\n",
        "            \n",
        "        \"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\n",
        "        \n",
        "        predictor = torch.tensor(self.file[\"predictor\"][i])\n",
        "#         print(\"predictor shape:\", predictor.shape)\n",
        "        # is of batch size, seq length, \n",
        "        \n",
        "        \n",
        "        truth = torch.tensor(self.file[\"truth\"][i])\n",
        "#         print(\"truth shape:\", truth.shape)\n",
        "        # only on layer so not in loop.\n",
        "        truth -= self.avg[0]\n",
        "        truth /= self.std[0]\n",
        "        \n",
        "        if isinstance(i, list):\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,:,j] -= self.avg[j]\n",
        "                    predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "                \n",
        "        else:\n",
        "            for j in range(len(self.avg)):\n",
        "                if self.application_boolean[j]:\n",
        "                    predictor[:,j] -= self.avg[j]\n",
        "                    predictor[:,j] /= self.std[j]\n",
        "                \n",
        "            \n",
        "#             #i.e if we are returning a single index.\n",
        "# #         # the value of truth should be [0] in the predictor array. \n",
        "#         for j in range(len(self.avg)):\n",
        "#             if self.application_boolean[j]:\n",
        "#                 predictor[:,:,j] -= self.avg[j]\n",
        "#                 predictor[:,:,j] /= self.std[j]\n",
        "                \n",
        "#                 # sort out dimensions of truth at some point \n",
        "        \n",
        "        \n",
        "                \n",
        "            \n",
        "        \n",
        "        return predictor, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG-2m6rnOLPz",
        "colab_type": "text"
      },
      "source": [
        "# wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS33z7MHOMIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrapper_full(name, optimizer,  structure, loss_func, avg, std, application_boolean, lr = None, epochs = 50, kernel_size = 3, batch_size = 50):\n",
        "    f = open(name + \".csv\", 'w') # open csv file for saving\n",
        "    \n",
        "    model = LSTMencdec_onestep(structure, 5, kernel_size = kernel_size).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr, amsgrad= True)\n",
        "\n",
        "    # put in structure.\n",
        "    f.write(\"Structure: \\n\")\n",
        "\n",
        "    for i in range(len(structure)):\n",
        "        for j in range(len(structure[0])):\n",
        "            f.write(\"{},\".format(structure[i,j]))\n",
        "        f.write(\"\\n\") # new line\n",
        "\n",
        "    f.write(\"Parameters:\\n\")\n",
        "    f.write(\"optimizer, epochs, learning rate, kernel size \\n\")\n",
        "    \n",
        "    if lr != None:\n",
        "        # optimizer problems\n",
        "        \n",
        "        f.write(\"{},{},{},{},{}\\n\".format(\"test\", epochs, lr, kernel_size, batch_size))\n",
        "    else:\n",
        "        f.write(\"{},{},{},{},{}\\n\".format(\"othertest\", epochs, \"Default\", kernel_size, batch_size))\n",
        "        \n",
        "    f.write(\"loss_func:\\n\")\n",
        "    f.write(loss_func.__repr__() + \"\\n\")\n",
        "    \n",
        "    f.write(\"optimizer:\\n\")\n",
        "    f.write(optimizer.__repr__() + \"\\n\")\n",
        "    \n",
        "    f.write(\"\\n\\n\\n\")\n",
        "    f.write(\"TRAINING\\n\")\n",
        "    \n",
        "    # now we define the training functions\n",
        "#     train, valid = initialise_dataset_HDF5()\n",
        "    \n",
        "#     index_map = np.arange(0, 93620,1)# dummy index_map just to make sure trains correctly. \n",
        "#     train = HDF5Dataset_with_avgs('data_prio_run_test5.hdf5', list(index_map),avg, std, apbln)\n",
        "    \"\"\"CHANGED THE ABOVE TO LIST - BETTER INDEXING?\"\"\"\n",
        "    # put model together with different size\n",
        "    # model test - put it together.\n",
        "    # now we train the model\n",
        "    \n",
        "    train, valid = initialise_dataset_HDF5_full('data_prio_run_test5.hdf5', valid_frac = 0.1, dataset_length = 93620,avg = avg, std = std, application_boolean=application_boolean)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # ignore this one.\n",
        "    \n",
        "#     model, optimizer = train_main(test_model, 1, train, valid, epochs = epochs, batch_size = 50)\n",
        "\n",
        "    loss_func = loss_func\n",
        "    \n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr = lr, amsgrad= True)\n",
        "    \n",
        "#     loss_func = nn.BCELoss()\n",
        "#     loss_func = pytorch_ssim.SSIM()\n",
        "    f.close()\n",
        "    \n",
        "    train_loader = DataLoader(train, batch_size = batch_size, shuffle = True) # implement moving MNIST data input\n",
        "    valid_loader = DataLoader(valid, batch_size = 2000, shuffle = False) # implement moving MNIST\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        # does is matter that we arent returning the model?\n",
        "        _, loss = train_enc_dec(model, optimizer, train_loader, loss_func = loss_func) # changed\n",
        "        \n",
        "        torch.save(optimizer.state_dict(), name+str(epoch)+\".pth\")\n",
        "        torch.save(model.state_dict(), name+str(epoch)+\".pth\")\n",
        "        \n",
        "        valid_loss = validate(model, valid_loader, loss_func = loss_func) # validation - need to shuffle split.\n",
        "        \n",
        "        f = open(name + \".csv\", 'a') # open csv file for saving\n",
        "\n",
        "        f.write(str(loss) + \",\" + str(valid_loss) + \"\\n\")\n",
        "        \n",
        "        f.close()\n",
        "\n",
        "#         torch.save(optimizer.state_dict(), name+str(epoch)+\".pth\")\n",
        "#         torch.save(model.state_dict(), name+str(epoch)+\".pth\")\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mdz5tVBMlur",
        "colab_type": "text"
      },
      "source": [
        "# RUN CODE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TPlTW4-Mnnn",
        "colab_type": "code",
        "outputId": "57d448a4-dda3-4504-f66d-0ade36a1b4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# changed \n",
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "test_model = LSTMencdec_onestep(structure, 1, kernel_size = 3).to(device)\n",
        "# print(\"seq length\", test_model.decoder.seq_length)\n",
        "# optim = torch.optim.Adam(test_model.parameters())\n",
        "\n",
        "\n",
        "\n",
        "# train_enc = train_enc_dec(test_model,)\n",
        "\n",
        "\n",
        "# train_main(test_model, 1, train, valid, epochs = 2, batch_size = 50)\n",
        "\n",
        "# model, optimizer = train_main(test_model, 1, train, valid, epochs = 50, batch_size = 50)\n",
        "\n",
        "\n",
        "# torch.save(optimizer.state_dict(), F\"Finished_opt_bce.pth\")\n",
        "# torch.save(model.state_dict(), F\"Finished_mod_bce.pth\")\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TYKFxzkqYOm",
        "colab_type": "text"
      },
      "source": [
        "# testing produced model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A24NFOEfrVZF",
        "colab_type": "text"
      },
      "source": [
        "## save fig def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTfdUYlVrUhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_save(model, train_loader, name, sample = 7):\n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "\n",
        "    x = x.cpu()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    fig, axes = plt.subplots(1,2)\n",
        "    print(x.shape)\n",
        "    print(b.shape)\n",
        "    axes[0].imshow(x[sample][0][0])\n",
        "    axes[1].imshow(b[sample])\n",
        "    \n",
        "    axes[1].set_title(\"truth\")\n",
        "    axes[0].set_title(\"Prediction\")\n",
        "    fig.suptitle(\"Prediction of:\" + name)\n",
        "    fig.savefig(name + \"comparison.pdf\")\n",
        "#     print(b[7])\n",
        "#     print(x[7][0][0])\n",
        "    fig, axes = plt.subplots(10,1,figsize=(32,32))\n",
        "    for i in range(10):\n",
        "        axes[i].imshow(a[sample][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uutCfsFirX9j",
        "colab_type": "text"
      },
      "source": [
        "## regular "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl08yN7IqZ_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa04dc8c-e9df-4d57-b789-99f9ed946cfd"
      },
      "source": [
        "%cd /content/drive/My Drive/masters_project/data/\n",
        "test_model = nn.DataParallel(LSTMencdec_onestep(structure, 5, kernel_size = 3)).to(device) # added data parrallel\n",
        "test_model.load_state_dict(torch.load(F\"valid_test149.pth\"))\n",
        "test_model.eval()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): LSTMencdec_onestep(\n",
              "    (encoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): LSTMmain(\n",
              "      (unit_list): ModuleList(\n",
              "        (0): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (1): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): LSTMunit(\n",
              "          (conv_dict): ModuleDict(\n",
              "            (Wxi): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxf): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxc): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Wxo): Conv2d(6, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (Whi): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whf): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Whc): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            (Who): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnOz5ZgIqrWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "623dae2c-2ca2-44ac-cb6c-e4d916d6cb30"
      },
      "source": [
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "index_map = np.arange(0,52109,1)\n",
        "train, valid = initialise_dataset_HDF5_full('data_min_events_25.hdf5', valid_frac = 0.1, dataset_length = 52109,avg = avg, std = std, application_boolean=apbln)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGIPCB90HL8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(valid, batch_size = 2000, shuffle = True) # implement moving MNIST data input\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyss5kSqex1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_loader = DataLoader(train, batch_size = 200, shuffle = False) # implement moving MNIST data input\n",
        "\n",
        "# test_image_save(test_model, train_loader, \"reduced_dataset_149_epochs_sample_167\", sample = 167)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmd9vsfQv_PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_loss_histogram(model, train_loader):\n",
        "    \n",
        "    model.eval()\n",
        "    # calculate x and prediction \n",
        "    for a, b in train_loader:\n",
        "        # a in input, b is truth\n",
        "        break # train loader cannot be indexed\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "        x = model(a.cuda())\n",
        "    \n",
        "    \n",
        "        x = x.cpu()\n",
        "#     print(x.shape)\n",
        "    # now over each one in x - we do\n",
        "        loss_func = nn.MSELoss()\n",
        "        loss = []\n",
        "        for i in range(len(x)):\n",
        "            loss.append(loss_func(x[i,:,0],b[i:i+1]).item())\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOV4WOMc-WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del test_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndy7HcwXWg_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "5b55e6bd-6034-4737-9a45-d97775a6ace9"
      },
      "source": [
        "losses = batch_loss_histogram(test_model, train_loader)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FINISHING ONE PASS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7acd14bac407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_loss_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-44ac77360118>\u001b[0m in \u001b[0;36mbatch_loss_histogram\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2113\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got -0.146537 at /pytorch/aten/src/THNN/generic/BCECriterion.c:62"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVcGC-jWabOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save(\"distribution_of_loss_5000valid_min_events_25.npy\", losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STLS9_A-XG79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUBiLvpXXKM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "4a7e4bc2-07d9-4050-bddd-9141db60af90"
      },
      "source": [
        "# sns.distplot(losses)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb816cfef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wenND0pCRBwBAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giegZ9y1J6JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# events = []\n",
        "# # len(np.where(a[0,:,0] > 0)[0])\n",
        "# for i in range(200):\n",
        "#     print(len(np.where(a[i,:,0] > 0)[0]))\n",
        "#     events.append(len(np.where(a[i,:,0] > 0)[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsIuiteQMaAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k = np.bincount(events)\n",
        "# plt.plot(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5-S4UHXNCPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.distplot(events)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8c1ea4qK7-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP0ZWy5nwDO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a.shape\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(10):\n",
        "#     plt.figure()\n",
        "    \n",
        "#     plt.imshow(a[78][i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8M9PO3Aqapo",
        "colab_type": "text"
      },
      "source": [
        "# more training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU4BDp-b3O7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pwd\n",
        "# %cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2FAh1DC2_oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k = h5py.File(\"data_prio_run_test5.hdf5\", 'r')\n",
        "# print(k['predictor'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaJb4x183W6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k.close()\n",
        "# k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf7jg7zc3nRd",
        "colab_type": "code",
        "outputId": "5e8a9d04-7fea-454c-ad8f-f492ec27fc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%pwd\n",
        "%cd /content/drive/My\\ Drive/masters_project/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masters_project/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lhoqrmP2Tws",
        "colab_type": "code",
        "outputId": "c2d48bb3-2e17-4947-8e48-56c9ea718c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "b = nn.MSELoss()\n",
        "\n",
        "avg = np.load(\"dset5_avg.npy\")\n",
        "std = np.load(\"dset5_std.npy\")\n",
        "# changed below\n",
        "apbln = [0,1,0,0,1] # think this is correct\n",
        "    \n",
        "wrapper_full(\"valid_test\", 10, structure, b, avg, std, apbln, lr = 0.005, epochs = 1, batch_size = 200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 0\n",
            "24 24\n",
            "0 12\n",
            "0 6\n",
            "0 5\n",
            "enc_shape, dec_shape, enc_copy_out, dec_copy_in:\n",
            "[12 24]\n",
            "[24 12  6  5]\n",
            "[False, True, False, False]\n",
            "[True, False, False, False]\n",
            "/content/drive/My Drive/masters_project/data\n",
            "/content/drive/My Drive/masters_project/data\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "0\n",
            "MSE_LOSS: 1.7294187123608953\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "1\n",
            "MSE_LOSS: 1.7636074693314892\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "2\n",
            "MSE_LOSS: 1.7299998539582235\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "3\n",
            "MSE_LOSS: 1.704885969381194\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "4\n",
            "MSE_LOSS: 1.7058646044361248\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "5\n",
            "MSE_LOSS: 1.7069451073157247\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "6\n",
            "MSE_LOSS: 1.6974868950286748\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "7\n",
            "MSE_LOSS: 1.6781633440856911\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "8\n",
            "MSE_LOSS: 1.6749964453564747\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "9\n",
            "MSE_LOSS: 1.679622567997067\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "10\n",
            "MSE_LOSS: 1.6829038790456872\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "11\n",
            "MSE_LOSS: 1.6704121601682564\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "12\n",
            "MSE_LOSS: 1.6706351084779194\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "13\n",
            "MSE_LOSS: 1.6694494718395678\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "14\n",
            "MSE_LOSS: 1.659349935106095\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "15\n",
            "MSE_LOSS: 1.672306795920245\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "16\n",
            "MSE_LOSS: 1.6661316380067164\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "17\n",
            "MSE_LOSS: 1.6697224041624013\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "18\n",
            "MSE_LOSS: 1.6696521773425197\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "19\n",
            "MSE_LOSS: 1.6693500912861825\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "20\n",
            "MSE_LOSS: 1.6714335192446783\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "21\n",
            "MSE_LOSS: 1.6697227792799374\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "22\n",
            "MSE_LOSS: 1.6737414576740264\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "23\n",
            "MSE_LOSS: 1.6741169691730364\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "24\n",
            "MSE_LOSS: 1.6760240353744624\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "25\n",
            "MSE_LOSS: 1.6789059319918904\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "26\n",
            "MSE_LOSS: 1.6799562086038253\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "27\n",
            "MSE_LOSS: 1.6785990874251364\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "28\n",
            "MSE_LOSS: 1.6788800352415012\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "29\n",
            "MSE_LOSS: 1.678996449444791\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "30\n",
            "MSE_LOSS: 1.6776635565915148\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "31\n",
            "MSE_LOSS: 1.6809514966370236\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "32\n",
            "MSE_LOSS: 1.6793207078197028\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "33\n",
            "MSE_LOSS: 1.6756457546704944\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "34\n",
            "MSE_LOSS: 1.6749738496754003\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "35\n",
            "MSE_LOSS: 1.6741671645480651\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "36\n",
            "MSE_LOSS: 1.669122074298539\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "37\n",
            "MSE_LOSS: 1.662549475647329\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "38\n",
            "MSE_LOSS: 1.6615108365639746\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "39\n",
            "MSE_LOSS: 1.6545041052521015\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "40\n",
            "MSE_LOSS: 1.652937479176311\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "41\n",
            "MSE_LOSS: 1.6512963072739812\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "42\n",
            "MSE_LOSS: 1.6508832123199833\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "43\n",
            "MSE_LOSS: 1.6502546807422485\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "44\n",
            "MSE_LOSS: 1.6513529265176412\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "45\n",
            "MSE_LOSS: 1.6502477405500493\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "46\n",
            "MSE_LOSS: 1.6512846730504283\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "47\n",
            "MSE_LOSS: 1.650704726593182\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "48\n",
            "MSE_LOSS: 1.6519995864852395\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "49\n",
            "MSE_LOSS: 1.6499553678357908\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "50\n",
            "MSE_LOSS: 1.6476867523199406\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "51\n",
            "MSE_LOSS: 1.6461460871182145\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "52\n",
            "MSE_LOSS: 1.6443838976321221\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "53\n",
            "MSE_LOSS: 1.6432132607296945\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "54\n",
            "MSE_LOSS: 1.6439764098735834\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "55\n",
            "MSE_LOSS: 1.6417575302405774\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "56\n",
            "MSE_LOSS: 1.6395516758094193\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "57\n",
            "MSE_LOSS: 1.638609201050739\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "58\n",
            "MSE_LOSS: 1.637302574417477\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "59\n",
            "MSE_LOSS: 1.6371411242498966\n",
            "FINISHING ONE PASS\n",
            "torch.Size([200, 1, 5, 16, 16])\n",
            "torch.Size([200, 16, 16])\n",
            "BATCH:\n",
            "60\n",
            "MSE_LOSS: 1.6374937707528485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-0346444901c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mapbln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# think this is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwrapper_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapbln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-65fc03697745>\u001b[0m in \u001b[0;36mwrapper_full\u001b[0;34m(name, optimizer, structure, loss_func, avg, std, application_boolean, lr, epochs, kernel_size, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# does is matter that we arent returning the model?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_enc_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# changed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-871fb556def9>\u001b[0m in \u001b[0;36mtrain_enc_dec\u001b[0;34m(model, optimizer, dataloader, loss_func)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# enables training for model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtot_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print(\"training\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# send to cuda.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-285a4e7b49bc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;34m\"\"\"TODO: CHECK IF THIS RETURNS DOUBLE\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m#         print(\"predictor shape:\", predictor.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# is of batch size, seq length,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q29pFNMoOg4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = np.zeros((50,1,1,16,16))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nefIDQzoOnbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1[:,0,0].shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kulxvr-3G9RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pwd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuOuuQUBW8v6",
        "colab_type": "text"
      },
      "source": [
        "# trying to unfuck averaging \n",
        "\n",
        "todo - put simple occurance of conflict as prediction - occurance of massive events - way bigger than average lead to issues with non gaussian distribution of event sizes. \n",
        "use binary to predict.\n",
        "re run dataset creation tonight and add single binary prediction\n",
        "- powerlaw transformation?\n",
        "- double check what the loss function is comparing. \n",
        "- make example where it imshows just for fun so can see what the inputs are.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L2iuV5GqdMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pwd\n",
        "# %cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKk1EIXUXwFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avg = np.load(\"dset4_avg.npy\")\n",
        "# std = np.load(\"dset4_std.npy\")\n",
        "# apbln = [1,0,0,0,1] # think this is correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRTblglIXyl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ELkwJ8HMMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd ..\n",
        "# index_map = np.arange(0,84485,1)\n",
        "# train = HDF5Dataset_with_avgs('data_prio_run_test4.hdf5', list(index_map),avg, std, apbln)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nquiRWWaeV_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred = train[0:200][0]\n",
        "\n",
        "# tru = train[0:200][1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CghmBSi7nkrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pred.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWef8waDnqAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tru.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGalPmdIqvg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj9hQMw7siXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -4.4e-2 == -0.044"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdOToLkq_Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # event 164 has massive mseloss due to large error\n",
        "# pred[164][-1][0].unique(return_counts = True) # why not lots of -0.44 ect \n",
        "# # plt.imshow(pred[164][-1][0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubUHdh1qrSr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tru[164].unique(return_counts = True) \n",
        "# # pred[164][-1][0].shape\n",
        "\n",
        "\n",
        "# # plt.imshow(tru[164])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5lUsVkdnzIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b(pred[164][-1][0],tru[164])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQpw9FEKoYZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tot = 0\n",
        "# for i in range(200):\n",
        "#     print(i)\n",
        "#     print(b(pred[i][-1][0], tru[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca_cEykSooKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQUaOOUregUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(pred[0][-1][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tttv1E-ck9GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(tru[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMj4c3H9eoG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(tru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHqZrAbPk_bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tru"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAQ4Ai4nervO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b(pred[0][0], tru)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oFJmQRyRI-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # d = train[20000]\n",
        "# d = train[20000:20010]\n",
        "# print(d[0].shape)\n",
        "# plt.imshow(d[1][0])\n",
        "# o = d[0][0]\n",
        "# for i in range(10):\n",
        "#     plt.figure()\n",
        "#     plt.imshow(o[i][0])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJHzwzCmHogM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %pwd\n",
        "# %cd data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9IZQNO4Ft1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd \n",
        "# b = nn.MSELoss()\n",
        "\n",
        "# avg = np.load(\"dset4_avg.npy\")\n",
        "# std = np.load(\"dset4_std.npy\")\n",
        "# apbln = [1,0,0,0,1] # think this is correct\n",
        "    \n",
        "# wrapper_full(\"first_run_full_data\", 10, structure, b, avg, std, apbln, lr = 0.005, epochs = 200, batch_size = 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X5y90Hn9ALr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}